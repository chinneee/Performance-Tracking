{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "217392d9",
   "metadata": {},
   "source": [
    "# Monthly Performance (Daily)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "903bddd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "import glob\n",
    "import re\n",
    "\n",
    "import gspread\n",
    "from gspread_dataframe import set_with_dataframe\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "from google.oauth2.service_account import Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44cce45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_date_from_filename(filename):\n",
    "    \"\"\"\n",
    "    Extract date from filename pattern: SA_Campaign_List_YYYYMMDD_YYYYMMDD_hash.xlxs\n",
    "    Returns the first date (start date)\n",
    "    \"\"\"\n",
    "    pattern = r'SA_Campaign_List_(\\d{8})_\\d{8}_.*\\.xlxs'\n",
    "    match = re.search(pattern, os.path.basename(filename))\n",
    "    if match:\n",
    "        date_str = match.group(1)\n",
    "        return pd.to_datetime(date_str, format='%Y%m%d')\n",
    "    return None\n",
    "\n",
    "def clean_currency_column(column):\n",
    "    \"\"\"\n",
    "    Remove $ symbol and convert to float\n",
    "    \"\"\"\n",
    "    if column.dtype == 'object':\n",
    "        # Remove $ symbol and any other non-numeric characters except decimal point\n",
    "        cleaned = column.astype(str).str.replace(r'[$,]', '', regex=True)\n",
    "        # Replace empty strings and 'nan' with NaN\n",
    "        cleaned = cleaned.replace(['', 'nan', 'NaN'], np.nan)\n",
    "        return pd.to_numeric(cleaned, errors='coerce')\n",
    "    return column\n",
    "\n",
    "def convert_to_float(column):\n",
    "    \"\"\"\n",
    "    Convert object columns to float\n",
    "    \"\"\"\n",
    "    if column.dtype == 'object':\n",
    "        # Replace empty strings and specific text with NaN\n",
    "        cleaned = column.astype(str).str.replace(r'[%,]', '', regex=True)\n",
    "        cleaned = cleaned.replace(['', 'nan', 'NaN', '--', 'N/A'], np.nan)\n",
    "        return pd.to_numeric(cleaned, errors='coerce')\n",
    "    return column\n",
    "\n",
    "def convert_to_int(column):\n",
    "    \"\"\"\n",
    "    Convert object columns to int\n",
    "    \"\"\"\n",
    "    if column.dtype == 'object':\n",
    "        cleaned = column.astype(str).str.replace(r'[,]', '', regex=True)\n",
    "        cleaned = cleaned.replace(['', 'nan', 'NaN', '--', 'N/A'], np.nan)\n",
    "        # Convert to float first, then to int (handling NaN values)\n",
    "        float_col = pd.to_numeric(cleaned, errors='coerce')\n",
    "        return float_col.astype('Int64')  # Nullable integer type\n",
    "    return column\n",
    "\n",
    "def extract_asin_from_portfolio(portfolio_str):\n",
    "    \"\"\"\n",
    "    Extract ASIN from Portfolio string. ASIN is typically 10 characters:\n",
    "    - Pattern 1: B followed by 9 alphanumeric characters (e.g., B08XXXXXXX)\n",
    "    - Pattern 2: 10 alphanumeric characters starting with letters\n",
    "    - Pattern 3: Any 10 consecutive alphanumeric characters\n",
    "    \"\"\"\n",
    "    if pd.isna(portfolio_str) or portfolio_str == '':\n",
    "        return None\n",
    "    \n",
    "    portfolio_str = str(portfolio_str)\n",
    "    \n",
    "    # Pattern 1: B + 9 alphanumeric (most common ASIN format)\n",
    "    pattern1 = r'B[A-Z0-9]{9}'\n",
    "    match1 = re.search(pattern1, portfolio_str)\n",
    "    if match1:\n",
    "        return match1.group()\n",
    "    \n",
    "    # Pattern 2: 10 alphanumeric characters starting with letter\n",
    "    pattern2 = r'[A-Z][A-Z0-9]{9}'\n",
    "    match2 = re.search(pattern2, portfolio_str)\n",
    "    if match2:\n",
    "        return match2.group()\n",
    "    \n",
    "    # Pattern 3: Any 10 consecutive alphanumeric characters\n",
    "    pattern3 = r'[A-Z0-9]{10}'\n",
    "    match3 = re.search(pattern3, portfolio_str)\n",
    "    if match3:\n",
    "        return match3.group()\n",
    "    \n",
    "    # Pattern 4: 10 alphanumeric with possible lowercase (convert to uppercase)\n",
    "    pattern4 = r'[A-Za-z0-9]{10}'\n",
    "    match4 = re.search(pattern4, portfolio_str)\n",
    "    if match4:\n",
    "        return match4.group().upper()\n",
    "    \n",
    "    # If no pattern matches, return first 10 characters as fallback\n",
    "    clean_str = re.sub(r'[^A-Za-z0-9]', '', portfolio_str)\n",
    "    if len(clean_str) >= 10:\n",
    "        return clean_str[:10].upper()\n",
    "    \n",
    "    return portfolio_str[:10] if len(portfolio_str) >= 10 else portfolio_str\n",
    "\n",
    "def normalize_campaign_types(text):\n",
    "    \"\"\"\n",
    "    Normalize campaign type keywords\n",
    "    \"\"\"\n",
    "    if pd.isna(text) or text == '':\n",
    "        return text\n",
    "    \n",
    "    text = str(text)\n",
    "    \n",
    "    # Define normalization mapping\n",
    "    normalizations = {\n",
    "        'sponsoredBrands': 'SB',\n",
    "        'sponsoredDisplay': 'SD', \n",
    "        'sponsoredProducts': 'SP',\n",
    "        'sponsoredbrands': 'SB',\n",
    "        'sponsoreddisplay': 'SD',\n",
    "        'sponsoredproducts': 'SP',\n",
    "        'Sponsored Brands': 'SB',\n",
    "        'Sponsored Display': 'SD',\n",
    "        'Sponsored Products': 'SP'\n",
    "    }\n",
    "    \n",
    "    # Apply normalizations\n",
    "    for original, normalized in normalizations.items():\n",
    "        text = text.replace(original, normalized)\n",
    "    \n",
    "    return text\n",
    "\n",
    "def process_single_xlxs(file_path):\n",
    "    \"\"\"\n",
    "    Process a single xlxs file according to specifications\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Read CSV file\n",
    "        df = pd.read_excel(file_path, encoding='utf-8')\n",
    "        \n",
    "        # Extract date from filename\n",
    "        date_extracted = extract_date_from_filename(file_path)\n",
    "        \n",
    "        # Drop specified columns if they exist\n",
    "        columns_to_drop = ['Profile', 'Labels', 'Budget group']\n",
    "        existing_columns_to_drop = [col for col in columns_to_drop if col in df.columns]\n",
    "        if existing_columns_to_drop:\n",
    "            df = df.drop(columns=existing_columns_to_drop)\n",
    "        \n",
    "        # Add ASIN column as first column (extract ASIN from Portfolio using smart detection)\n",
    "        if 'Portfolio' in df.columns:\n",
    "            df.insert(0, 'ASIN', df['Portfolio'].apply(extract_asin_from_portfolio))\n",
    "        \n",
    "        # Add Date column\n",
    "        df.insert(1, 'Date', date_extracted)\n",
    "        \n",
    "        # Normalize campaign types in Campaign Type column\n",
    "        if 'Campaign type' in df.columns:\n",
    "            df['Campaign type'] = df['Campaign type'].apply(normalize_campaign_types)\n",
    "        \n",
    "        # Clean currency columns (remove $ and convert to float)\n",
    "        currency_columns = ['Daily Budget', 'Current Budget']\n",
    "        for col in currency_columns:\n",
    "            if col in df.columns:\n",
    "                df[col] = clean_currency_column(df[col])\n",
    "        \n",
    "        # Convert specified columns to float\n",
    "        float_columns = ['Avg.time in Budget', 'Top-of-search IS', 'CPC', 'CVR', 'ACOS', 'ROAS']\n",
    "        for col in float_columns:\n",
    "            if col in df.columns:\n",
    "                df[col] = convert_to_float(df[col])\n",
    "        \n",
    "        # Convert specified columns to int\n",
    "        int_columns = ['Orders Other SKU', 'Units Other SKU']\n",
    "        for col in int_columns:\n",
    "            if col in df.columns:\n",
    "                df[col] = convert_to_int(df[col])\n",
    "        \n",
    "        print(f\"Successfully processed: {os.path.basename(file_path)}\")\n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def process_folder(folder_path):\n",
    "    \"\"\"\n",
    "    Process all CSV files in a folder\n",
    "    \"\"\"\n",
    "    # Find all CSV files in the folder\n",
    "    csv_pattern = os.path.join(folder_path, \"*.xlxs\")\n",
    "    csv_files = glob.glob(csv_pattern)\n",
    "    \n",
    "    if not csv_files:\n",
    "        print(f\"No xlxs files found in {folder_path}\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    print(f\"Found {len(csv_files)} CSV files in {folder_path}\")\n",
    "    \n",
    "    # Process each file and collect DataFrames\n",
    "    dataframes = []\n",
    "    for file_path in sorted(csv_files):  # Sort to ensure consistent order\n",
    "        df = process_single_xlxs(file_path)\n",
    "        if df is not None and not df.empty:\n",
    "            dataframes.append(df)\n",
    "    \n",
    "    # Combine all DataFrames\n",
    "    if dataframes:\n",
    "        combined_df = pd.concat(dataframes, ignore_index=True, sort=False)\n",
    "        print(f\"Combined {len(dataframes)} files from {folder_path}\")\n",
    "        return combined_df\n",
    "    else:\n",
    "        print(f\"No valid data found in {folder_path}\")\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c45f2d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processing Ads M7 ===\n",
      "Found 31 XLSX files\n",
      "Processing: SA_Campaign_List_20250701_20250701_4WJG5E.xlsx\n",
      "  - Rows: 120\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-08-28 00:00:00\n",
      "Processing: SA_Campaign_List_20250702_20250702_xUOGZv.xlsx\n",
      "  - Rows: 108\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-08-28 00:00:00\n",
      "Processing: SA_Campaign_List_20250703_20250703_xmkj9O.xlsx\n",
      "  - Rows: 107\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-08-28 00:00:00\n",
      "Processing: SA_Campaign_List_20250704_20250704_dBKLQ3.xlsx\n",
      "  - Rows: 104\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-08-28 00:00:00\n",
      "Processing: SA_Campaign_List_20250705_20250705_p4i8mp.xlsx\n",
      "  - Rows: 104\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-08-28 00:00:00\n",
      "Processing: SA_Campaign_List_20250706_20250706_kwqqom.xlsx\n",
      "  - Rows: 105\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-08-28 00:00:00\n",
      "Processing: SA_Campaign_List_20250707_20250707_TC2Ogc.xlsx\n",
      "  - Rows: 97\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-08-28 00:00:00\n",
      "Processing: SA_Campaign_List_20250708_20250708_gciUtn.xlsx\n",
      "  - Rows: 101\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-08-28 00:00:00\n",
      "Processing: SA_Campaign_List_20250709_20250709_kiqQ0F.xlsx\n",
      "  - Rows: 99\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-08-28 00:00:00\n",
      "Processing: SA_Campaign_List_20250710_20250710_2FHxEA.xlsx\n",
      "  - Rows: 103\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-08-28 00:00:00\n",
      "Processing: SA_Campaign_List_20250711_20250711_MPg1F3.xlsx\n",
      "  - Rows: 114\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-08-28 00:00:00\n",
      "Processing: SA_Campaign_List_20250712_20250712_IZIMui.xlsx\n",
      "  - Rows: 108\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-08-28 00:00:00\n",
      "Processing: SA_Campaign_List_20250713_20250713_zr2GfU.xlsx\n",
      "  - Rows: 106\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-08-28 00:00:00\n",
      "Processing: SA_Campaign_List_20250714_20250714_I358RU.xlsx\n",
      "  - Rows: 96\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-08-28 00:00:00\n",
      "Processing: SA_Campaign_List_20250715_20250715_JAVCpg.xlsx\n",
      "  - Rows: 84\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-08-28 00:00:00\n",
      "Processing: SA_Campaign_List_20250716_20250716_ytXnzl.xlsx\n",
      "  - Rows: 68\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-08-28 00:00:00\n",
      "Processing: SA_Campaign_List_20250717_20250717_g88Fdt.xlsx\n",
      "  - Rows: 57\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-08-28 00:00:00\n",
      "Processing: SA_Campaign_List_20250718_20250718_Qlj7wK.xlsx\n",
      "  - Rows: 49\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-08-28 00:00:00\n",
      "Processing: SA_Campaign_List_20250719_20250719_uKK5QU.xlsx\n",
      "  - Rows: 53\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-08-28 00:00:00\n",
      "Processing: SA_Campaign_List_20250720_20250720_Iaf7fh.xlsx\n",
      "  - Rows: 54\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-08-28 00:00:00\n",
      "Processing: SA_Campaign_List_20250721_20250721_Qhlekk.xlsx\n",
      "  - Rows: 52\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-08-28 00:00:00\n",
      "Processing: SA_Campaign_List_20250722_20250722_7caWnY.xlsx\n",
      "  - Rows: 51\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-08-28 00:00:00\n",
      "Processing: SA_Campaign_List_20250723_20250723_MED0zR.xlsx\n",
      "  - Rows: 53\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-08-28 00:00:00\n",
      "Processing: SA_Campaign_List_20250724_20250724_4covm5.xlsx\n",
      "  - Rows: 45\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-08-28 00:00:00\n",
      "Processing: SA_Campaign_List_20250725_20250725_WLA9uW.xlsx\n",
      "  - Rows: 35\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-08-28 00:00:00\n",
      "Processing: SA_Campaign_List_20250726_20250726_enQAx4.xlsx\n",
      "  - Rows: 33\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-08-28 00:00:00\n",
      "Processing: SA_Campaign_List_20250727_20250727_8SlyWP.xlsx\n",
      "  - Rows: 35\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-08-28 00:00:00\n",
      "Processing: SA_Campaign_List_20250728_20250728_pa3zYT.xlsx\n",
      "  - Rows: 27\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-08-28 00:00:00\n",
      "Processing: SA_Campaign_List_20250729_20250729_vOmdcC.xlsx\n",
      "  - Rows: 22\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-08-28 00:00:00\n",
      "Processing: SA_Campaign_List_20250730_20250730_y9IPnP.xlsx\n",
      "  - Rows: 21\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-08-28 00:00:00\n",
      "Processing: SA_Campaign_List_20250731_20250731_FHZQ1Z.xlsx\n",
      "  - Rows: 18\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-08-28 00:00:00\n",
      "Combined 31 files into 2229 total rows\n",
      "\n",
      "=== Processing Ads M8 ===\n",
      "Found 25 XLSX files\n",
      "Processing: SA_Campaign_List_20250801_20250801_PzzQVP.xlsx\n",
      "  - Rows: 18\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-08-28 00:00:00\n",
      "Processing: SA_Campaign_List_20250802_20250802_WvxgGp.xlsx\n",
      "  - Rows: 19\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-08-28 00:00:00\n",
      "Processing: SA_Campaign_List_20250803_20250803_covfo3.xlsx\n",
      "  - Rows: 19\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-08-28 00:00:00\n",
      "Processing: SA_Campaign_List_20250804_20250804_5sYEQV.xlsx\n",
      "  - Rows: 19\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-08-28 00:00:00\n",
      "Processing: SA_Campaign_List_20250805_20250805_dPnOAQ.xlsx\n",
      "  - Rows: 19\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-08-28 00:00:00\n",
      "Processing: SA_Campaign_List_20250806_20250806_5NcnJG.xlsx\n",
      "  - Rows: 16\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-08-28 00:00:00\n",
      "Processing: SA_Campaign_List_20250807_20250807_KNRLaB.xlsx\n",
      "  - Rows: 16\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-08-28 00:00:00\n",
      "Processing: SA_Campaign_List_20250808_20250808_K9lFxE.xlsx\n",
      "  - Rows: 16\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-08-28 00:00:00\n",
      "Processing: SA_Campaign_List_20250809_20250809_p7V74a.xlsx\n",
      "  - Rows: 17\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-08-28 00:00:00\n",
      "Processing: SA_Campaign_List_20250810_20250810_fKDLxZ.xlsx\n",
      "  - Rows: 16\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-08-28 00:00:00\n",
      "Processing: SA_Campaign_List_20250811_20250811_exhB9y.xlsx\n",
      "  - Rows: 16\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-08-28 00:00:00\n",
      "Processing: SA_Campaign_List_20250812_20250812_uHCldf.xlsx\n",
      "  - Rows: 17\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-08-28 00:00:00\n",
      "Processing: SA_Campaign_List_20250813_20250813_GxUTpq.xlsx\n",
      "  - Rows: 35\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-08-28 00:00:00\n",
      "Processing: SA_Campaign_List_20250814_20250814_sbIV2b.xlsx\n",
      "  - Rows: 41\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-08-28 00:00:00\n",
      "Processing: SA_Campaign_List_20250815_20250815_SNyJ2f.xlsx\n",
      "  - Rows: 55\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-08-28 00:00:00\n",
      "Processing: SA_Campaign_List_20250816_20250816_jPyqmt.xlsx\n",
      "  - Rows: 61\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-08-28 00:00:00\n",
      "Processing: SA_Campaign_List_20250817_20250817_MISNdf.xlsx\n",
      "  - Rows: 61\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-08-28 00:00:00\n",
      "Processing: SA_Campaign_List_20250818_20250818_VGtnry.xlsx\n",
      "  - Rows: 78\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-08-28 00:00:00\n",
      "Processing: SA_Campaign_List_20250819_20250819_9Fkc8y.xlsx\n",
      "  - Rows: 85\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-08-28 00:00:00\n",
      "Processing: SA_Campaign_List_20250820_20250820_QH3jHI.xlsx\n",
      "  - Rows: 83\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-08-28 00:00:00\n",
      "Processing: SA_Campaign_List_20250821_20250821_Yhbpou.xlsx\n",
      "  - Rows: 83\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-08-28 00:00:00\n",
      "Processing: SA_Campaign_List_20250822_20250822_ObEtgh.xlsx\n",
      "  - Rows: 85\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-08-28 00:00:00\n",
      "Processing: SA_Campaign_List_20250823_20250823_0kDt43.xlsx\n",
      "  - Rows: 86\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-08-28 00:00:00\n",
      "Processing: SA_Campaign_List_20250824_20250824_IVJBcG.xlsx\n",
      "  - Rows: 85\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-08-28 00:00:00\n",
      "Processing: SA_Campaign_List_20250825_20250825_4W6CuI.xlsx\n",
      "  - Rows: 86\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-08-28 00:00:00\n",
      "Combined 25 files into 1132 total rows\n",
      "\n",
      "=== Final Results ===\n",
      "Total rows: 3361\n",
      "Date range: 2025-08-28 00:00:00 to 2025-08-28 00:00:00\n",
      "Columns: ['Campaign type', 'Campaign', 'Status', 'Country', 'Profile', 'Portfolio', 'Target type', 'Daily Budget', 'Bidding Strategy', 'SP Off-site Ads Strategy', 'Top-of-search IS', 'Avg.time in Budget', 'Impressions', 'Clicks', 'CTR', 'Spend', 'CPC', 'Orders', 'Sales', 'Units', 'CVR', 'ACOS', 'ROAS', 'CPA', 'Sales Same SKU', 'Sales Other SKU', 'Orders Same SKU', 'Orders Other SKU', 'Units Same SKU', 'Units Other SKU', 'Date']\n",
      "\n",
      "Data saved to: Combined_Ads_Data_20250828_173604.xlsx\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "       Campaign type                                           Campaign  \\\n",
      "0  sponsoredProducts          B08R8PXYL6_12oz_Sixty fabulous_auto 12h41   \n",
      "1  sponsoredProducts          B0BYDDFNBD_CF_One more chapter_auto 11h12   \n",
      "2  sponsoredProducts  B0CM5RJ8VD_20oz_Favorite dad nutri black_all k...   \n",
      "3  sponsoredProducts  B08R8R2LQF_20oz_May forties be with you_auto 1...   \n",
      "4  sponsoredProducts   B0CM5RJ8VD_20oz_Favorite dad nutri black_asin ex   \n",
      "\n",
      "       Status Country    Profile  \\\n",
      "0      Paused      CA  NewEleven   \n",
      "1      Paused      CA  NewEleven   \n",
      "2      Paused      CA  NewEleven   \n",
      "3  Delivering      CA  NewEleven   \n",
      "4      Paused      CA  NewEleven   \n",
      "\n",
      "                                           Portfolio Target type Daily Budget  \\\n",
      "0     B08R8PXYL6_TUMBLER 12_SIXTY FABULOUS ROSE GOLD        auto      C$10.00   \n",
      "1      B0BYDDFNBD_COFFEE GLASS_JUST ONE MORE CHAPTER        auto       C$5.00   \n",
      "2     B0CM5RJ8VD_TUMBLER 20_FAVORITE DAD NUTRI BLACK      manual       C$5.00   \n",
      "3  B08R8R2LQF_TUMBLER 20_MAY THE FORTIES BE WITH ...        auto       C$5.00   \n",
      "4     B0CM5RJ8VD_TUMBLER 20_FAVORITE DAD NUTRI BLACK      manual       C$5.00   \n",
      "\n",
      "         Bidding Strategy SP Off-site Ads Strategy Top-of-search IS  \\\n",
      "0   Dynamic bids and down                  NOT_SET            0.003   \n",
      "1   Dynamic bids and down                  NOT_SET           0.0109   \n",
      "2  Dynamic bids down only                  NOT_SET           0.0048   \n",
      "3  Dynamic bids down only                  NOT_SET                0   \n",
      "4   Dynamic bids and down                  NOT_SET           0.0238   \n",
      "\n",
      "  Avg.time in Budget  Impressions  Clicks     CTR  Spend   CPC  Orders  Sales  \\\n",
      "0                90%         2914       4  0.0014   4.49  1.12       1  24.98   \n",
      "1               100%          812       9  0.0111   5.69  0.63       0   0.00   \n",
      "2               100%          434       1  0.0023   0.66  0.66       0   0.00   \n",
      "3               100%          373       1  0.0027   0.43  0.43       0   0.00   \n",
      "4               100%          265       1  0.0038   1.24  1.24       0   0.00   \n",
      "\n",
      "   Units   CVR    ACOS  ROAS   CPA  Sales Same SKU  Sales Other SKU  \\\n",
      "0      1  0.25  0.1797  5.56  4.49           24.98              0.0   \n",
      "1      0     0      --     0    --            0.00              0.0   \n",
      "2      0     0      --     0    --            0.00              0.0   \n",
      "3      0     0      --     0    --            0.00              0.0   \n",
      "4      0     0      --     0    --            0.00              0.0   \n",
      "\n",
      "   Orders Same SKU Orders Other SKU  Units Same SKU Units Other SKU       Date  \n",
      "0                1               --               1              -- 2025-08-28  \n",
      "1                0               --               0              -- 2025-08-28  \n",
      "2                0               --               0              -- 2025-08-28  \n",
      "3                0               --               0              -- 2025-08-28  \n",
      "4                0               --               0              -- 2025-08-28  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "def process_single_xlsx(file_path):\n",
    "    \"\"\"\n",
    "    Process a single XLSX file and extract relevant data\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"Processing: {os.path.basename(file_path)}\")\n",
    "        \n",
    "        # Read Excel file\n",
    "        df = pd.read_excel(file_path)\n",
    "        \n",
    "        # Remove completely empty columns\n",
    "        df = df.dropna(axis=1, how='all')\n",
    "        \n",
    "        # Clean column names (strip whitespace)\n",
    "        df.columns = [str(col).strip() for col in df.columns]\n",
    "        \n",
    "        # Extract date from filename (assuming format contains DD_MM_YYYY)\n",
    "        filename = os.path.basename(file_path)\n",
    "        date_match = re.search(r'(\\d{2}_\\d{2}_\\d{4})', filename)\n",
    "        if date_match:\n",
    "            date_str = date_match.group(1)\n",
    "            file_date = pd.to_datetime(date_str, format='%d_%m_%Y')\n",
    "            df['Date'] = file_date\n",
    "        else:\n",
    "            # Try other common date formats\n",
    "            date_match = re.search(r'(\\d{4}-\\d{2}-\\d{2})', filename)\n",
    "            if date_match:\n",
    "                df['Date'] = pd.to_datetime(date_match.group(1))\n",
    "            else:\n",
    "                # Use file modification date as fallback\n",
    "                mod_time = os.path.getmtime(file_path)\n",
    "                df['Date'] = pd.to_datetime(datetime.fromtimestamp(mod_time).date())\n",
    "        \n",
    "        print(f\"  - Rows: {len(df)}\")\n",
    "        print(f\"  - Columns: {len(df.columns)}\")\n",
    "        print(f\"  - Date assigned: {df['Date'].iloc[0] if not df.empty else 'N/A'}\")\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def process_folder(folder_path):\n",
    "    \"\"\"\n",
    "    Process all XLSX files in a folder and return combined DataFrame\n",
    "    \"\"\"\n",
    "    if not os.path.exists(folder_path):\n",
    "        print(f\"Folder not found: {folder_path}\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    xlsx_files = [f for f in os.listdir(folder_path) if f.lower().endswith('.xlsx') and not f.startswith('~')]\n",
    "    \n",
    "    if not xlsx_files:\n",
    "        print(f\"No XLSX files found in {folder_path}\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    print(f\"Found {len(xlsx_files)} XLSX files\")\n",
    "    \n",
    "    dataframes = []\n",
    "    for file in xlsx_files:\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        df = process_single_xlsx(file_path)\n",
    "        if df is not None and not df.empty:\n",
    "            dataframes.append(df)\n",
    "    \n",
    "    if dataframes:\n",
    "        # Combine all dataframes\n",
    "        combined_df = pd.concat(dataframes, ignore_index=True, sort=False)\n",
    "        print(f\"Combined {len(dataframes)} files into {len(combined_df)} total rows\")\n",
    "        return combined_df\n",
    "    else:\n",
    "        print(\"No valid data found in any files\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to process Ads M7 and M8 folders\n",
    "    \"\"\"\n",
    "    # Define folder paths\n",
    "    base_path = \"C:/Users/admin1/Desktop/Performance-Tracking/Ads-XNurta\"  # Adjust this path as needed\n",
    "    ads_m7_path = os.path.join(base_path, \"H2_2025_CA\", \"Tháng 7\")\n",
    "    ads_m8_path = os.path.join(base_path, \"H2_2025_CA\", \"Tháng 8\")\n",
    "    \n",
    "    # Check if folders exist\n",
    "    folders_to_process = []\n",
    "    if os.path.exists(ads_m7_path):\n",
    "        folders_to_process.append((\"Ads M7\", ads_m7_path))\n",
    "    else:\n",
    "        print(f\"Warning: {ads_m7_path} not found\")\n",
    "    \n",
    "    if os.path.exists(ads_m8_path):\n",
    "        folders_to_process.append((\"Ads M8\", ads_m8_path))\n",
    "    else:\n",
    "        print(f\"Warning: {ads_m8_path} not found\")\n",
    "    \n",
    "    if not folders_to_process:\n",
    "        print(\"No valid folders found. Please check your paths.\")\n",
    "        return\n",
    "    \n",
    "    # Process each folder\n",
    "    all_dataframes = []\n",
    "    for folder_name, folder_path in folders_to_process:\n",
    "        print(f\"\\n=== Processing {folder_name} ===\")\n",
    "        df = process_folder(folder_path)\n",
    "        if not df.empty:\n",
    "            all_dataframes.append(df)\n",
    "    \n",
    "    # Combine all data from both folders\n",
    "    if all_dataframes:\n",
    "        final_df = pd.concat(all_dataframes, ignore_index=True, sort=False)\n",
    "        \n",
    "        # Sort by Date and ASIN for better organization (if ASIN column exists)\n",
    "        sort_columns = ['Date']\n",
    "        if 'ASIN' in final_df.columns:\n",
    "            sort_columns.append('ASIN')\n",
    "        \n",
    "        final_df = final_df.sort_values(sort_columns, na_position='last')\n",
    "        \n",
    "        # Reset index\n",
    "        final_df = final_df.reset_index(drop=True)\n",
    "        \n",
    "        print(f\"\\n=== Final Results ===\")\n",
    "        print(f\"Total rows: {len(final_df)}\")\n",
    "        print(f\"Date range: {final_df['Date'].min()} to {final_df['Date'].max()}\")\n",
    "        print(f\"Columns: {list(final_df.columns)}\")\n",
    "        \n",
    "        # Save combined data as XLSX\n",
    "        output_filename = f\"Combined_Ads_Data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx\"\n",
    "        \n",
    "        # Handle datetime columns for Excel compatibility\n",
    "        for col in final_df.columns:\n",
    "            if final_df[col].dtype == 'datetime64[ns, UTC]':\n",
    "                final_df[col] = final_df[col].dt.tz_localize(None)\n",
    "        \n",
    "        # Create Excel writer object\n",
    "        with pd.ExcelWriter(output_filename, engine='openpyxl') as writer:\n",
    "            final_df.to_excel(writer, sheet_name='Combined_Ads_Data', index=False)\n",
    "            \n",
    "            # Get the workbook and worksheet objects\n",
    "            workbook = writer.book\n",
    "            worksheet = writer.sheets['Combined_Ads_Data']\n",
    "            \n",
    "            # Auto-adjust column widths\n",
    "            for column in worksheet.columns:\n",
    "                max_length = 0\n",
    "                column_letter = column[0].column_letter\n",
    "                for cell in column:\n",
    "                    try:\n",
    "                        if len(str(cell.value)) > max_length:\n",
    "                            max_length = len(str(cell.value))\n",
    "                    except:\n",
    "                        pass\n",
    "                adjusted_width = min(max_length + 2, 50)  # Cap at 50 characters\n",
    "                worksheet.column_dimensions[column_letter].width = adjusted_width\n",
    "        \n",
    "        print(f\"\\nData saved to: {output_filename}\")\n",
    "        \n",
    "        # Display sample data\n",
    "        print(f\"\\nSample data (first 5 rows):\")\n",
    "        pd.set_option('display.max_columns', None)\n",
    "        pd.set_option('display.width', None)\n",
    "        print(final_df.head())\n",
    "        \n",
    "        return final_df\n",
    "    else:\n",
    "        print(\"No data to process.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Additional utility functions for ongoing updates\n",
    "def update_with_new_file(existing_df, new_file_path):\n",
    "    \"\"\"\n",
    "    Add new file data to existing DataFrame\n",
    "    \"\"\"\n",
    "    new_df = process_single_xlsx(new_file_path)\n",
    "    if new_df is not None and not new_df.empty:\n",
    "        # Combine with existing data\n",
    "        updated_df = pd.concat([existing_df, new_df], ignore_index=True, sort=False)\n",
    "        \n",
    "        # Remove duplicates based on Date and ASIN (if ASIN exists)\n",
    "        if 'ASIN' in updated_df.columns:\n",
    "            updated_df = updated_df.drop_duplicates(subset=['Date', 'ASIN'], keep='last')\n",
    "            # Sort by Date and ASIN\n",
    "            updated_df = updated_df.sort_values(['Date', 'ASIN'], na_position='last')\n",
    "        else:\n",
    "            # If no ASIN, just sort by Date\n",
    "            updated_df = updated_df.sort_values(['Date'], na_position='last')\n",
    "        \n",
    "        updated_df = updated_df.reset_index(drop=True)\n",
    "        \n",
    "        print(f\"Successfully added data from {os.path.basename(new_file_path)}\")\n",
    "        return updated_df\n",
    "    else:\n",
    "        print(f\"Failed to process new file: {new_file_path}\")\n",
    "        return existing_df\n",
    "\n",
    "def daily_update(base_df_path, new_file_path):\n",
    "    \"\"\"\n",
    "    Daily update function for adding new data\n",
    "    \"\"\"\n",
    "    # Load existing data from XLSX\n",
    "    if os.path.exists(base_df_path):\n",
    "        existing_df = pd.read_excel(base_df_path)\n",
    "        if 'Date' in existing_df.columns:\n",
    "            existing_df['Date'] = pd.to_datetime(existing_df['Date'])\n",
    "    else:\n",
    "        existing_df = pd.DataFrame()\n",
    "    \n",
    "    # Add new file data\n",
    "    updated_df = update_with_new_file(existing_df, new_file_path)\n",
    "    \n",
    "    # Handle datetime columns for Excel compatibility\n",
    "    for col in updated_df.columns:\n",
    "        if updated_df[col].dtype == 'datetime64[ns, UTC]':\n",
    "            updated_df[col] = updated_df[col].dt.tz_localize(None)\n",
    "    \n",
    "    # Save updated data as XLSX\n",
    "    with pd.ExcelWriter(base_df_path, engine='openpyxl') as writer:\n",
    "        updated_df.to_excel(writer, sheet_name='Combined_Ads_Data', index=False)\n",
    "        \n",
    "        # Get the workbook and worksheet objects\n",
    "        workbook = writer.book\n",
    "        worksheet = writer.sheets['Combined_Ads_Data']\n",
    "        \n",
    "        # Auto-adjust column widths\n",
    "        for column in worksheet.columns:\n",
    "            max_length = 0\n",
    "            column_letter = column[0].column_letter\n",
    "            for cell in column:\n",
    "                try:\n",
    "                    if len(str(cell.value)) > max_length:\n",
    "                        max_length = len(str(cell.value))\n",
    "                except:\n",
    "                    pass\n",
    "            adjusted_width = min(max_length + 2, 50)  # Cap at 50 characters\n",
    "            worksheet.column_dimensions[column_letter].width = adjusted_width\n",
    "    \n",
    "    print(f\"Updated data saved to: {base_df_path}\")\n",
    "    \n",
    "    return updated_df\n",
    "\n",
    "def load_existing_data(file_path):\n",
    "    \"\"\"\n",
    "    Load existing XLSX data file\n",
    "    \"\"\"\n",
    "    if os.path.exists(file_path) and file_path.lower().endswith('.xlsx'):\n",
    "        df = pd.read_excel(file_path)\n",
    "        if 'Date' in df.columns:\n",
    "            df['Date'] = pd.to_datetime(df['Date'])\n",
    "        print(f\"Loaded existing data: {len(df)} rows from {file_path}\")\n",
    "        return df\n",
    "    else:\n",
    "        print(f\"File not found or not XLSX format: {file_path}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Run the main processing\n",
    "    result_df = main()\n",
    "    \n",
    "    # Example of how to use daily update with XLSX files:\n",
    "    # daily_update(\"Combined_Ads_Data_20241201_120000.xlsx\", \"path/to/new/file.xlsx\")\n",
    "    \n",
    "    # Example of how to load existing XLSX data:\n",
    "    # existing_data = load_existing_data(\"Combined_Ads_Data_20241201_120000.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b026772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processing Ads M7 ===\n",
      "Found 31 XLSX files\n",
      "Processing: SA_Campaign_List_20250701_20250701_4WJG5E.xlsx\n",
      "  - Date extracted from filename: 2025-07-01\n",
      "  - Rows: 120\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-07-01 00:00:00\n",
      "Processing: SA_Campaign_List_20250702_20250702_xUOGZv.xlsx\n",
      "  - Date extracted from filename: 2025-07-02\n",
      "  - Rows: 108\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-07-02 00:00:00\n",
      "Processing: SA_Campaign_List_20250703_20250703_xmkj9O.xlsx\n",
      "  - Date extracted from filename: 2025-07-03\n",
      "  - Rows: 107\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-07-03 00:00:00\n",
      "Processing: SA_Campaign_List_20250704_20250704_dBKLQ3.xlsx\n",
      "  - Date extracted from filename: 2025-07-04\n",
      "  - Rows: 104\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-07-04 00:00:00\n",
      "Processing: SA_Campaign_List_20250705_20250705_p4i8mp.xlsx\n",
      "  - Date extracted from filename: 2025-07-05\n",
      "  - Rows: 104\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-07-05 00:00:00\n",
      "Processing: SA_Campaign_List_20250706_20250706_kwqqom.xlsx\n",
      "  - Date extracted from filename: 2025-07-06\n",
      "  - Rows: 105\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-07-06 00:00:00\n",
      "Processing: SA_Campaign_List_20250707_20250707_TC2Ogc.xlsx\n",
      "  - Date extracted from filename: 2025-07-07\n",
      "  - Rows: 97\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-07-07 00:00:00\n",
      "Processing: SA_Campaign_List_20250708_20250708_gciUtn.xlsx\n",
      "  - Date extracted from filename: 2025-07-08\n",
      "  - Rows: 101\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-07-08 00:00:00\n",
      "Processing: SA_Campaign_List_20250709_20250709_kiqQ0F.xlsx\n",
      "  - Date extracted from filename: 2025-07-09\n",
      "  - Rows: 99\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-07-09 00:00:00\n",
      "Processing: SA_Campaign_List_20250710_20250710_2FHxEA.xlsx\n",
      "  - Date extracted from filename: 2025-07-10\n",
      "  - Rows: 103\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-07-10 00:00:00\n",
      "Processing: SA_Campaign_List_20250711_20250711_MPg1F3.xlsx\n",
      "  - Date extracted from filename: 2025-07-11\n",
      "  - Rows: 114\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-07-11 00:00:00\n",
      "Processing: SA_Campaign_List_20250712_20250712_IZIMui.xlsx\n",
      "  - Date extracted from filename: 2025-07-12\n",
      "  - Rows: 108\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-07-12 00:00:00\n",
      "Processing: SA_Campaign_List_20250713_20250713_zr2GfU.xlsx\n",
      "  - Date extracted from filename: 2025-07-13\n",
      "  - Rows: 106\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-07-13 00:00:00\n",
      "Processing: SA_Campaign_List_20250714_20250714_I358RU.xlsx\n",
      "  - Date extracted from filename: 2025-07-14\n",
      "  - Rows: 96\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-07-14 00:00:00\n",
      "Processing: SA_Campaign_List_20250715_20250715_JAVCpg.xlsx\n",
      "  - Date extracted from filename: 2025-07-15\n",
      "  - Rows: 84\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-07-15 00:00:00\n",
      "Processing: SA_Campaign_List_20250716_20250716_ytXnzl.xlsx\n",
      "  - Date extracted from filename: 2025-07-16\n",
      "  - Rows: 68\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-07-16 00:00:00\n",
      "Processing: SA_Campaign_List_20250717_20250717_g88Fdt.xlsx\n",
      "  - Date extracted from filename: 2025-07-17\n",
      "  - Rows: 57\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-07-17 00:00:00\n",
      "Processing: SA_Campaign_List_20250718_20250718_Qlj7wK.xlsx\n",
      "  - Date extracted from filename: 2025-07-18\n",
      "  - Rows: 49\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-07-18 00:00:00\n",
      "Processing: SA_Campaign_List_20250719_20250719_uKK5QU.xlsx\n",
      "  - Date extracted from filename: 2025-07-19\n",
      "  - Rows: 53\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-07-19 00:00:00\n",
      "Processing: SA_Campaign_List_20250720_20250720_Iaf7fh.xlsx\n",
      "  - Date extracted from filename: 2025-07-20\n",
      "  - Rows: 54\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-07-20 00:00:00\n",
      "Processing: SA_Campaign_List_20250721_20250721_Qhlekk.xlsx\n",
      "  - Date extracted from filename: 2025-07-21\n",
      "  - Rows: 52\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-07-21 00:00:00\n",
      "Processing: SA_Campaign_List_20250722_20250722_7caWnY.xlsx\n",
      "  - Date extracted from filename: 2025-07-22\n",
      "  - Rows: 51\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-07-22 00:00:00\n",
      "Processing: SA_Campaign_List_20250723_20250723_MED0zR.xlsx\n",
      "  - Date extracted from filename: 2025-07-23\n",
      "  - Rows: 53\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-07-23 00:00:00\n",
      "Processing: SA_Campaign_List_20250724_20250724_4covm5.xlsx\n",
      "  - Date extracted from filename: 2025-07-24\n",
      "  - Rows: 45\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-07-24 00:00:00\n",
      "Processing: SA_Campaign_List_20250725_20250725_WLA9uW.xlsx\n",
      "  - Date extracted from filename: 2025-07-25\n",
      "  - Rows: 35\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-07-25 00:00:00\n",
      "Processing: SA_Campaign_List_20250726_20250726_enQAx4.xlsx\n",
      "  - Date extracted from filename: 2025-07-26\n",
      "  - Rows: 33\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-07-26 00:00:00\n",
      "Processing: SA_Campaign_List_20250727_20250727_8SlyWP.xlsx\n",
      "  - Date extracted from filename: 2025-07-27\n",
      "  - Rows: 35\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-07-27 00:00:00\n",
      "Processing: SA_Campaign_List_20250728_20250728_pa3zYT.xlsx\n",
      "  - Date extracted from filename: 2025-07-28\n",
      "  - Rows: 27\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-07-28 00:00:00\n",
      "Processing: SA_Campaign_List_20250729_20250729_vOmdcC.xlsx\n",
      "  - Date extracted from filename: 2025-07-29\n",
      "  - Rows: 22\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-07-29 00:00:00\n",
      "Processing: SA_Campaign_List_20250730_20250730_y9IPnP.xlsx\n",
      "  - Date extracted from filename: 2025-07-30\n",
      "  - Rows: 21\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-07-30 00:00:00\n",
      "Processing: SA_Campaign_List_20250731_20250731_FHZQ1Z.xlsx\n",
      "  - Date extracted from filename: 2025-07-31\n",
      "  - Rows: 18\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-07-31 00:00:00\n",
      "Combined 31 files into 2229 total rows\n",
      "\n",
      "=== Processing Ads M8 ===\n",
      "Found 25 XLSX files\n",
      "Processing: SA_Campaign_List_20250801_20250801_PzzQVP.xlsx\n",
      "  - Date extracted from filename: 2025-08-01\n",
      "  - Rows: 18\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-08-01 00:00:00\n",
      "Processing: SA_Campaign_List_20250802_20250802_WvxgGp.xlsx\n",
      "  - Date extracted from filename: 2025-08-02\n",
      "  - Rows: 19\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-08-02 00:00:00\n",
      "Processing: SA_Campaign_List_20250803_20250803_covfo3.xlsx\n",
      "  - Date extracted from filename: 2025-08-03\n",
      "  - Rows: 19\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-08-03 00:00:00\n",
      "Processing: SA_Campaign_List_20250804_20250804_5sYEQV.xlsx\n",
      "  - Date extracted from filename: 2025-08-04\n",
      "  - Rows: 19\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-08-04 00:00:00\n",
      "Processing: SA_Campaign_List_20250805_20250805_dPnOAQ.xlsx\n",
      "  - Date extracted from filename: 2025-08-05\n",
      "  - Rows: 19\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-08-05 00:00:00\n",
      "Processing: SA_Campaign_List_20250806_20250806_5NcnJG.xlsx\n",
      "  - Date extracted from filename: 2025-08-06\n",
      "  - Rows: 16\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-08-06 00:00:00\n",
      "Processing: SA_Campaign_List_20250807_20250807_KNRLaB.xlsx\n",
      "  - Date extracted from filename: 2025-08-07\n",
      "  - Rows: 16\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-08-07 00:00:00\n",
      "Processing: SA_Campaign_List_20250808_20250808_K9lFxE.xlsx\n",
      "  - Date extracted from filename: 2025-08-08\n",
      "  - Rows: 16\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-08-08 00:00:00\n",
      "Processing: SA_Campaign_List_20250809_20250809_p7V74a.xlsx\n",
      "  - Date extracted from filename: 2025-08-09\n",
      "  - Rows: 17\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-08-09 00:00:00\n",
      "Processing: SA_Campaign_List_20250810_20250810_fKDLxZ.xlsx\n",
      "  - Date extracted from filename: 2025-08-10\n",
      "  - Rows: 16\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-08-10 00:00:00\n",
      "Processing: SA_Campaign_List_20250811_20250811_exhB9y.xlsx\n",
      "  - Date extracted from filename: 2025-08-11\n",
      "  - Rows: 16\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-08-11 00:00:00\n",
      "Processing: SA_Campaign_List_20250812_20250812_uHCldf.xlsx\n",
      "  - Date extracted from filename: 2025-08-12\n",
      "  - Rows: 17\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-08-12 00:00:00\n",
      "Processing: SA_Campaign_List_20250813_20250813_GxUTpq.xlsx\n",
      "  - Date extracted from filename: 2025-08-13\n",
      "  - Rows: 35\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-08-13 00:00:00\n",
      "Processing: SA_Campaign_List_20250814_20250814_sbIV2b.xlsx\n",
      "  - Date extracted from filename: 2025-08-14\n",
      "  - Rows: 41\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-08-14 00:00:00\n",
      "Processing: SA_Campaign_List_20250815_20250815_SNyJ2f.xlsx\n",
      "  - Date extracted from filename: 2025-08-15\n",
      "  - Rows: 55\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-08-15 00:00:00\n",
      "Processing: SA_Campaign_List_20250816_20250816_jPyqmt.xlsx\n",
      "  - Date extracted from filename: 2025-08-16\n",
      "  - Rows: 61\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-08-16 00:00:00\n",
      "Processing: SA_Campaign_List_20250817_20250817_MISNdf.xlsx\n",
      "  - Date extracted from filename: 2025-08-17\n",
      "  - Rows: 61\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-08-17 00:00:00\n",
      "Processing: SA_Campaign_List_20250818_20250818_VGtnry.xlsx\n",
      "  - Date extracted from filename: 2025-08-18\n",
      "  - Rows: 78\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-08-18 00:00:00\n",
      "Processing: SA_Campaign_List_20250819_20250819_9Fkc8y.xlsx\n",
      "  - Date extracted from filename: 2025-08-19\n",
      "  - Rows: 85\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-08-19 00:00:00\n",
      "Processing: SA_Campaign_List_20250820_20250820_QH3jHI.xlsx\n",
      "  - Date extracted from filename: 2025-08-20\n",
      "  - Rows: 83\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-08-20 00:00:00\n",
      "Processing: SA_Campaign_List_20250821_20250821_Yhbpou.xlsx\n",
      "  - Date extracted from filename: 2025-08-21\n",
      "  - Rows: 83\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-08-21 00:00:00\n",
      "Processing: SA_Campaign_List_20250822_20250822_ObEtgh.xlsx\n",
      "  - Date extracted from filename: 2025-08-22\n",
      "  - Rows: 85\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-08-22 00:00:00\n",
      "Processing: SA_Campaign_List_20250823_20250823_0kDt43.xlsx\n",
      "  - Date extracted from filename: 2025-08-23\n",
      "  - Rows: 86\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-08-23 00:00:00\n",
      "Processing: SA_Campaign_List_20250824_20250824_IVJBcG.xlsx\n",
      "  - Date extracted from filename: 2025-08-24\n",
      "  - Rows: 85\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-08-24 00:00:00\n",
      "Processing: SA_Campaign_List_20250825_20250825_4W6CuI.xlsx\n",
      "  - Date extracted from filename: 2025-08-25\n",
      "  - Rows: 86\n",
      "  - Columns: 31\n",
      "  - Date assigned: 2025-08-25 00:00:00\n",
      "Combined 25 files into 1132 total rows\n",
      "\n",
      "=== Final Results ===\n",
      "Total rows: 3361\n",
      "Date range: 2025-07-01 00:00:00 to 2025-08-25 00:00:00\n",
      "Columns: ['Campaign type', 'Campaign', 'Status', 'Country', 'Profile', 'Portfolio', 'Target type', 'Daily Budget', 'Bidding Strategy', 'SP Off-site Ads Strategy', 'Top-of-search IS', 'Avg.time in Budget', 'Impressions', 'Clicks', 'CTR', 'Spend', 'CPC', 'Orders', 'Sales', 'Units', 'CVR', 'ACOS', 'ROAS', 'CPA', 'Sales Same SKU', 'Sales Other SKU', 'Orders Same SKU', 'Orders Other SKU', 'Units Same SKU', 'Units Other SKU', 'Date']\n",
      "\n",
      "Data saved to: Combined_Ads_Data_20250828_174030.xlsx\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "       Campaign type                                           Campaign  \\\n",
      "0  sponsoredProducts          B08R8PXYL6_12oz_Sixty fabulous_auto 12h41   \n",
      "1  sponsoredProducts   B0DH7PQ1RX_20oz_vintage 1985 black_all key 11h37   \n",
      "2  sponsoredProducts  B0DH83T7MF_20oz_Vintage 1975 weird being black...   \n",
      "3  sponsoredProducts         B0DH7X6R1J_20oz_50 & fabulous_category 17h   \n",
      "4  sponsoredProducts  B0CXXJ751C_CF_Work Bestie Nutri_work bestie gi...   \n",
      "\n",
      "   Status Country    Profile  \\\n",
      "0  Paused      CA  NewEleven   \n",
      "1  Paused      CA  NewEleven   \n",
      "2  Paused      CA  NewEleven   \n",
      "3  Paused      CA  NewEleven   \n",
      "4  Paused      CA  NewEleven   \n",
      "\n",
      "                                           Portfolio Target type Daily Budget  \\\n",
      "0     B08R8PXYL6_TUMBLER 12_SIXTY FABULOUS ROSE GOLD        auto      C$10.00   \n",
      "1           B0DH7PQ1RX_TUMBLER 20_VINTAGE 1985 BLACK      manual       C$5.00   \n",
      "2           B0DH83T7MF_TUMBLER 20_VINTAGE 1975 BLACK      manual       C$5.00   \n",
      "3  B0DH7X6R1J_TUMBLER 20_50 & FABULOUS + MAKING T...      manual       C$5.00   \n",
      "4  B0CXXJ751C_COFFEE GLASS_WORK BESTIE + WORK BES...      manual       C$5.00   \n",
      "\n",
      "        Bidding Strategy SP Off-site Ads Strategy Top-of-search IS  \\\n",
      "0  Dynamic bids and down                  NOT_SET            0.003   \n",
      "1  Dynamic bids and down                  NOT_SET             0.05   \n",
      "2  Dynamic bids and down                  NOT_SET                0   \n",
      "3  Dynamic bids and down                  NOT_SET              0.5   \n",
      "4  Dynamic bids and down                  NOT_SET           0.6667   \n",
      "\n",
      "  Avg.time in Budget  Impressions  Clicks     CTR  Spend   CPC  Orders  Sales  \\\n",
      "0                90%         2914       4  0.0014   4.49  1.12       1  24.98   \n",
      "1               100%           18       0  0.0000   0.00    --       0   0.00   \n",
      "2               100%           18       0  0.0000   0.00    --       0   0.00   \n",
      "3               100%           22       1  0.0455   1.57  1.57       0   0.00   \n",
      "4               100%           23       1  0.0435   0.83  0.83       1  23.98   \n",
      "\n",
      "   Units   CVR    ACOS   ROAS   CPA  Sales Same SKU  Sales Other SKU  \\\n",
      "0      1  0.25  0.1797   5.56  4.49           24.98              0.0   \n",
      "1      0    --      --     --    --            0.00              0.0   \n",
      "2      0    --      --     --    --            0.00              0.0   \n",
      "3      0     0      --      0    --            0.00              0.0   \n",
      "4      1     1  0.0346  28.89  0.83           23.98              0.0   \n",
      "\n",
      "   Orders Same SKU Orders Other SKU  Units Same SKU Units Other SKU       Date  \n",
      "0                1               --               1              -- 2025-07-01  \n",
      "1                0               --               0              -- 2025-07-01  \n",
      "2                0               --               0              -- 2025-07-01  \n",
      "3                0               --               0              -- 2025-07-01  \n",
      "4                1               --               1              -- 2025-07-01  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "def process_single_xlsx(file_path):\n",
    "    \"\"\"\n",
    "    Process a single XLSX file and extract relevant data\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"Processing: {os.path.basename(file_path)}\")\n",
    "        \n",
    "        # Read Excel file\n",
    "        df = pd.read_excel(file_path)\n",
    "        \n",
    "        # Remove completely empty columns\n",
    "        df = df.dropna(axis=1, how='all')\n",
    "        \n",
    "        # Clean column names (strip whitespace)\n",
    "        df.columns = [str(col).strip() for col in df.columns]\n",
    "        \n",
    "        # Extract date from filename with multiple patterns\n",
    "        filename = os.path.basename(file_path)\n",
    "        file_date = None\n",
    "        \n",
    "        # Try different date patterns\n",
    "        date_patterns = [\n",
    "            # SA_Campaign_List_YYYYMMDD_YYYYMMDD_XXXX format (primary pattern)\n",
    "            (r'SA_Campaign_List_(\\d{8})_\\d{8}_\\w+', '%Y%m%d'),\n",
    "            # General YYYYMMDD format (20250701)\n",
    "            (r'(\\d{8})', '%Y%m%d'),\n",
    "            # DD_MM_YYYY format (01_07_2025)\n",
    "            (r'(\\d{2}_\\d{2}_\\d{4})', '%d_%m_%Y'),\n",
    "            # YYYY-MM-DD format (2025-07-01)\n",
    "            (r'(\\d{4}-\\d{2}-\\d{2})', '%Y-%m-%d'),\n",
    "            # DD-MM-YYYY format (01-07-2025)\n",
    "            (r'(\\d{2}-\\d{2}-\\d{4})', '%d-%m-%Y'),\n",
    "            # DD.MM.YYYY format (01.07.2025)\n",
    "            (r'(\\d{2}\\.\\d{2}\\.\\d{4})', '%d.%m.%Y'),\n",
    "            # Month names in Vietnamese/English\n",
    "            (r'(?i)(tháng\\s*7|july|jul).*(\\d{4})', None),  # July patterns\n",
    "            (r'(?i)(tháng\\s*8|august|aug).*(\\d{4})', None), # August patterns\n",
    "        ]\n",
    "        \n",
    "        for pattern, date_format in date_patterns:\n",
    "            match = re.search(pattern, filename)\n",
    "            if match:\n",
    "                try:\n",
    "                    if date_format is None:\n",
    "                        # Handle month name patterns\n",
    "                        if 'tháng' in match.group(1).lower() or 'july' in match.group(1).lower() or 'jul' in match.group(1).lower():\n",
    "                            year = match.group(2) if len(match.groups()) > 1 else '2025'\n",
    "                            file_date = pd.to_datetime(f\"{year}-07-01\")\n",
    "                        elif 'august' in match.group(1).lower() or 'aug' in match.group(1).lower():\n",
    "                            year = match.group(2) if len(match.groups()) > 1 else '2025'\n",
    "                            file_date = pd.to_datetime(f\"{year}-08-01\")\n",
    "                    else:\n",
    "                        # Handle numeric date patterns\n",
    "                        date_str = match.group(1)\n",
    "                        file_date = pd.to_datetime(date_str, format=date_format)\n",
    "                    \n",
    "                    if file_date is not None:\n",
    "                        df['Date'] = file_date\n",
    "                        print(f\"  - Date extracted from filename: {file_date.strftime('%Y-%m-%d')}\")\n",
    "                        break\n",
    "                        \n",
    "                except ValueError as e:\n",
    "                    print(f\"  - Failed to parse date with pattern {pattern}: {e}\")\n",
    "                    continue\n",
    "        \n",
    "        # If no date found, use file modification date as fallback\n",
    "        if file_date is None:\n",
    "            mod_time = os.path.getmtime(file_path)\n",
    "            df['Date'] = pd.to_datetime(datetime.fromtimestamp(mod_time).date())\n",
    "            print(f\"  - Warning: Used file modification date as fallback\")\n",
    "        \n",
    "        print(f\"  - Rows: {len(df)}\")\n",
    "        print(f\"  - Columns: {len(df.columns)}\")\n",
    "        print(f\"  - Date assigned: {df['Date'].iloc[0] if not df.empty else 'N/A'}\")\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def process_folder(folder_path):\n",
    "    \"\"\"\n",
    "    Process all XLSX files in a folder and return combined DataFrame\n",
    "    \"\"\"\n",
    "    if not os.path.exists(folder_path):\n",
    "        print(f\"Folder not found: {folder_path}\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    xlsx_files = [f for f in os.listdir(folder_path) if f.lower().endswith('.xlsx') and not f.startswith('~')]\n",
    "    \n",
    "    if not xlsx_files:\n",
    "        print(f\"No XLSX files found in {folder_path}\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    print(f\"Found {len(xlsx_files)} XLSX files\")\n",
    "    \n",
    "    dataframes = []\n",
    "    for file in xlsx_files:\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        df = process_single_xlsx(file_path)\n",
    "        if df is not None and not df.empty:\n",
    "            dataframes.append(df)\n",
    "    \n",
    "    if dataframes:\n",
    "        # Combine all dataframes\n",
    "        combined_df = pd.concat(dataframes, ignore_index=True, sort=False)\n",
    "        print(f\"Combined {len(dataframes)} files into {len(combined_df)} total rows\")\n",
    "        return combined_df\n",
    "    else:\n",
    "        print(\"No valid data found in any files\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to process Ads M7 and M8 folders\n",
    "    \"\"\"\n",
    "    # Define folder paths\n",
    "    base_path = \"C:/Users/admin1/Desktop/Performance-Tracking/Ads-XNurta\"  # Adjust this path as needed\n",
    "    ads_m7_path = os.path.join(base_path, \"H2_2025_CA\", \"Tháng 7\")\n",
    "    ads_m8_path = os.path.join(base_path, \"H2_2025_CA\", \"Tháng 8\")\n",
    "    \n",
    "    # Check if folders exist\n",
    "    folders_to_process = []\n",
    "    if os.path.exists(ads_m7_path):\n",
    "        folders_to_process.append((\"Ads M7\", ads_m7_path))\n",
    "    else:\n",
    "        print(f\"Warning: {ads_m7_path} not found\")\n",
    "    \n",
    "    if os.path.exists(ads_m8_path):\n",
    "        folders_to_process.append((\"Ads M8\", ads_m8_path))\n",
    "    else:\n",
    "        print(f\"Warning: {ads_m8_path} not found\")\n",
    "    \n",
    "    if not folders_to_process:\n",
    "        print(\"No valid folders found. Please check your paths.\")\n",
    "        return\n",
    "    \n",
    "    # Process each folder\n",
    "    all_dataframes = []\n",
    "    for folder_name, folder_path in folders_to_process:\n",
    "        print(f\"\\n=== Processing {folder_name} ===\")\n",
    "        df = process_folder(folder_path)\n",
    "        if not df.empty:\n",
    "            all_dataframes.append(df)\n",
    "    \n",
    "    # Combine all data from both folders\n",
    "    if all_dataframes:\n",
    "        final_df = pd.concat(all_dataframes, ignore_index=True, sort=False)\n",
    "        \n",
    "        # Sort by Date and ASIN for better organization (if ASIN column exists)\n",
    "        sort_columns = ['Date']\n",
    "        if 'ASIN' in final_df.columns:\n",
    "            sort_columns.append('ASIN')\n",
    "        \n",
    "        final_df = final_df.sort_values(sort_columns, na_position='last')\n",
    "        \n",
    "        # Reset index\n",
    "        final_df = final_df.reset_index(drop=True)\n",
    "        \n",
    "        print(f\"\\n=== Final Results ===\")\n",
    "        print(f\"Total rows: {len(final_df)}\")\n",
    "        print(f\"Date range: {final_df['Date'].min()} to {final_df['Date'].max()}\")\n",
    "        print(f\"Columns: {list(final_df.columns)}\")\n",
    "        \n",
    "        # Save combined data as XLSX\n",
    "        output_filename = f\"Combined_Ads_Data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx\"\n",
    "        \n",
    "        # Handle datetime columns for Excel compatibility\n",
    "        for col in final_df.columns:\n",
    "            if final_df[col].dtype == 'datetime64[ns, UTC]':\n",
    "                final_df[col] = final_df[col].dt.tz_localize(None)\n",
    "        \n",
    "        # Create Excel writer object\n",
    "        with pd.ExcelWriter(output_filename, engine='openpyxl') as writer:\n",
    "            final_df.to_excel(writer, sheet_name='Combined_Ads_Data', index=False)\n",
    "            \n",
    "            # Get the workbook and worksheet objects\n",
    "            workbook = writer.book\n",
    "            worksheet = writer.sheets['Combined_Ads_Data']\n",
    "            \n",
    "            # Auto-adjust column widths\n",
    "            for column in worksheet.columns:\n",
    "                max_length = 0\n",
    "                column_letter = column[0].column_letter\n",
    "                for cell in column:\n",
    "                    try:\n",
    "                        if len(str(cell.value)) > max_length:\n",
    "                            max_length = len(str(cell.value))\n",
    "                    except:\n",
    "                        pass\n",
    "                adjusted_width = min(max_length + 2, 50)  # Cap at 50 characters\n",
    "                worksheet.column_dimensions[column_letter].width = adjusted_width\n",
    "        \n",
    "        print(f\"\\nData saved to: {output_filename}\")\n",
    "        \n",
    "        # Display sample data\n",
    "        print(f\"\\nSample data (first 5 rows):\")\n",
    "        pd.set_option('display.max_columns', None)\n",
    "        pd.set_option('display.width', None)\n",
    "        print(final_df.head())\n",
    "        \n",
    "        return final_df\n",
    "    else:\n",
    "        print(\"No data to process.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Additional utility functions for ongoing updates\n",
    "def update_with_new_file(existing_df, new_file_path):\n",
    "    \"\"\"\n",
    "    Add new file data to existing DataFrame\n",
    "    \"\"\"\n",
    "    new_df = process_single_xlsx(new_file_path)\n",
    "    if new_df is not None and not new_df.empty:\n",
    "        # Combine with existing data\n",
    "        updated_df = pd.concat([existing_df, new_df], ignore_index=True, sort=False)\n",
    "        \n",
    "        # Remove duplicates based on Date and ASIN (if ASIN exists)\n",
    "        if 'ASIN' in updated_df.columns:\n",
    "            updated_df = updated_df.drop_duplicates(subset=['Date', 'ASIN'], keep='last')\n",
    "            # Sort by Date and ASIN\n",
    "            updated_df = updated_df.sort_values(['Date', 'ASIN'], na_position='last')\n",
    "        else:\n",
    "            # If no ASIN, just sort by Date\n",
    "            updated_df = updated_df.sort_values(['Date'], na_position='last')\n",
    "        \n",
    "        updated_df = updated_df.reset_index(drop=True)\n",
    "        \n",
    "        print(f\"Successfully added data from {os.path.basename(new_file_path)}\")\n",
    "        return updated_df\n",
    "    else:\n",
    "        print(f\"Failed to process new file: {new_file_path}\")\n",
    "        return existing_df\n",
    "\n",
    "def daily_update(base_df_path, new_file_path):\n",
    "    \"\"\"\n",
    "    Daily update function for adding new data\n",
    "    \"\"\"\n",
    "    # Load existing data from XLSX\n",
    "    if os.path.exists(base_df_path):\n",
    "        existing_df = pd.read_excel(base_df_path)\n",
    "        if 'Date' in existing_df.columns:\n",
    "            existing_df['Date'] = pd.to_datetime(existing_df['Date'])\n",
    "    else:\n",
    "        existing_df = pd.DataFrame()\n",
    "    \n",
    "    # Add new file data\n",
    "    updated_df = update_with_new_file(existing_df, new_file_path)\n",
    "    \n",
    "    # Handle datetime columns for Excel compatibility\n",
    "    for col in updated_df.columns:\n",
    "        if updated_df[col].dtype == 'datetime64[ns, UTC]':\n",
    "            updated_df[col] = updated_df[col].dt.tz_localize(None)\n",
    "    \n",
    "    # Save updated data as XLSX\n",
    "    with pd.ExcelWriter(base_df_path, engine='openpyxl') as writer:\n",
    "        updated_df.to_excel(writer, sheet_name='Combined_Ads_Data', index=False)\n",
    "        \n",
    "        # Get the workbook and worksheet objects\n",
    "        workbook = writer.book\n",
    "        worksheet = writer.sheets['Combined_Ads_Data']\n",
    "        \n",
    "        # Auto-adjust column widths\n",
    "        for column in worksheet.columns:\n",
    "            max_length = 0\n",
    "            column_letter = column[0].column_letter\n",
    "            for cell in column:\n",
    "                try:\n",
    "                    if len(str(cell.value)) > max_length:\n",
    "                        max_length = len(str(cell.value))\n",
    "                except:\n",
    "                    pass\n",
    "            adjusted_width = min(max_length + 2, 50)  # Cap at 50 characters\n",
    "            worksheet.column_dimensions[column_letter].width = adjusted_width\n",
    "    \n",
    "    print(f\"Updated data saved to: {base_df_path}\")\n",
    "    \n",
    "    return updated_df\n",
    "\n",
    "def load_existing_data(file_path):\n",
    "    \"\"\"\n",
    "    Load existing XLSX data file\n",
    "    \"\"\"\n",
    "    if os.path.exists(file_path) and file_path.lower().endswith('.xlsx'):\n",
    "        df = pd.read_excel(file_path)\n",
    "        if 'Date' in df.columns:\n",
    "            df['Date'] = pd.to_datetime(df['Date'])\n",
    "        print(f\"Loaded existing data: {len(df)} rows from {file_path}\")\n",
    "        return df\n",
    "    else:\n",
    "        print(f\"File not found or not XLSX format: {file_path}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Run the main processing\n",
    "    result_df = main()\n",
    "    \n",
    "    # Example of how to use daily update with XLSX files:\n",
    "    # daily_update(\"Combined_Ads_Data_20241201_120000.xlsx\", \"path/to/new/file.xlsx\")\n",
    "    \n",
    "    # Example of how to load existing XLSX data:\n",
    "    # existing_data = load_existing_data(\"Combined_Ads_Data_20241201_120000.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "53d4ccf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "scopes = [\"https://www.googleapis.com/auth/spreadsheets\", \n",
    "          \"https://www.googleapis.com/auth/drive\"]\n",
    "creds = Credentials.from_service_account_file(\"c:/Users/admin1/Downloads/new_credential.json\", scopes=scopes)\n",
    "client = gspread.authorize(creds)\n",
    "\n",
    "# Mở Google Sheet\n",
    "sheet_id = \"1lZ4dsi94HaeWshsEizKTyNHeOOG0tpLJhzL9pMxvd6k\"\n",
    "\n",
    "# Mở file Google Sheet (Spreadsheet object)\n",
    "spreadsheet = client.open_by_key(sheet_id)\n",
    "sheet1 = client.open_by_key(sheet_id).worksheet(\"Raw_XN_Q3_2025_CA\")\n",
    "\n",
    "set_with_dataframe(sheet1, result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe770be",
   "metadata": {},
   "source": [
    "# SellerBoard (Daily)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "def39f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "import json\n",
    "import glob\n",
    "import re\n",
    "import gspread\n",
    "from gspread_dataframe import set_with_dataframe\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "from google.oauth2.service_account import Credentials\n",
    "import json\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c4f88db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose run mode:\n",
      "1. Initial run (reprocess all July-August files)\n",
      "2. Incremental run (process only new/modified files)\n",
      "============================================================\n",
      "🚀 INITIAL RUN: Processing all July-August files\n",
      "🗑️ Cleared metadata for July/August file: NewEleven_EU_Dashboard Products Group by ASIN_01_07_2025-01_07_2025_(09_26_07_381).xlsx\n",
      "🗑️ Cleared metadata for July/August file: NewEleven_EU_Dashboard Products Group by ASIN_02_07_2025-02_07_2025_(09_26_20_162).xlsx\n",
      "🗑️ Cleared metadata for July/August file: NewEleven_EU_Dashboard Products Group by ASIN_03_07_2025-03_07_2025_(09_26_33_861).xlsx\n",
      "🗑️ Cleared metadata for July/August file: NewEleven_EU_Dashboard Products Group by ASIN_04_07_2025-04_07_2025_(09_26_45_926).xlsx\n",
      "🗑️ Cleared metadata for July/August file: NewEleven_EU_Dashboard Products Group by ASIN_05_07_2025-05_07_2025_(09_26_57_228).xlsx\n",
      "🗑️ Cleared metadata for July/August file: NewEleven_EU_Dashboard Products Group by ASIN_06_07_2025-06_07_2025_(09_27_10_809).xlsx\n",
      "🗑️ Cleared metadata for July/August file: NewEleven_EU_Dashboard Products Group by ASIN_07_07_2025-07_07_2025_(09_27_22_413).xlsx\n",
      "🗑️ Cleared metadata for July/August file: NewEleven_EU_Dashboard Products Group by ASIN_08_07_2025-08_07_2025_(09_27_34_523).xlsx\n",
      "🗑️ Cleared metadata for July/August file: NewEleven_EU_Dashboard Products Group by ASIN_09_07_2025-09_07_2025_(09_27_46_109).xlsx\n",
      "🗑️ Cleared metadata for July/August file: NewEleven_EU_Dashboard Products Group by ASIN_10_07_2025-10_07_2025_(09_27_57_905).xlsx\n",
      "🗑️ Cleared metadata for July/August file: NewEleven_EU_Dashboard Products Group by ASIN_11_07_2025-11_07_2025_(09_28_09_867).xlsx\n",
      "🗑️ Cleared metadata for July/August file: NewEleven_EU_Dashboard Products Group by ASIN_12_07_2025-12_07_2025_(09_28_21_969).xlsx\n",
      "🗑️ Cleared metadata for July/August file: NewEleven_EU_Dashboard Products Group by ASIN_13_07_2025-13_07_2025_(09_28_33_834).xlsx\n",
      "🗑️ Cleared metadata for July/August file: NewEleven_EU_Dashboard Products Group by ASIN_14_07_2025-14_07_2025_(09_28_46_707).xlsx\n",
      "🗑️ Cleared metadata for July/August file: NewEleven_EU_Dashboard Products Group by ASIN_15_07_2025-15_07_2025_(09_28_58_142).xlsx\n",
      "🗑️ Cleared metadata for July/August file: NewEleven_EU_Dashboard Products Group by ASIN_16_07_2025-16_07_2025_(09_29_09_655).xlsx\n",
      "🗑️ Cleared metadata for July/August file: NewEleven_EU_Dashboard Products Group by ASIN_17_07_2025-17_07_2025_(09_29_23_726).xlsx\n",
      "🗑️ Cleared metadata for July/August file: NewEleven_EU_Dashboard Products Group by ASIN_18_07_2025-18_07_2025_(09_29_36_942).xlsx\n",
      "🗑️ Cleared metadata for July/August file: NewEleven_EU_Dashboard Products Group by ASIN_19_07_2025-19_07_2025_(09_29_50_948).xlsx\n",
      "🗑️ Cleared metadata for July/August file: NewEleven_EU_Dashboard Products Group by ASIN_20_07_2025-20_07_2025_(09_30_03_862).xlsx\n",
      "🗑️ Cleared metadata for July/August file: NewEleven_EU_Dashboard Products Group by ASIN_21_07_2025-21_07_2025_(09_30_18_319).xlsx\n",
      "🗑️ Cleared metadata for July/August file: NewEleven_EU_Dashboard Products Group by ASIN_22_07_2025-22_07_2025_(09_30_33_993).xlsx\n",
      "🗑️ Cleared metadata for July/August file: NewEleven_EU_Dashboard Products Group by ASIN_23_07_2025-23_07_2025_(09_30_43_234).xlsx\n",
      "🗑️ Cleared metadata for July/August file: NewEleven_EU_Dashboard Products Group by ASIN_24_07_2025-24_07_2025_(09_30_54_151).xlsx\n",
      "🗑️ Cleared metadata for July/August file: NewEleven_EU_Dashboard Products Group by ASIN_25_07_2025-25_07_2025_(09_31_10_103).xlsx\n",
      "🗑️ Cleared metadata for July/August file: NewEleven_EU_Dashboard Products Group by ASIN_26_07_2025-26_07_2025_(09_31_28_569).xlsx\n",
      "🗑️ Cleared metadata for July/August file: NewEleven_EU_Dashboard Products Group by ASIN_27_07_2025-27_07_2025_(09_31_39_815).xlsx\n",
      "🗑️ Cleared metadata for July/August file: NewEleven_EU_Dashboard Products Group by ASIN_28_07_2025-28_07_2025_(09_31_48_326).xlsx\n",
      "🗑️ Cleared metadata for July/August file: NewEleven_EU_Dashboard Products Group by ASIN_29_07_2025-29_07_2025_(09_31_58_235).xlsx\n",
      "🗑️ Cleared metadata for July/August file: NewEleven_EU_Dashboard Products Group by ASIN_30_07_2025-30_07_2025_(09_32_08_308).xlsx\n",
      "🗑️ Cleared metadata for July/August file: NewEleven_EU_Dashboard Products Group by ASIN_31_07_2025-31_07_2025_(09_32_18_858).xlsx\n",
      "🗑️ Cleared metadata for July/August file: NewEleven_EU_Dashboard Products Group by ASIN_01_08_2025-01_08_2025_(09_32_32_640).xlsx\n",
      "🗑️ Cleared metadata for July/August file: NewEleven_EU_Dashboard Products Group by ASIN_02_08_2025-02_08_2025_(09_32_46_122).xlsx\n",
      "🗑️ Cleared metadata for July/August file: NewEleven_EU_Dashboard Products Group by ASIN_03_08_2025-03_08_2025_(09_33_02_477).xlsx\n",
      "🗑️ Cleared metadata for July/August file: NewEleven_EU_Dashboard Products Group by ASIN_04_08_2025-04_08_2025_(09_33_12_945).xlsx\n",
      "🗑️ Cleared metadata for July/August file: NewEleven_EU_Dashboard Products Group by ASIN_05_08_2025-05_08_2025_(09_33_22_773).xlsx\n",
      "🗑️ Cleared metadata for July/August file: NewEleven_EU_Dashboard Products Group by ASIN_06_08_2025-06_08_2025_(09_33_33_746).xlsx\n",
      "🗑️ Cleared metadata for July/August file: NewEleven_EU_Dashboard Products Group by ASIN_07_08_2025-07_08_2025_(09_33_45_831).xlsx\n",
      "🗑️ Cleared metadata for July/August file: NewEleven_EU_Dashboard Products Group by ASIN_08_08_2025-08_08_2025_(09_33_55_312).xlsx\n",
      "🗑️ Cleared metadata for July/August file: NewEleven_EU_Dashboard Products Group by ASIN_09_08_2025-09_08_2025_(09_34_06_159).xlsx\n",
      "🗑️ Cleared metadata for July/August file: NewEleven_EU_Dashboard Products Group by ASIN_10_08_2025-10_08_2025_(09_34_19_483).xlsx\n",
      "🗑️ Cleared metadata for July/August file: NewEleven_EU_Dashboard Products Group by ASIN_11_08_2025-11_08_2025_(09_34_28_709).xlsx\n",
      "🗑️ Cleared metadata for July/August file: NewEleven_EU_Dashboard Products Group by ASIN_12_08_2025-12_08_2025_(09_34_42_881).xlsx\n",
      "🗑️ Cleared metadata for July/August file: NewEleven_EU_Dashboard Products Group by ASIN_13_08_2025-13_08_2025_(09_34_51_142).xlsx\n",
      "🗑️ Cleared metadata for July/August file: NewEleven_EU_Dashboard Products Group by ASIN_14_08_2025-14_08_2025_(09_35_01_703).xlsx\n",
      "🗑️ Cleared metadata for July/August file: NewEleven_EU_Dashboard Products Group by ASIN_15_08_2025-15_08_2025_(09_35_12_567).xlsx\n",
      "🗑️ Cleared metadata for July/August file: NewEleven_EU_Dashboard Products Group by ASIN_16_08_2025-16_08_2025_(09_35_25_805).xlsx\n",
      "🗑️ Cleared metadata for July/August file: NewEleven_EU_Dashboard Products Group by ASIN_17_08_2025-17_08_2025_(09_35_35_305).xlsx\n",
      "🗑️ Cleared metadata for July/August file: NewEleven_EU_Dashboard Products Group by ASIN_18_08_2025-18_08_2025_(09_35_46_961).xlsx\n",
      "🗑️ Cleared metadata for July/August file: NewEleven_EU_Dashboard Products Group by ASIN_19_08_2025-19_08_2025_(09_35_59_638).xlsx\n",
      "🗑️ Cleared metadata for July/August file: NewEleven_EU_Dashboard Products Group by ASIN_20_08_2025-20_08_2025_(09_36_11_475).xlsx\n",
      "🗑️ Cleared metadata for July/August file: NewEleven_EU_Dashboard Products Group by ASIN_21_08_2025-21_08_2025_(09_36_26_414).xlsx\n",
      "🗑️ Cleared metadata for July/August file: NewEleven_EU_Dashboard Products Group by ASIN_22_08_2025-22_08_2025_(09_36_39_445).xlsx\n",
      "🗑️ Cleared metadata for July/August file: NewEleven_EU_Dashboard Products Group by ASIN_23_08_2025-23_08_2025_(09_36_50_831).xlsx\n",
      "============================================================\n",
      "🔄 Initial run: Processing July/August file NewEleven_Dashboard Products Group by ASIN_01_07_2025-01_07_2025_(02_16_59_866).xlsx\n",
      "📊 Processing: NewEleven_Dashboard Products Group by ASIN_01_07_2025-01_07_2025_(02_16_59_866).xlsx\n",
      "📋 Available columns: 19/21\n",
      "⚠️ Missing columns: ['VAT', 'Shipping']\n",
      "🔄 Initial run: Processing July/August file NewEleven_Dashboard Products Group by ASIN_02_07_2025-02_07_2025_(02_17_19_401).xlsx\n",
      "📊 Processing: NewEleven_Dashboard Products Group by ASIN_02_07_2025-02_07_2025_(02_17_19_401).xlsx\n",
      "📋 Available columns: 19/21\n",
      "⚠️ Missing columns: ['VAT', 'Shipping']\n",
      "🔄 Initial run: Processing July/August file NewEleven_Dashboard Products Group by ASIN_03_07_2025-03_07_2025_(02_17_35_203).xlsx\n",
      "📊 Processing: NewEleven_Dashboard Products Group by ASIN_03_07_2025-03_07_2025_(02_17_35_203).xlsx\n",
      "📋 Available columns: 19/21\n",
      "⚠️ Missing columns: ['VAT', 'Shipping']\n",
      "🔄 Initial run: Processing July/August file NewEleven_Dashboard Products Group by ASIN_04_07_2025-04_07_2025_(02_17_52_472).xlsx\n",
      "📊 Processing: NewEleven_Dashboard Products Group by ASIN_04_07_2025-04_07_2025_(02_17_52_472).xlsx\n",
      "📋 Available columns: 19/21\n",
      "⚠️ Missing columns: ['VAT', 'Shipping']\n",
      "🔄 Initial run: Processing July/August file NewEleven_Dashboard Products Group by ASIN_05_07_2025-05_07_2025_(02_18_20_680).xlsx\n",
      "📊 Processing: NewEleven_Dashboard Products Group by ASIN_05_07_2025-05_07_2025_(02_18_20_680).xlsx\n",
      "📋 Available columns: 19/21\n",
      "⚠️ Missing columns: ['VAT', 'Shipping']\n",
      "🔄 Initial run: Processing July/August file NewEleven_Dashboard Products Group by ASIN_06_07_2025-06_07_2025_(02_18_35_117).xlsx\n",
      "📊 Processing: NewEleven_Dashboard Products Group by ASIN_06_07_2025-06_07_2025_(02_18_35_117).xlsx\n",
      "📋 Available columns: 19/21\n",
      "⚠️ Missing columns: ['VAT', 'Shipping']\n",
      "🔄 Initial run: Processing July/August file NewEleven_Dashboard Products Group by ASIN_07_07_2025-07_07_2025_(02_18_54_289).xlsx\n",
      "📊 Processing: NewEleven_Dashboard Products Group by ASIN_07_07_2025-07_07_2025_(02_18_54_289).xlsx\n",
      "📋 Available columns: 19/21\n",
      "⚠️ Missing columns: ['VAT', 'Shipping']\n",
      "🔄 Initial run: Processing July/August file NewEleven_Dashboard Products Group by ASIN_08_07_2025-08_07_2025_(02_19_15_601).xlsx\n",
      "📊 Processing: NewEleven_Dashboard Products Group by ASIN_08_07_2025-08_07_2025_(02_19_15_601).xlsx\n",
      "📋 Available columns: 19/21\n",
      "⚠️ Missing columns: ['VAT', 'Shipping']\n",
      "🔄 Initial run: Processing July/August file NewEleven_Dashboard Products Group by ASIN_09_07_2025-09_07_2025_(02_19_35_777).xlsx\n",
      "📊 Processing: NewEleven_Dashboard Products Group by ASIN_09_07_2025-09_07_2025_(02_19_35_777).xlsx\n",
      "📋 Available columns: 19/21\n",
      "⚠️ Missing columns: ['VAT', 'Shipping']\n",
      "🔄 Initial run: Processing July/August file NewEleven_Dashboard Products Group by ASIN_10_07_2025-10_07_2025_(02_19_53_624).xlsx\n",
      "📊 Processing: NewEleven_Dashboard Products Group by ASIN_10_07_2025-10_07_2025_(02_19_53_624).xlsx\n",
      "📋 Available columns: 19/21\n",
      "⚠️ Missing columns: ['VAT', 'Shipping']\n",
      "🔄 Initial run: Processing July/August file NewEleven_Dashboard Products Group by ASIN_11_07_2025-11_07_2025_(02_20_12_322).xlsx\n",
      "📊 Processing: NewEleven_Dashboard Products Group by ASIN_11_07_2025-11_07_2025_(02_20_12_322).xlsx\n",
      "📋 Available columns: 19/21\n",
      "⚠️ Missing columns: ['VAT', 'Shipping']\n",
      "🔄 Initial run: Processing July/August file NewEleven_Dashboard Products Group by ASIN_12_07_2025-12_07_2025_(02_20_28_579).xlsx\n",
      "📊 Processing: NewEleven_Dashboard Products Group by ASIN_12_07_2025-12_07_2025_(02_20_28_579).xlsx\n",
      "📋 Available columns: 19/21\n",
      "⚠️ Missing columns: ['VAT', 'Shipping']\n",
      "🔄 Initial run: Processing July/August file NewEleven_Dashboard Products Group by ASIN_13_07_2025-13_07_2025_(02_20_45_881).xlsx\n",
      "📊 Processing: NewEleven_Dashboard Products Group by ASIN_13_07_2025-13_07_2025_(02_20_45_881).xlsx\n",
      "📋 Available columns: 19/21\n",
      "⚠️ Missing columns: ['VAT', 'Shipping']\n",
      "🔄 Initial run: Processing July/August file NewEleven_Dashboard Products Group by ASIN_14_07_2025-14_07_2025_(02_21_47_490).xlsx\n",
      "📊 Processing: NewEleven_Dashboard Products Group by ASIN_14_07_2025-14_07_2025_(02_21_47_490).xlsx\n",
      "📋 Available columns: 19/21\n",
      "⚠️ Missing columns: ['VAT', 'Shipping']\n",
      "🔄 Initial run: Processing July/August file NewEleven_Dashboard Products Group by ASIN_15_07_2025-15_07_2025_(02_22_09_416).xlsx\n",
      "📊 Processing: NewEleven_Dashboard Products Group by ASIN_15_07_2025-15_07_2025_(02_22_09_416).xlsx\n",
      "📋 Available columns: 19/21\n",
      "⚠️ Missing columns: ['VAT', 'Shipping']\n",
      "🔄 Initial run: Processing July/August file NewEleven_Dashboard Products Group by ASIN_16_07_2025-16_07_2025_(02_22_25_149).xlsx\n",
      "📊 Processing: NewEleven_Dashboard Products Group by ASIN_16_07_2025-16_07_2025_(02_22_25_149).xlsx\n",
      "📋 Available columns: 19/21\n",
      "⚠️ Missing columns: ['VAT', 'Shipping']\n",
      "🔄 Initial run: Processing July/August file NewEleven_Dashboard Products Group by ASIN_17_07_2025-17_07_2025_(02_22_44_477).xlsx\n",
      "📊 Processing: NewEleven_Dashboard Products Group by ASIN_17_07_2025-17_07_2025_(02_22_44_477).xlsx\n",
      "📋 Available columns: 19/21\n",
      "⚠️ Missing columns: ['VAT', 'Shipping']\n",
      "🔄 Initial run: Processing July/August file NewEleven_Dashboard Products Group by ASIN_18_07_2025-18_07_2025_(02_23_03_403).xlsx\n",
      "📊 Processing: NewEleven_Dashboard Products Group by ASIN_18_07_2025-18_07_2025_(02_23_03_403).xlsx\n",
      "📋 Available columns: 19/21\n",
      "⚠️ Missing columns: ['VAT', 'Shipping']\n",
      "🔄 Initial run: Processing July/August file NewEleven_Dashboard Products Group by ASIN_19_07_2025-19_07_2025_(02_23_28_630).xlsx\n",
      "📊 Processing: NewEleven_Dashboard Products Group by ASIN_19_07_2025-19_07_2025_(02_23_28_630).xlsx\n",
      "📋 Available columns: 19/21\n",
      "⚠️ Missing columns: ['VAT', 'Shipping']\n",
      "🔄 Initial run: Processing July/August file NewEleven_Dashboard Products Group by ASIN_20_07_2025-20_07_2025_(02_23_44_322).xlsx\n",
      "📊 Processing: NewEleven_Dashboard Products Group by ASIN_20_07_2025-20_07_2025_(02_23_44_322).xlsx\n",
      "📋 Available columns: 19/21\n",
      "⚠️ Missing columns: ['VAT', 'Shipping']\n",
      "🔄 Initial run: Processing July/August file NewEleven_Dashboard Products Group by ASIN_21_07_2025-21_07_2025_(02_24_36_725).xlsx\n",
      "📊 Processing: NewEleven_Dashboard Products Group by ASIN_21_07_2025-21_07_2025_(02_24_36_725).xlsx\n",
      "📋 Available columns: 19/21\n",
      "⚠️ Missing columns: ['VAT', 'Shipping']\n",
      "🔄 Initial run: Processing July/August file NewEleven_Dashboard Products Group by ASIN_22_07_2025-22_07_2025_(02_24_59_422).xlsx\n",
      "📊 Processing: NewEleven_Dashboard Products Group by ASIN_22_07_2025-22_07_2025_(02_24_59_422).xlsx\n",
      "📋 Available columns: 19/21\n",
      "⚠️ Missing columns: ['VAT', 'Shipping']\n",
      "🔄 Initial run: Processing July/August file NewEleven_Dashboard Products Group by ASIN_23_07_2025-23_07_2025_(02_25_27_489).xlsx\n",
      "📊 Processing: NewEleven_Dashboard Products Group by ASIN_23_07_2025-23_07_2025_(02_25_27_489).xlsx\n",
      "📋 Available columns: 19/21\n",
      "⚠️ Missing columns: ['VAT', 'Shipping']\n",
      "🔄 Initial run: Processing July/August file NewEleven_Dashboard Products Group by ASIN_24_07_2025-24_07_2025_(02_25_50_194).xlsx\n",
      "📊 Processing: NewEleven_Dashboard Products Group by ASIN_24_07_2025-24_07_2025_(02_25_50_194).xlsx\n",
      "📋 Available columns: 19/21\n",
      "⚠️ Missing columns: ['VAT', 'Shipping']\n",
      "🔄 Initial run: Processing July/August file NewEleven_Dashboard Products Group by ASIN_25_07_2025-25_07_2025_(02_26_07_983).xlsx\n",
      "📊 Processing: NewEleven_Dashboard Products Group by ASIN_25_07_2025-25_07_2025_(02_26_07_983).xlsx\n",
      "📋 Available columns: 19/21\n",
      "⚠️ Missing columns: ['VAT', 'Shipping']\n",
      "🔄 Initial run: Processing July/August file NewEleven_Dashboard Products Group by ASIN_26_07_2025-26_07_2025_(02_26_32_233).xlsx\n",
      "📊 Processing: NewEleven_Dashboard Products Group by ASIN_26_07_2025-26_07_2025_(02_26_32_233).xlsx\n",
      "📋 Available columns: 19/21\n",
      "⚠️ Missing columns: ['VAT', 'Shipping']\n",
      "🔄 Initial run: Processing July/August file NewEleven_Dashboard Products Group by ASIN_27_07_2025-27_07_2025_(02_27_09_575).xlsx\n",
      "📊 Processing: NewEleven_Dashboard Products Group by ASIN_27_07_2025-27_07_2025_(02_27_09_575).xlsx\n",
      "📋 Available columns: 19/21\n",
      "⚠️ Missing columns: ['VAT', 'Shipping']\n",
      "🔄 Initial run: Processing July/August file NewEleven_Dashboard Products Group by ASIN_28_07_2025-28_07_2025_(02_27_30_663).xlsx\n",
      "📊 Processing: NewEleven_Dashboard Products Group by ASIN_28_07_2025-28_07_2025_(02_27_30_663).xlsx\n",
      "📋 Available columns: 19/21\n",
      "⚠️ Missing columns: ['VAT', 'Shipping']\n",
      "🔄 Initial run: Processing July/August file NewEleven_Dashboard Products Group by ASIN_29_07_2025-29_07_2025_(02_27_54_576).xlsx\n",
      "📊 Processing: NewEleven_Dashboard Products Group by ASIN_29_07_2025-29_07_2025_(02_27_54_576).xlsx\n",
      "📋 Available columns: 19/21\n",
      "⚠️ Missing columns: ['VAT', 'Shipping']\n",
      "🔄 Initial run: Processing July/August file NewEleven_Dashboard Products Group by ASIN_30_07_2025-30_07_2025_(02_28_11_985).xlsx\n",
      "📊 Processing: NewEleven_Dashboard Products Group by ASIN_30_07_2025-30_07_2025_(02_28_11_985).xlsx\n",
      "📋 Available columns: 19/21\n",
      "⚠️ Missing columns: ['VAT', 'Shipping']\n",
      "🔄 Initial run: Processing July/August file NewEleven_Dashboard Products Group by ASIN_31_07_2025-31_07_2025_(02_28_40_743).xlsx\n",
      "📊 Processing: NewEleven_Dashboard Products Group by ASIN_31_07_2025-31_07_2025_(02_28_40_743).xlsx\n",
      "📋 Available columns: 19/21\n",
      "⚠️ Missing columns: ['VAT', 'Shipping']\n",
      "🔄 Initial run: Processing July/August file NewEleven_Dashboard Products Group by ASIN_01_08_2025-01_08_2025_(02_29_37_523).xlsx\n",
      "📊 Processing: NewEleven_Dashboard Products Group by ASIN_01_08_2025-01_08_2025_(02_29_37_523).xlsx\n",
      "📋 Available columns: 19/21\n",
      "⚠️ Missing columns: ['VAT', 'Shipping']\n",
      "🔄 Initial run: Processing July/August file NewEleven_Dashboard Products Group by ASIN_02_08_2025-02_08_2025_(02_31_39_571).xlsx\n",
      "📊 Processing: NewEleven_Dashboard Products Group by ASIN_02_08_2025-02_08_2025_(02_31_39_571).xlsx\n",
      "📋 Available columns: 19/21\n",
      "⚠️ Missing columns: ['VAT', 'Shipping']\n",
      "🔄 Initial run: Processing July/August file NewEleven_Dashboard Products Group by ASIN_03_08_2025-03_08_2025_(00_20_13_243).xlsx\n",
      "📊 Processing: NewEleven_Dashboard Products Group by ASIN_03_08_2025-03_08_2025_(00_20_13_243).xlsx\n",
      "📋 Available columns: 19/21\n",
      "⚠️ Missing columns: ['VAT', 'Shipping']\n",
      "🔄 Initial run: Processing July/August file NewEleven_Dashboard Products Group by ASIN_04_08_2025-04_08_2025_(00_20_42_850).xlsx\n",
      "📊 Processing: NewEleven_Dashboard Products Group by ASIN_04_08_2025-04_08_2025_(00_20_42_850).xlsx\n",
      "📋 Available columns: 19/21\n",
      "⚠️ Missing columns: ['VAT', 'Shipping']\n",
      "🔄 Initial run: Processing July/August file NewEleven_Dashboard Products Group by ASIN_05_08_2025-05_08_2025_(00_21_02_535).xlsx\n",
      "📊 Processing: NewEleven_Dashboard Products Group by ASIN_05_08_2025-05_08_2025_(00_21_02_535).xlsx\n",
      "📋 Available columns: 19/21\n",
      "⚠️ Missing columns: ['VAT', 'Shipping']\n",
      "🔄 Initial run: Processing July/August file NewEleven_Dashboard Products Group by ASIN_06_08_2025-06_08_2025_(01_58_45_358).xlsx\n",
      "📊 Processing: NewEleven_Dashboard Products Group by ASIN_06_08_2025-06_08_2025_(01_58_45_358).xlsx\n",
      "📋 Available columns: 19/21\n",
      "⚠️ Missing columns: ['VAT', 'Shipping']\n",
      "🔄 Initial run: Processing July/August file NewEleven_Dashboard Products Group by ASIN_07_08_2025-07_08_2025_(01_59_03_545).xlsx\n",
      "📊 Processing: NewEleven_Dashboard Products Group by ASIN_07_08_2025-07_08_2025_(01_59_03_545).xlsx\n",
      "📋 Available columns: 19/21\n",
      "⚠️ Missing columns: ['VAT', 'Shipping']\n",
      "🔄 Initial run: Processing July/August file NewEleven_Dashboard Products Group by ASIN_08_08_2025-08_08_2025_(00_21_58_982).xlsx\n",
      "📊 Processing: NewEleven_Dashboard Products Group by ASIN_08_08_2025-08_08_2025_(00_21_58_982).xlsx\n",
      "📋 Available columns: 19/21\n",
      "⚠️ Missing columns: ['VAT', 'Shipping']\n",
      "🔄 Initial run: Processing July/August file NewEleven_Dashboard Products Group by ASIN_09_08_2025-09_08_2025_(00_22_17_837).xlsx\n",
      "📊 Processing: NewEleven_Dashboard Products Group by ASIN_09_08_2025-09_08_2025_(00_22_17_837).xlsx\n",
      "📋 Available columns: 19/21\n",
      "⚠️ Missing columns: ['VAT', 'Shipping']\n",
      "🔄 Initial run: Processing July/August file NewEleven_Dashboard Products Group by ASIN_10_08_2025-10_08_2025_(00_22_32_925).xlsx\n",
      "📊 Processing: NewEleven_Dashboard Products Group by ASIN_10_08_2025-10_08_2025_(00_22_32_925).xlsx\n",
      "📋 Available columns: 19/21\n",
      "⚠️ Missing columns: ['VAT', 'Shipping']\n",
      "🔄 Initial run: Processing July/August file NewEleven_Dashboard Products Group by ASIN_11_08_2025-11_08_2025_(00_22_49_674).xlsx\n",
      "📊 Processing: NewEleven_Dashboard Products Group by ASIN_11_08_2025-11_08_2025_(00_22_49_674).xlsx\n",
      "📋 Available columns: 19/21\n",
      "⚠️ Missing columns: ['VAT', 'Shipping']\n",
      "🔄 Initial run: Processing July/August file NewEleven_Dashboard Products Group by ASIN_12_08_2025-12_08_2025_(00_23_06_346).xlsx\n",
      "📊 Processing: NewEleven_Dashboard Products Group by ASIN_12_08_2025-12_08_2025_(00_23_06_346).xlsx\n",
      "📋 Available columns: 19/21\n",
      "⚠️ Missing columns: ['VAT', 'Shipping']\n",
      "🔄 Initial run: Processing July/August file NewEleven_Dashboard Products Group by ASIN_13_08_2025-13_08_2025_(00_13_27_500).xlsx\n",
      "📊 Processing: NewEleven_Dashboard Products Group by ASIN_13_08_2025-13_08_2025_(00_13_27_500).xlsx\n",
      "📋 Available columns: 19/21\n",
      "⚠️ Missing columns: ['VAT', 'Shipping']\n",
      "🔄 Initial run: Processing July/August file NewEleven_Dashboard Products Group by ASIN_14_08_2025-14_08_2025_(00_14_12_537).xlsx\n",
      "📊 Processing: NewEleven_Dashboard Products Group by ASIN_14_08_2025-14_08_2025_(00_14_12_537).xlsx\n",
      "📋 Available columns: 19/21\n",
      "⚠️ Missing columns: ['VAT', 'Shipping']\n",
      "🔄 Initial run: Processing July/August file NewEleven_Dashboard Products Group by ASIN_15_08_2025-15_08_2025_(00_14_36_185).xlsx\n",
      "📊 Processing: NewEleven_Dashboard Products Group by ASIN_15_08_2025-15_08_2025_(00_14_36_185).xlsx\n",
      "📋 Available columns: 19/21\n",
      "⚠️ Missing columns: ['VAT', 'Shipping']\n",
      "🔄 Initial run: Processing July/August file NewEleven_Dashboard Products Group by ASIN_16_08_2025-16_08_2025_(00_15_01_117).xlsx\n",
      "📊 Processing: NewEleven_Dashboard Products Group by ASIN_16_08_2025-16_08_2025_(00_15_01_117).xlsx\n",
      "📋 Available columns: 19/21\n",
      "⚠️ Missing columns: ['VAT', 'Shipping']\n",
      "🔄 Initial run: Processing July/August file NewEleven_Dashboard Products Group by ASIN_17_08_2025-17_08_2025_(00_15_18_561).xlsx\n",
      "📊 Processing: NewEleven_Dashboard Products Group by ASIN_17_08_2025-17_08_2025_(00_15_18_561).xlsx\n",
      "📋 Available columns: 19/21\n",
      "⚠️ Missing columns: ['VAT', 'Shipping']\n",
      "🔄 Initial run: Processing July/August file NewEleven_Dashboard Products Group by ASIN_18_08_2025-18_08_2025_(00_15_40_811).xlsx\n",
      "📊 Processing: NewEleven_Dashboard Products Group by ASIN_18_08_2025-18_08_2025_(00_15_40_811).xlsx\n",
      "📋 Available columns: 19/21\n",
      "⚠️ Missing columns: ['VAT', 'Shipping']\n",
      "🔄 Initial run: Processing July/August file NewEleven_Dashboard Products Group by ASIN_19_08_2025-19_08_2025_(00_16_07_413).xlsx\n",
      "📊 Processing: NewEleven_Dashboard Products Group by ASIN_19_08_2025-19_08_2025_(00_16_07_413).xlsx\n",
      "📋 Available columns: 19/21\n",
      "⚠️ Missing columns: ['VAT', 'Shipping']\n",
      "🔄 Initial run: Processing July/August file NewEleven_Dashboard Products Group by ASIN_20_08_2025-20_08_2025_(00_16_29_901).xlsx\n",
      "📊 Processing: NewEleven_Dashboard Products Group by ASIN_20_08_2025-20_08_2025_(00_16_29_901).xlsx\n",
      "📋 Available columns: 19/21\n",
      "⚠️ Missing columns: ['VAT', 'Shipping']\n",
      "🔄 Initial run: Processing July/August file NewEleven_Dashboard Products Group by ASIN_21_08_2025-21_08_2025_(00_16_50_846).xlsx\n",
      "📊 Processing: NewEleven_Dashboard Products Group by ASIN_21_08_2025-21_08_2025_(00_16_50_846).xlsx\n",
      "📋 Available columns: 19/21\n",
      "⚠️ Missing columns: ['VAT', 'Shipping']\n",
      "🔄 Initial run: Processing July/August file NewEleven_Dashboard Products Group by ASIN_22_08_2025-22_08_2025_(00_16_03_351).xlsx\n",
      "📊 Processing: NewEleven_Dashboard Products Group by ASIN_22_08_2025-22_08_2025_(00_16_03_351).xlsx\n",
      "📋 Available columns: 19/21\n",
      "⚠️ Missing columns: ['VAT', 'Shipping']\n",
      "🔄 Initial run: Processing July/August file NewEleven_Dashboard Products Group by ASIN_23_08_2025-23_08_2025_(00_16_17_604).xlsx\n",
      "📊 Processing: NewEleven_Dashboard Products Group by ASIN_23_08_2025-23_08_2025_(00_16_17_604).xlsx\n",
      "📋 Available columns: 19/21\n",
      "⚠️ Missing columns: ['VAT', 'Shipping']\n",
      "🔄 Initial run: Processing July/August file NewEleven_Dashboard Products Group by ASIN_24_08_2025-24_08_2025_(00_16_33_979).xlsx\n",
      "📊 Processing: NewEleven_Dashboard Products Group by ASIN_24_08_2025-24_08_2025_(00_16_33_979).xlsx\n",
      "📋 Available columns: 19/21\n",
      "⚠️ Missing columns: ['VAT', 'Shipping']\n",
      "🔄 Initial run: Processing July/August file NewEleven_Dashboard Products Group by ASIN_25_08_2025-25_08_2025_(19_26_04_885).xlsx\n",
      "📊 Processing: NewEleven_Dashboard Products Group by ASIN_25_08_2025-25_08_2025_(19_26_04_885).xlsx\n",
      "📋 Available columns: 19/21\n",
      "⚠️ Missing columns: ['VAT', 'Shipping']\n",
      "🔄 Initial run: Processing July/August file NewEleven_Dashboard Products Group by ASIN_26_08_2025-26_08_2025_(19_40_55_532).xlsx\n",
      "📊 Processing: NewEleven_Dashboard Products Group by ASIN_26_08_2025-26_08_2025_(19_40_55_532).xlsx\n",
      "📋 Available columns: 19/21\n",
      "⚠️ Missing columns: ['VAT', 'Shipping']\n",
      "🔄 Initial run: Processing July/August file NewEleven_Dashboard Products Group by ASIN_27_08_2025-27_08_2025_(19_41_15_116).xlsx\n",
      "📊 Processing: NewEleven_Dashboard Products Group by ASIN_27_08_2025-27_08_2025_(19_41_15_116).xlsx\n",
      "📋 Available columns: 18/21\n",
      "⚠️ Missing columns: ['Sessions', 'VAT', 'Shipping']\n",
      "\n",
      "📈 Combining 58 dataframes...\n",
      "✅ Combined data shape: (13855, 21)\n",
      "📅 Date range: 2025-07-01 00:00:00 to 2025-08-27 00:00:00\n",
      "📤 Uploading to Google Sheets...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin1\\AppData\\Local\\Temp\\ipykernel_11996\\2388057400.py:237: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  master_df = pd.concat(all_dataframes, ignore_index=True, sort=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Successfully uploaded 13855 rows to Google Sheets\n",
      "🔗 Sheet: Raw_SB_H2_2025_US\n",
      "📋 Columns: Product, ASIN, Date, SKU, Units, Refunds, Sales, Promo, Ads, Sponsored products (PPC), % Refunds, Refund сost, Amazon fees, Cost of Goods, Gross profit, Net profit, Estimated payout, Real ACOS, Sessions, VAT, Shipping\n",
      "\n",
      "🎉 Successfully processed 58 files:\n",
      "   ✓ NewEleven_Dashboard Products Group by ASIN_01_07_2025-01_07_2025_(02_16_59_866).xlsx\n",
      "   ✓ NewEleven_Dashboard Products Group by ASIN_02_07_2025-02_07_2025_(02_17_19_401).xlsx\n",
      "   ✓ NewEleven_Dashboard Products Group by ASIN_03_07_2025-03_07_2025_(02_17_35_203).xlsx\n",
      "   ✓ NewEleven_Dashboard Products Group by ASIN_04_07_2025-04_07_2025_(02_17_52_472).xlsx\n",
      "   ✓ NewEleven_Dashboard Products Group by ASIN_05_07_2025-05_07_2025_(02_18_20_680).xlsx\n",
      "   ✓ NewEleven_Dashboard Products Group by ASIN_06_07_2025-06_07_2025_(02_18_35_117).xlsx\n",
      "   ✓ NewEleven_Dashboard Products Group by ASIN_07_07_2025-07_07_2025_(02_18_54_289).xlsx\n",
      "   ✓ NewEleven_Dashboard Products Group by ASIN_08_07_2025-08_07_2025_(02_19_15_601).xlsx\n",
      "   ✓ NewEleven_Dashboard Products Group by ASIN_09_07_2025-09_07_2025_(02_19_35_777).xlsx\n",
      "   ✓ NewEleven_Dashboard Products Group by ASIN_10_07_2025-10_07_2025_(02_19_53_624).xlsx\n",
      "   ✓ NewEleven_Dashboard Products Group by ASIN_11_07_2025-11_07_2025_(02_20_12_322).xlsx\n",
      "   ✓ NewEleven_Dashboard Products Group by ASIN_12_07_2025-12_07_2025_(02_20_28_579).xlsx\n",
      "   ✓ NewEleven_Dashboard Products Group by ASIN_13_07_2025-13_07_2025_(02_20_45_881).xlsx\n",
      "   ✓ NewEleven_Dashboard Products Group by ASIN_14_07_2025-14_07_2025_(02_21_47_490).xlsx\n",
      "   ✓ NewEleven_Dashboard Products Group by ASIN_15_07_2025-15_07_2025_(02_22_09_416).xlsx\n",
      "   ✓ NewEleven_Dashboard Products Group by ASIN_16_07_2025-16_07_2025_(02_22_25_149).xlsx\n",
      "   ✓ NewEleven_Dashboard Products Group by ASIN_17_07_2025-17_07_2025_(02_22_44_477).xlsx\n",
      "   ✓ NewEleven_Dashboard Products Group by ASIN_18_07_2025-18_07_2025_(02_23_03_403).xlsx\n",
      "   ✓ NewEleven_Dashboard Products Group by ASIN_19_07_2025-19_07_2025_(02_23_28_630).xlsx\n",
      "   ✓ NewEleven_Dashboard Products Group by ASIN_20_07_2025-20_07_2025_(02_23_44_322).xlsx\n",
      "   ✓ NewEleven_Dashboard Products Group by ASIN_21_07_2025-21_07_2025_(02_24_36_725).xlsx\n",
      "   ✓ NewEleven_Dashboard Products Group by ASIN_22_07_2025-22_07_2025_(02_24_59_422).xlsx\n",
      "   ✓ NewEleven_Dashboard Products Group by ASIN_23_07_2025-23_07_2025_(02_25_27_489).xlsx\n",
      "   ✓ NewEleven_Dashboard Products Group by ASIN_24_07_2025-24_07_2025_(02_25_50_194).xlsx\n",
      "   ✓ NewEleven_Dashboard Products Group by ASIN_25_07_2025-25_07_2025_(02_26_07_983).xlsx\n",
      "   ✓ NewEleven_Dashboard Products Group by ASIN_26_07_2025-26_07_2025_(02_26_32_233).xlsx\n",
      "   ✓ NewEleven_Dashboard Products Group by ASIN_27_07_2025-27_07_2025_(02_27_09_575).xlsx\n",
      "   ✓ NewEleven_Dashboard Products Group by ASIN_28_07_2025-28_07_2025_(02_27_30_663).xlsx\n",
      "   ✓ NewEleven_Dashboard Products Group by ASIN_29_07_2025-29_07_2025_(02_27_54_576).xlsx\n",
      "   ✓ NewEleven_Dashboard Products Group by ASIN_30_07_2025-30_07_2025_(02_28_11_985).xlsx\n",
      "   ✓ NewEleven_Dashboard Products Group by ASIN_31_07_2025-31_07_2025_(02_28_40_743).xlsx\n",
      "   ✓ NewEleven_Dashboard Products Group by ASIN_01_08_2025-01_08_2025_(02_29_37_523).xlsx\n",
      "   ✓ NewEleven_Dashboard Products Group by ASIN_02_08_2025-02_08_2025_(02_31_39_571).xlsx\n",
      "   ✓ NewEleven_Dashboard Products Group by ASIN_03_08_2025-03_08_2025_(00_20_13_243).xlsx\n",
      "   ✓ NewEleven_Dashboard Products Group by ASIN_04_08_2025-04_08_2025_(00_20_42_850).xlsx\n",
      "   ✓ NewEleven_Dashboard Products Group by ASIN_05_08_2025-05_08_2025_(00_21_02_535).xlsx\n",
      "   ✓ NewEleven_Dashboard Products Group by ASIN_06_08_2025-06_08_2025_(01_58_45_358).xlsx\n",
      "   ✓ NewEleven_Dashboard Products Group by ASIN_07_08_2025-07_08_2025_(01_59_03_545).xlsx\n",
      "   ✓ NewEleven_Dashboard Products Group by ASIN_08_08_2025-08_08_2025_(00_21_58_982).xlsx\n",
      "   ✓ NewEleven_Dashboard Products Group by ASIN_09_08_2025-09_08_2025_(00_22_17_837).xlsx\n",
      "   ✓ NewEleven_Dashboard Products Group by ASIN_10_08_2025-10_08_2025_(00_22_32_925).xlsx\n",
      "   ✓ NewEleven_Dashboard Products Group by ASIN_11_08_2025-11_08_2025_(00_22_49_674).xlsx\n",
      "   ✓ NewEleven_Dashboard Products Group by ASIN_12_08_2025-12_08_2025_(00_23_06_346).xlsx\n",
      "   ✓ NewEleven_Dashboard Products Group by ASIN_13_08_2025-13_08_2025_(00_13_27_500).xlsx\n",
      "   ✓ NewEleven_Dashboard Products Group by ASIN_14_08_2025-14_08_2025_(00_14_12_537).xlsx\n",
      "   ✓ NewEleven_Dashboard Products Group by ASIN_15_08_2025-15_08_2025_(00_14_36_185).xlsx\n",
      "   ✓ NewEleven_Dashboard Products Group by ASIN_16_08_2025-16_08_2025_(00_15_01_117).xlsx\n",
      "   ✓ NewEleven_Dashboard Products Group by ASIN_17_08_2025-17_08_2025_(00_15_18_561).xlsx\n",
      "   ✓ NewEleven_Dashboard Products Group by ASIN_18_08_2025-18_08_2025_(00_15_40_811).xlsx\n",
      "   ✓ NewEleven_Dashboard Products Group by ASIN_19_08_2025-19_08_2025_(00_16_07_413).xlsx\n",
      "   ✓ NewEleven_Dashboard Products Group by ASIN_20_08_2025-20_08_2025_(00_16_29_901).xlsx\n",
      "   ✓ NewEleven_Dashboard Products Group by ASIN_21_08_2025-21_08_2025_(00_16_50_846).xlsx\n",
      "   ✓ NewEleven_Dashboard Products Group by ASIN_22_08_2025-22_08_2025_(00_16_03_351).xlsx\n",
      "   ✓ NewEleven_Dashboard Products Group by ASIN_23_08_2025-23_08_2025_(00_16_17_604).xlsx\n",
      "   ✓ NewEleven_Dashboard Products Group by ASIN_24_08_2025-24_08_2025_(00_16_33_979).xlsx\n",
      "   ✓ NewEleven_Dashboard Products Group by ASIN_25_08_2025-25_08_2025_(19_26_04_885).xlsx\n",
      "   ✓ NewEleven_Dashboard Products Group by ASIN_26_08_2025-26_08_2025_(19_40_55_532).xlsx\n",
      "   ✓ NewEleven_Dashboard Products Group by ASIN_27_08_2025-27_08_2025_(19_41_15_116).xlsx\n",
      "\n",
      "📊 PROCESSING SUMMARY\n",
      "=====================\n",
      "July files: 31\n",
      "August files: 27\n",
      "Other files: 0\n",
      "Total files: 58\n",
      "Standard columns: 21\n",
      "Last run: 2025-08-28 16:42:41\n",
      "        \n",
      "\n",
      "📋 Standard columns (21):\n",
      "    1. Product\n",
      "    2. ASIN\n",
      "    3. Date\n",
      "    4. SKU\n",
      "    5. Units\n",
      "    6. Refunds\n",
      "    7. Sales\n",
      "    8. Promo\n",
      "    9. Ads\n",
      "   10. Sponsored products (PPC)\n",
      "   11. % Refunds\n",
      "   12. Refund сost\n",
      "   13. Amazon fees\n",
      "   14. Cost of Goods\n",
      "   15. Gross profit\n",
      "   16. Net profit\n",
      "   17. Estimated payout\n",
      "   18. Real ACOS\n",
      "   19. Sessions\n",
      "   20. VAT\n",
      "   21. Shipping\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import hashlib\n",
    "import re\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import gspread\n",
    "from google.oauth2.service_account import Credentials\n",
    "from gspread_dataframe import set_with_dataframe\n",
    "\n",
    "class SBDataProcessor:\n",
    "    def __init__(self, base_folder, credentials_path, sheet_id, worksheet_name):\n",
    "        self.base_folder = base_folder\n",
    "        self.credentials_path = credentials_path\n",
    "        self.sheet_id = sheet_id\n",
    "        self.worksheet_name = worksheet_name\n",
    "        self.metadata_file = \"sb_file_metadata.json\"\n",
    "        \n",
    "        # Định nghĩa thứ tự cột chuẩn\n",
    "        self.standard_columns = [\n",
    "            'Product', 'ASIN', 'Date', 'SKU', 'Units', 'Refunds', 'Sales', \n",
    "            'Promo', 'Ads', 'Sponsored products (PPC)', '% Refunds', 'Refund сost',\n",
    "            'Amazon fees', 'Cost of Goods', 'Gross profit', 'Net profit', \n",
    "            'Estimated payout', 'Real ACOS', 'Sessions', 'VAT', 'Shipping'\n",
    "        ]\n",
    "        \n",
    "        # Initialize Google Sheets\n",
    "        self._init_google_sheets()\n",
    "        \n",
    "        # Load existing metadata\n",
    "        self.file_metadata = self._load_metadata()\n",
    "        \n",
    "    def _init_google_sheets(self):\n",
    "        \"\"\"Initialize Google Sheets connection\"\"\"\n",
    "        scopes = [\"https://www.googleapis.com/auth/spreadsheets\", \n",
    "                  \"https://www.googleapis.com/auth/drive\"]\n",
    "        creds = Credentials.from_service_account_file(self.credentials_path, scopes=scopes)\n",
    "        self.client = gspread.authorize(creds)\n",
    "        self.spreadsheet = self.client.open_by_key(self.sheet_id)\n",
    "        self.worksheet = self.spreadsheet.worksheet(self.worksheet_name)\n",
    "    \n",
    "    def _load_metadata(self):\n",
    "        \"\"\"Load file metadata from JSON file\"\"\"\n",
    "        if os.path.exists(self.metadata_file):\n",
    "            with open(self.metadata_file, 'r', encoding='utf-8') as f:\n",
    "                return json.load(f)\n",
    "        return {}\n",
    "    \n",
    "    def _save_metadata(self):\n",
    "        \"\"\"Save file metadata to JSON file\"\"\"\n",
    "        with open(self.metadata_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(self.file_metadata, f, indent=2, ensure_ascii=False, default=str)\n",
    "    \n",
    "    def _get_file_hash(self, file_path):\n",
    "        \"\"\"Calculate file hash for change detection\"\"\"\n",
    "        hash_md5 = hashlib.md5()\n",
    "        with open(file_path, \"rb\") as f:\n",
    "            for chunk in iter(lambda: f.read(4096), b\"\"):\n",
    "                hash_md5.update(chunk)\n",
    "        return hash_md5.hexdigest()\n",
    "    \n",
    "    def extract_date_from_filename(self, filename):\n",
    "        \"\"\"Extract first DD_MM_YYYY pattern from filename\"\"\"\n",
    "        match = re.search(r\"(\\d{2}_\\d{2}_\\d{4})\", filename)\n",
    "        if match:\n",
    "            return datetime.strptime(match.group(1), \"%d_%m_%Y\").date()\n",
    "        return None\n",
    "    \n",
    "    def _standardize_columns(self, df):\n",
    "        \"\"\"Standardize and select only required columns\"\"\"\n",
    "        # Làm sạch tên cột\n",
    "        df.columns = [str(c).strip() for c in df.columns]\n",
    "        \n",
    "        # Tạo mapping cho các tên cột có thể khác nhau\n",
    "        column_mapping = {}\n",
    "        df_columns_lower = [col.lower() for col in df.columns]\n",
    "        \n",
    "        for std_col in self.standard_columns:\n",
    "            std_col_lower = std_col.lower()\n",
    "            \n",
    "            # Tìm cột khớp chính xác hoặc gần giống\n",
    "            for i, df_col in enumerate(df.columns):\n",
    "                df_col_lower = df_col.lower()\n",
    "                \n",
    "                # Khớp chính xác\n",
    "                if std_col_lower == df_col_lower:\n",
    "                    column_mapping[df_col] = std_col\n",
    "                    break\n",
    "                # Khớp một phần cho một số trường hợp đặc biệt\n",
    "                elif 'sponsored' in std_col_lower and 'sponsored' in df_col_lower and 'ppc' in df_col_lower:\n",
    "                    column_mapping[df_col] = std_col\n",
    "                    break\n",
    "                elif 'refund' in std_col_lower and 'cost' in std_col_lower and 'refund' in df_col_lower and ('cost' in df_col_lower or 'сost' in df_col_lower):\n",
    "                    column_mapping[df_col] = std_col\n",
    "                    break\n",
    "        \n",
    "        # Rename columns theo mapping\n",
    "        df = df.rename(columns=column_mapping)\n",
    "        \n",
    "        # Chỉ giữ lại các cột cần thiết\n",
    "        available_columns = [col for col in self.standard_columns if col in df.columns]\n",
    "        df_filtered = df[available_columns].copy()\n",
    "        \n",
    "        # Thêm các cột thiếu với giá trị None\n",
    "        for col in self.standard_columns:\n",
    "            if col not in df_filtered.columns:\n",
    "                df_filtered[col] = None\n",
    "        \n",
    "        # Sắp xếp lại theo thứ tự chuẩn\n",
    "        df_filtered = df_filtered[self.standard_columns]\n",
    "        \n",
    "        print(f\"📋 Available columns: {len(available_columns)}/{len(self.standard_columns)}\")\n",
    "        missing_cols = [col for col in self.standard_columns if col not in available_columns]\n",
    "        if missing_cols:\n",
    "            print(f\"⚠️ Missing columns: {missing_cols}\")\n",
    "        \n",
    "        return df_filtered\n",
    "    \n",
    "    def process_single_excel(self, file_path):\n",
    "        \"\"\"Process a single Excel file and return DataFrame with Date column\"\"\"\n",
    "        try:\n",
    "            df = pd.read_excel(file_path)\n",
    "            df = df.dropna(axis=1, how=\"all\")  \n",
    "            \n",
    "            # Extract date from filename\n",
    "            date_val = self.extract_date_from_filename(os.path.basename(file_path))\n",
    "            if date_val:\n",
    "                df[\"Date\"] = pd.to_datetime(date_val)\n",
    "            \n",
    "            # Standardize columns\n",
    "            df = self._standardize_columns(df)\n",
    "            \n",
    "            return df\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Error processing {file_path}: {e}\")\n",
    "            return pd.DataFrame()\n",
    "    \n",
    "    def _is_july_august_file(self, file_date):\n",
    "        \"\"\"Check if file belongs to July or August\"\"\"\n",
    "        if not file_date:\n",
    "            return False\n",
    "        return file_date.month in [7, 8] and file_date.year == 2025  # Adjust year as needed\n",
    "    \n",
    "    def _should_process_file(self, file_path, file_date, is_initial_run=False):\n",
    "        \"\"\"Determine if file should be processed\"\"\"\n",
    "        file_name = os.path.basename(file_path)\n",
    "        current_hash = self._get_file_hash(file_path)\n",
    "        modification_time = os.path.getmtime(file_path)\n",
    "        \n",
    "        # For initial run, process all July-August files\n",
    "        if is_initial_run:\n",
    "            if self._is_july_august_file(file_date):\n",
    "                print(f\"🔄 Initial run: Processing July/August file {file_name}\")\n",
    "                return True\n",
    "            return False\n",
    "        \n",
    "        # For subsequent runs, check if file is new or changed\n",
    "        if file_name not in self.file_metadata:\n",
    "            print(f\"➕ New file detected: {file_name}\")\n",
    "            return True\n",
    "        \n",
    "        stored_metadata = self.file_metadata[file_name]\n",
    "        \n",
    "        # Check if file has been modified (hash changed or modification time changed)\n",
    "        if (stored_metadata.get('hash') != current_hash or \n",
    "            stored_metadata.get('modification_time') != modification_time):\n",
    "            print(f\"🔄 Modified file detected: {file_name}\")\n",
    "            return True\n",
    "        \n",
    "        print(f\"⏭️ Skipping unchanged file: {file_name}\")\n",
    "        return False\n",
    "    \n",
    "    def _update_file_metadata(self, file_path, file_date):\n",
    "        \"\"\"Update metadata for processed file\"\"\"\n",
    "        file_name = os.path.basename(file_path)\n",
    "        self.file_metadata[file_name] = {\n",
    "            'path': file_path,\n",
    "            'date': file_date,\n",
    "            'hash': self._get_file_hash(file_path),\n",
    "            'modification_time': os.path.getmtime(file_path),\n",
    "            'processed_at': datetime.now()\n",
    "        }\n",
    "    \n",
    "    def process_files(self, initial_run=False):\n",
    "        \"\"\"\n",
    "        Main processing function\n",
    "        Args:\n",
    "            initial_run (bool): If True, reprocess all July-August files from scratch\n",
    "        \"\"\"\n",
    "        print(\"=\" * 60)\n",
    "        if initial_run:\n",
    "            print(\"🚀 INITIAL RUN: Processing all July-August files\")\n",
    "            # Clear existing July-August metadata for fresh start\n",
    "            files_to_remove = []\n",
    "            for file_name, metadata in self.file_metadata.items():\n",
    "                if isinstance(metadata.get('date'), str):\n",
    "                    file_date = datetime.strptime(metadata['date'], \"%Y-%m-%d\").date()\n",
    "                elif metadata.get('date'):\n",
    "                    file_date = metadata['date']\n",
    "                else:\n",
    "                    continue\n",
    "                    \n",
    "                if self._is_july_august_file(file_date):\n",
    "                    files_to_remove.append(file_name)\n",
    "            \n",
    "            for file_name in files_to_remove:\n",
    "                del self.file_metadata[file_name]\n",
    "                print(f\"🗑️ Cleared metadata for July/August file: {file_name}\")\n",
    "        else:\n",
    "            print(\"🔄 INCREMENTAL RUN: Processing new/modified files only\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        all_dataframes = []\n",
    "        processed_files = []\n",
    "        \n",
    "        # Scan all Excel files in subfolders\n",
    "        for root, dirs, files in os.walk(self.base_folder):\n",
    "            for file in files:\n",
    "                if file.endswith(\".xlsx\"):\n",
    "                    file_path = os.path.join(root, file)\n",
    "                    file_date = self.extract_date_from_filename(file)\n",
    "                    \n",
    "                    if self._should_process_file(file_path, file_date, initial_run):\n",
    "                        print(f\"📊 Processing: {file}\")\n",
    "                        df = self.process_single_excel(file_path)\n",
    "                        \n",
    "                        if not df.empty:\n",
    "                            all_dataframes.append(df)\n",
    "                            processed_files.append(file)\n",
    "                            self._update_file_metadata(file_path, file_date)\n",
    "                        else:\n",
    "                            print(f\"⚠️ Empty dataframe for: {file}\")\n",
    "        \n",
    "        # Combine all processed data\n",
    "        if all_dataframes:\n",
    "            print(f\"\\n📈 Combining {len(all_dataframes)} dataframes...\")\n",
    "            master_df = pd.concat(all_dataframes, ignore_index=True, sort=False)\n",
    "            \n",
    "            # Sort by date, then by sales (descending)\n",
    "            if \"Date\" in master_df.columns and \"Sales\" in master_df.columns:\n",
    "                master_df = master_df.sort_values([\"Date\", \"Sales\"], ascending=[True, False])\n",
    "            elif \"Date\" in master_df.columns:\n",
    "                master_df = master_df.sort_values(\"Date\", ascending=True)\n",
    "            \n",
    "            print(f\"✅ Combined data shape: {master_df.shape}\")\n",
    "            if \"Date\" in master_df.columns:\n",
    "                print(f\"📅 Date range: {master_df['Date'].min()} to {master_df['Date'].max()}\")\n",
    "            \n",
    "            # Upload to Google Sheets\n",
    "            self._upload_to_sheets(master_df)\n",
    "            \n",
    "            # Save metadata\n",
    "            self._save_metadata()\n",
    "            \n",
    "            print(f\"\\n🎉 Successfully processed {len(processed_files)} files:\")\n",
    "            for file in processed_files:\n",
    "                print(f\"   ✓ {file}\")\n",
    "            \n",
    "            return master_df\n",
    "        else:\n",
    "            print(\"ℹ️ No files to process.\")\n",
    "            return pd.DataFrame()\n",
    "    \n",
    "    def _upload_to_sheets(self, df):\n",
    "        \"\"\"Upload DataFrame to Google Sheets\"\"\"\n",
    "        try:\n",
    "            print(\"📤 Uploading to Google Sheets...\")\n",
    "            \n",
    "            # Clear existing data (columns A to U to match our 21 standard columns)\n",
    "            self.worksheet.batch_clear(['A:U'])\n",
    "            \n",
    "            # Upload new data\n",
    "            set_with_dataframe(self.worksheet, df)\n",
    "            \n",
    "            print(f\"✅ Successfully uploaded {len(df)} rows to Google Sheets\")\n",
    "            print(f\"🔗 Sheet: {self.worksheet_name}\")\n",
    "            print(f\"📋 Columns: {', '.join(self.standard_columns)}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error uploading to Google Sheets: {e}\")\n",
    "    \n",
    "    def get_processing_summary(self):\n",
    "        \"\"\"Get summary of processed files\"\"\"\n",
    "        if not self.file_metadata:\n",
    "            return \"No files processed yet.\"\n",
    "        \n",
    "        july_files = []\n",
    "        august_files = []\n",
    "        other_files = []\n",
    "        \n",
    "        for file_name, metadata in self.file_metadata.items():\n",
    "            if isinstance(metadata.get('date'), str):\n",
    "                file_date = datetime.strptime(metadata['date'], \"%Y-%m-%d\").date()\n",
    "            elif metadata.get('date'):\n",
    "                file_date = metadata['date']\n",
    "            else:\n",
    "                other_files.append(file_name)\n",
    "                continue\n",
    "            \n",
    "            if file_date.month == 7:\n",
    "                july_files.append(file_name)\n",
    "            elif file_date.month == 8:\n",
    "                august_files.append(file_name)\n",
    "            else:\n",
    "                other_files.append(file_name)\n",
    "        \n",
    "        summary = f\"\"\"\n",
    "📊 PROCESSING SUMMARY\n",
    "=====================\n",
    "July files: {len(july_files)}\n",
    "August files: {len(august_files)}\n",
    "Other files: {len(other_files)}\n",
    "Total files: {len(self.file_metadata)}\n",
    "Standard columns: {len(self.standard_columns)}\n",
    "Last run: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "        \"\"\"\n",
    "        return summary\n",
    "\n",
    "# Usage Example\n",
    "if __name__ == \"__main__\":\n",
    "    # Configuration\n",
    "    config = {\n",
    "        'base_folder': \"C:/Users/admin1/Desktop/Performance-Tracking/Agg-SB/H2_2025_US\",\n",
    "        'credentials_path': \"c:/Users/admin1/Downloads/new_credential.json\",\n",
    "        'sheet_id': \"1lZ4dsi94HaeWshsEizKTyNHeOOG0tpLJhzL9pMxvd6k\",\n",
    "        'worksheet_name': \"Raw_SB_H2_2025_US\"\n",
    "    }\n",
    "    \n",
    "    # Initialize processor\n",
    "    processor = SBDataProcessor(**config)\n",
    "    \n",
    "    # First time: Run with initial_run=True to reprocess all July-August files\n",
    "    print(\"Choose run mode:\")\n",
    "    print(\"1. Initial run (reprocess all July-August files)\")\n",
    "    print(\"2. Incremental run (process only new/modified files)\")\n",
    "    \n",
    "    choice = input(\"Enter choice (1 or 2): \").strip()\n",
    "    \n",
    "    if choice == \"1\":\n",
    "        result_df = processor.process_files(initial_run=True)\n",
    "    else:\n",
    "        result_df = processor.process_files(initial_run=False)\n",
    "    \n",
    "    # Print summary\n",
    "    print(processor.get_processing_summary())\n",
    "    \n",
    "    # Show column info\n",
    "    print(f\"\\n📋 Standard columns ({len(processor.standard_columns)}):\")\n",
    "    for i, col in enumerate(processor.standard_columns, 1):\n",
    "        print(f\"   {i:2d}. {col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eedbdb7",
   "metadata": {},
   "source": [
    "# XNurta H2 2024 (Daily)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f100f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose run mode for XNurta 2024 Q3 data:\n",
      "1. Initial run (reprocess all Q3 2024 files: Jul-Sep)\n",
      "2. Incremental run (process only new/modified files)\n",
      "============================================================\n",
      "🚀 INITIAL RUN: Processing Q3 2024 XNurta files (Jul-Sep)\n",
      "🗑️ Cleared metadata for Q3 2024 file: SA_Campaign_List_20240701_20240701_38C2RG.xlsx\n",
      "🗑️ Cleared metadata for Q3 2024 file: SA_Campaign_List_20240702_20240702_9TkpbM.xlsx\n",
      "🗑️ Cleared metadata for Q3 2024 file: SA_Campaign_List_20240703_20240703_G80TRn.xlsx\n",
      "🗑️ Cleared metadata for Q3 2024 file: SA_Campaign_List_20240704_20240704_gZtCIL.xlsx\n",
      "🗑️ Cleared metadata for Q3 2024 file: SA_Campaign_List_20240705_20240705_A1i8Dn.xlsx\n",
      "🗑️ Cleared metadata for Q3 2024 file: SA_Campaign_List_20240706_20240706_ed4ep2.xlsx\n",
      "🗑️ Cleared metadata for Q3 2024 file: SA_Campaign_List_20240707_20240707_1nbAjc.xlsx\n",
      "🗑️ Cleared metadata for Q3 2024 file: SA_Campaign_List_20240708_20240708_nSsf7X.xlsx\n",
      "🗑️ Cleared metadata for Q3 2024 file: SA_Campaign_List_20240709_20240709_Sa3Pwo.xlsx\n",
      "🗑️ Cleared metadata for Q3 2024 file: SA_Campaign_List_20240710_20240710_NBUR0e.xlsx\n",
      "🗑️ Cleared metadata for Q3 2024 file: SA_Campaign_List_20240711_20240711_5zfUcS.xlsx\n",
      "🗑️ Cleared metadata for Q3 2024 file: SA_Campaign_List_20240712_20240712_Rd20hJ.xlsx\n",
      "🗑️ Cleared metadata for Q3 2024 file: SA_Campaign_List_20240713_20240713_z6wmov.xlsx\n",
      "🗑️ Cleared metadata for Q3 2024 file: SA_Campaign_List_20240714_20240714_gkwAAt.xlsx\n",
      "🗑️ Cleared metadata for Q3 2024 file: SA_Campaign_List_20240715_20240715_EB6eR5.xlsx\n",
      "🗑️ Cleared metadata for Q3 2024 file: SA_Campaign_List_20240716_20240716_X7QEk3.xlsx\n",
      "🗑️ Cleared metadata for Q3 2024 file: SA_Campaign_List_20240717_20240717_238iuR.xlsx\n",
      "🗑️ Cleared metadata for Q3 2024 file: SA_Campaign_List_20240718_20240718_jCLFfO.xlsx\n",
      "🗑️ Cleared metadata for Q3 2024 file: SA_Campaign_List_20240719_20240719_mgEWBW.xlsx\n",
      "🗑️ Cleared metadata for Q3 2024 file: SA_Campaign_List_20240720_20240720_D61x3E.xlsx\n",
      "🗑️ Cleared metadata for Q3 2024 file: SA_Campaign_List_20240721_20240721_Y9D7Br.xlsx\n",
      "🗑️ Cleared metadata for Q3 2024 file: SA_Campaign_List_20240722_20240722_WzjMZL.xlsx\n",
      "🗑️ Cleared metadata for Q3 2024 file: SA_Campaign_List_20240723_20240723_AQERzQ.xlsx\n",
      "🗑️ Cleared metadata for Q3 2024 file: SA_Campaign_List_20240724_20240724_vsoX3D.xlsx\n",
      "🗑️ Cleared metadata for Q3 2024 file: SA_Campaign_List_20240725_20240725_fdrCVt.xlsx\n",
      "🗑️ Cleared metadata for Q3 2024 file: SA_Campaign_List_20240726_20240726_yl0GwV.xlsx\n",
      "🗑️ Cleared metadata for Q3 2024 file: SA_Campaign_List_20240727_20240727_oUaGYh.xlsx\n",
      "🗑️ Cleared metadata for Q3 2024 file: SA_Campaign_List_20240728_20240728_JA2MmE.xlsx\n",
      "🗑️ Cleared metadata for Q3 2024 file: SA_Campaign_List_20240729_20240729_nccfO7.xlsx\n",
      "🗑️ Cleared metadata for Q3 2024 file: SA_Campaign_List_20240730_20240730_snFC0I.xlsx\n",
      "🗑️ Cleared metadata for Q3 2024 file: SA_Campaign_List_20240731_20240731_7gjPuv.xlsx\n",
      "🗑️ Cleared metadata for Q3 2024 file: SA_Campaign_List_20240801_20240801_THl8uh.xlsx\n",
      "🗑️ Cleared metadata for Q3 2024 file: SA_Campaign_List_20240802_20240802_Q1JEsN.xlsx\n",
      "🗑️ Cleared metadata for Q3 2024 file: SA_Campaign_List_20240803_20240803_syIZ3O.xlsx\n",
      "🗑️ Cleared metadata for Q3 2024 file: SA_Campaign_List_20240804_20240804_H2wN6Y.xlsx\n",
      "🗑️ Cleared metadata for Q3 2024 file: SA_Campaign_List_20240805_20240805_A3oC8p.xlsx\n",
      "🗑️ Cleared metadata for Q3 2024 file: SA_Campaign_List_20240806_20240806_tMyfQk.xlsx\n",
      "🗑️ Cleared metadata for Q3 2024 file: SA_Campaign_List_20240807_20240807_pvwPyI.xlsx\n",
      "🗑️ Cleared metadata for Q3 2024 file: SA_Campaign_List_20240808_20240808_iBVkTq (1).xlsx\n",
      "🗑️ Cleared metadata for Q3 2024 file: SA_Campaign_List_20240809_20240809_leqaeZ.xlsx\n",
      "🗑️ Cleared metadata for Q3 2024 file: SA_Campaign_List_20240810_20240810_yhgNkX.xlsx\n",
      "🗑️ Cleared metadata for Q3 2024 file: SA_Campaign_List_20240811_20240811_QtBpvM.xlsx\n",
      "🗑️ Cleared metadata for Q3 2024 file: SA_Campaign_List_20240812_20240812_JCmF4k.xlsx\n",
      "🗑️ Cleared metadata for Q3 2024 file: SA_Campaign_List_20240813_20240813_wEXK61.xlsx\n",
      "🗑️ Cleared metadata for Q3 2024 file: SA_Campaign_List_20240814_20240814_oXNFzb.xlsx\n",
      "🗑️ Cleared metadata for Q3 2024 file: SA_Campaign_List_20240815_20240815_jYtq9X.xlsx\n",
      "🗑️ Cleared metadata for Q3 2024 file: SA_Campaign_List_20240816_20240816_XV74Ue.xlsx\n",
      "🗑️ Cleared metadata for Q3 2024 file: SA_Campaign_List_20240817_20240817_dhbN8X.xlsx\n",
      "🗑️ Cleared metadata for Q3 2024 file: SA_Campaign_List_20240818_20240818_cVE3M2.xlsx\n",
      "🗑️ Cleared metadata for Q3 2024 file: SA_Campaign_List_20240819_20240819_xlZUuH.xlsx\n",
      "🗑️ Cleared metadata for Q3 2024 file: SA_Campaign_List_20240820_20240820_Cgxnji.xlsx\n",
      "🗑️ Cleared metadata for Q3 2024 file: SA_Campaign_List_20240821_20240821_X2DaaD.xlsx\n",
      "🗑️ Cleared metadata for Q3 2024 file: SA_Campaign_List_20240822_20240822_KNfyGC.xlsx\n",
      "🗑️ Cleared metadata for Q3 2024 file: SA_Campaign_List_20240823_20240823_xgc6an.xlsx\n",
      "🗑️ Cleared metadata for Q3 2024 file: SA_Campaign_List_20240824_20240824_zkQ8SX.xlsx\n",
      "🗑️ Cleared metadata for Q3 2024 file: SA_Campaign_List_20240825_20240825_JXZ5CR.xlsx\n",
      "🗑️ Cleared metadata for Q3 2024 file: SA_Campaign_List_20240826_20240826_j46ClA.xlsx\n",
      "🗑️ Cleared metadata for Q3 2024 file: SA_Campaign_List_20240827_20240827_yD1KBc.xlsx\n",
      "🗑️ Cleared metadata for Q3 2024 file: SA_Campaign_List_20240828_20240828_FKLiIq.xlsx\n",
      "🗑️ Cleared metadata for Q3 2024 file: SA_Campaign_List_20240829_20240829_qBu7M1.xlsx\n",
      "🗑️ Cleared metadata for Q3 2024 file: SA_Campaign_List_20240830_20240830_ZqG2zh.xlsx\n",
      "🗑️ Cleared metadata for Q3 2024 file: SA_Campaign_List_20240831_20240831_sBrJAN.xlsx\n",
      "🗑️ Cleared metadata for Q3 2024 file: SA_Campaign_List_20240901_20240901_3JsLtM.xlsx\n",
      "🗑️ Cleared metadata for Q3 2024 file: SA_Campaign_List_20240902_20240902_cG3CFE.xlsx\n",
      "🗑️ Cleared metadata for Q3 2024 file: SA_Campaign_List_20240903_20240903_GZDx0M.xlsx\n",
      "🗑️ Cleared metadata for Q3 2024 file: SA_Campaign_List_20240904_20240904_rIkwF3.xlsx\n",
      "🗑️ Cleared metadata for Q3 2024 file: SA_Campaign_List_20240905_20240905_Otkihv.xlsx\n",
      "🗑️ Cleared metadata for Q3 2024 file: SA_Campaign_List_20240906_20240906_6P7Fxn.xlsx\n",
      "🗑️ Cleared metadata for Q3 2024 file: SA_Campaign_List_20240907_20240907_SgpIZ2.xlsx\n",
      "🗑️ Cleared metadata for Q3 2024 file: SA_Campaign_List_20240908_20240908_74oHrV.xlsx\n",
      "🗑️ Cleared metadata for Q3 2024 file: SA_Campaign_List_20240909_20240909_5EBgFV.xlsx\n",
      "🗑️ Cleared metadata for Q3 2024 file: SA_Campaign_List_20240910_20240910_L1awWn.xlsx\n",
      "🗑️ Cleared metadata for Q3 2024 file: SA_Campaign_List_20240911_20240911_W5poXg.xlsx\n",
      "🗑️ Cleared metadata for Q3 2024 file: SA_Campaign_List_20240912_20240912_0qtkeO.xlsx\n",
      "🗑️ Cleared metadata for Q3 2024 file: SA_Campaign_List_20240913_20240913_E1WdFc.xlsx\n",
      "🗑️ Cleared metadata for Q3 2024 file: SA_Campaign_List_20240914_20240914_YxYNAn.xlsx\n",
      "🗑️ Cleared metadata for Q3 2024 file: SA_Campaign_List_20240915_20240915_W7CMIj.xlsx\n",
      "🗑️ Cleared metadata for Q3 2024 file: SA_Campaign_List_20240916_20240916_DOofR0.xlsx\n",
      "🗑️ Cleared metadata for Q3 2024 file: SA_Campaign_List_20240917_20240917_2vgqpt.xlsx\n",
      "🗑️ Cleared metadata for Q3 2024 file: SA_Campaign_List_20240918_20240918_J8z1kr.xlsx\n",
      "🗑️ Cleared metadata for Q3 2024 file: SA_Campaign_List_20240919_20240919_8jFTcp.xlsx\n",
      "🗑️ Cleared metadata for Q3 2024 file: SA_Campaign_List_20240920_20240920_4cmtsa.xlsx\n",
      "🗑️ Cleared metadata for Q3 2024 file: SA_Campaign_List_20240921_20240921_es3nT6.xlsx\n",
      "🗑️ Cleared metadata for Q3 2024 file: SA_Campaign_List_20240922_20240922_0AkxFc.xlsx\n",
      "🗑️ Cleared metadata for Q3 2024 file: SA_Campaign_List_20240923_20240923_wuLXAt.xlsx\n",
      "🗑️ Cleared metadata for Q3 2024 file: SA_Campaign_List_20240924_20240924_Bi9snd.xlsx\n",
      "🗑️ Cleared metadata for Q3 2024 file: SA_Campaign_List_20240925_20240925_OGRl2a.xlsx\n",
      "🗑️ Cleared metadata for Q3 2024 file: SA_Campaign_List_20240926_20240926_snbQG0.xlsx\n",
      "🗑️ Cleared metadata for Q3 2024 file: SA_Campaign_List_20240927_20240927_KJf43V.xlsx\n",
      "🗑️ Cleared metadata for Q3 2024 file: SA_Campaign_List_20240928_20240928_e1R8gN.xlsx\n",
      "🗑️ Cleared metadata for Q3 2024 file: SA_Campaign_List_20240929_20240929_f8Zkxo.xlsx\n",
      "🗑️ Cleared metadata for Q3 2024 file: SA_Campaign_List_20240930_20240930_GbPddt.xlsx\n",
      "============================================================\n",
      "🔄 Initial run: Processing Q3 2024 file SA_Campaign_List_20240701_20240701_38C2RG.xlsx\n",
      "📊 Processing: SA_Campaign_List_20240701_20240701_38C2RG.xlsx\n",
      "   🗑️ Dropped columns: Profile, Labels, Budget group, Status, Current Budget, SP Off-site Ads Strategy, Bidding Strategy\n",
      "✅ Successfully processed: SA_Campaign_List_20240701_20240701_38C2RG.xlsx\n",
      "🔄 Initial run: Processing Q3 2024 file SA_Campaign_List_20240702_20240702_9TkpbM.xlsx\n",
      "📊 Processing: SA_Campaign_List_20240702_20240702_9TkpbM.xlsx\n",
      "   🗑️ Dropped columns: Profile, Labels, Budget group, Status, Current Budget, SP Off-site Ads Strategy, Bidding Strategy\n",
      "✅ Successfully processed: SA_Campaign_List_20240702_20240702_9TkpbM.xlsx\n",
      "🔄 Initial run: Processing Q3 2024 file SA_Campaign_List_20240703_20240703_G80TRn.xlsx\n",
      "📊 Processing: SA_Campaign_List_20240703_20240703_G80TRn.xlsx\n",
      "   🗑️ Dropped columns: Profile, Labels, Budget group, Status, Current Budget, SP Off-site Ads Strategy, Bidding Strategy\n",
      "✅ Successfully processed: SA_Campaign_List_20240703_20240703_G80TRn.xlsx\n",
      "🔄 Initial run: Processing Q3 2024 file SA_Campaign_List_20240704_20240704_gZtCIL.xlsx\n",
      "📊 Processing: SA_Campaign_List_20240704_20240704_gZtCIL.xlsx\n",
      "   🗑️ Dropped columns: Profile, Labels, Budget group, Status, Current Budget, SP Off-site Ads Strategy, Bidding Strategy\n",
      "✅ Successfully processed: SA_Campaign_List_20240704_20240704_gZtCIL.xlsx\n",
      "🔄 Initial run: Processing Q3 2024 file SA_Campaign_List_20240705_20240705_A1i8Dn.xlsx\n",
      "📊 Processing: SA_Campaign_List_20240705_20240705_A1i8Dn.xlsx\n",
      "   🗑️ Dropped columns: Profile, Labels, Budget group, Status, Current Budget, SP Off-site Ads Strategy, Bidding Strategy\n",
      "✅ Successfully processed: SA_Campaign_List_20240705_20240705_A1i8Dn.xlsx\n",
      "🔄 Initial run: Processing Q3 2024 file SA_Campaign_List_20240706_20240706_ed4ep2.xlsx\n",
      "📊 Processing: SA_Campaign_List_20240706_20240706_ed4ep2.xlsx\n",
      "   🗑️ Dropped columns: Profile, Labels, Budget group, Status, Current Budget, SP Off-site Ads Strategy, Bidding Strategy\n",
      "✅ Successfully processed: SA_Campaign_List_20240706_20240706_ed4ep2.xlsx\n",
      "🔄 Initial run: Processing Q3 2024 file SA_Campaign_List_20240707_20240707_1nbAjc.xlsx\n",
      "📊 Processing: SA_Campaign_List_20240707_20240707_1nbAjc.xlsx\n",
      "   🗑️ Dropped columns: Profile, Labels, Budget group, Status, Current Budget, SP Off-site Ads Strategy, Bidding Strategy\n",
      "✅ Successfully processed: SA_Campaign_List_20240707_20240707_1nbAjc.xlsx\n",
      "🔄 Initial run: Processing Q3 2024 file SA_Campaign_List_20240708_20240708_nSsf7X.xlsx\n",
      "📊 Processing: SA_Campaign_List_20240708_20240708_nSsf7X.xlsx\n",
      "   🗑️ Dropped columns: Profile, Labels, Budget group, Status, Current Budget, SP Off-site Ads Strategy, Bidding Strategy\n",
      "✅ Successfully processed: SA_Campaign_List_20240708_20240708_nSsf7X.xlsx\n",
      "🔄 Initial run: Processing Q3 2024 file SA_Campaign_List_20240709_20240709_Sa3Pwo.xlsx\n",
      "📊 Processing: SA_Campaign_List_20240709_20240709_Sa3Pwo.xlsx\n",
      "   🗑️ Dropped columns: Profile, Labels, Budget group, Status, Current Budget, SP Off-site Ads Strategy, Bidding Strategy\n",
      "✅ Successfully processed: SA_Campaign_List_20240709_20240709_Sa3Pwo.xlsx\n",
      "🔄 Initial run: Processing Q3 2024 file SA_Campaign_List_20240710_20240710_NBUR0e.xlsx\n",
      "📊 Processing: SA_Campaign_List_20240710_20240710_NBUR0e.xlsx\n",
      "   🗑️ Dropped columns: Profile, Labels, Budget group, Status, Current Budget, SP Off-site Ads Strategy, Bidding Strategy\n",
      "✅ Successfully processed: SA_Campaign_List_20240710_20240710_NBUR0e.xlsx\n",
      "🔄 Initial run: Processing Q3 2024 file SA_Campaign_List_20240711_20240711_5zfUcS.xlsx\n",
      "📊 Processing: SA_Campaign_List_20240711_20240711_5zfUcS.xlsx\n",
      "   🗑️ Dropped columns: Profile, Labels, Budget group, Status, Current Budget, SP Off-site Ads Strategy, Bidding Strategy\n",
      "✅ Successfully processed: SA_Campaign_List_20240711_20240711_5zfUcS.xlsx\n",
      "🔄 Initial run: Processing Q3 2024 file SA_Campaign_List_20240712_20240712_Rd20hJ.xlsx\n",
      "📊 Processing: SA_Campaign_List_20240712_20240712_Rd20hJ.xlsx\n",
      "   🗑️ Dropped columns: Profile, Labels, Budget group, Status, Current Budget, SP Off-site Ads Strategy, Bidding Strategy\n",
      "✅ Successfully processed: SA_Campaign_List_20240712_20240712_Rd20hJ.xlsx\n",
      "🔄 Initial run: Processing Q3 2024 file SA_Campaign_List_20240713_20240713_z6wmov.xlsx\n",
      "📊 Processing: SA_Campaign_List_20240713_20240713_z6wmov.xlsx\n",
      "   🗑️ Dropped columns: Profile, Labels, Budget group, Status, Current Budget, SP Off-site Ads Strategy, Bidding Strategy\n",
      "✅ Successfully processed: SA_Campaign_List_20240713_20240713_z6wmov.xlsx\n",
      "🔄 Initial run: Processing Q3 2024 file SA_Campaign_List_20240714_20240714_gkwAAt.xlsx\n",
      "📊 Processing: SA_Campaign_List_20240714_20240714_gkwAAt.xlsx\n",
      "   🗑️ Dropped columns: Profile, Labels, Budget group, Status, Current Budget, SP Off-site Ads Strategy, Bidding Strategy\n",
      "✅ Successfully processed: SA_Campaign_List_20240714_20240714_gkwAAt.xlsx\n",
      "🔄 Initial run: Processing Q3 2024 file SA_Campaign_List_20240715_20240715_EB6eR5.xlsx\n",
      "📊 Processing: SA_Campaign_List_20240715_20240715_EB6eR5.xlsx\n",
      "   🗑️ Dropped columns: Profile, Labels, Budget group, Status, Current Budget, SP Off-site Ads Strategy, Bidding Strategy\n",
      "✅ Successfully processed: SA_Campaign_List_20240715_20240715_EB6eR5.xlsx\n",
      "🔄 Initial run: Processing Q3 2024 file SA_Campaign_List_20240716_20240716_X7QEk3.xlsx\n",
      "📊 Processing: SA_Campaign_List_20240716_20240716_X7QEk3.xlsx\n",
      "   🗑️ Dropped columns: Profile, Labels, Budget group, Status, Current Budget, SP Off-site Ads Strategy, Bidding Strategy\n",
      "✅ Successfully processed: SA_Campaign_List_20240716_20240716_X7QEk3.xlsx\n",
      "🔄 Initial run: Processing Q3 2024 file SA_Campaign_List_20240717_20240717_238iuR.xlsx\n",
      "📊 Processing: SA_Campaign_List_20240717_20240717_238iuR.xlsx\n",
      "   🗑️ Dropped columns: Profile, Labels, Budget group, Status, Current Budget, SP Off-site Ads Strategy, Bidding Strategy\n",
      "✅ Successfully processed: SA_Campaign_List_20240717_20240717_238iuR.xlsx\n",
      "🔄 Initial run: Processing Q3 2024 file SA_Campaign_List_20240718_20240718_jCLFfO.xlsx\n",
      "📊 Processing: SA_Campaign_List_20240718_20240718_jCLFfO.xlsx\n",
      "   🗑️ Dropped columns: Profile, Labels, Budget group, Status, Current Budget, SP Off-site Ads Strategy, Bidding Strategy\n",
      "✅ Successfully processed: SA_Campaign_List_20240718_20240718_jCLFfO.xlsx\n",
      "🔄 Initial run: Processing Q3 2024 file SA_Campaign_List_20240719_20240719_mgEWBW.xlsx\n",
      "📊 Processing: SA_Campaign_List_20240719_20240719_mgEWBW.xlsx\n",
      "   🗑️ Dropped columns: Profile, Labels, Budget group, Status, Current Budget, SP Off-site Ads Strategy, Bidding Strategy\n",
      "✅ Successfully processed: SA_Campaign_List_20240719_20240719_mgEWBW.xlsx\n",
      "🔄 Initial run: Processing Q3 2024 file SA_Campaign_List_20240720_20240720_D61x3E.xlsx\n",
      "📊 Processing: SA_Campaign_List_20240720_20240720_D61x3E.xlsx\n",
      "   🗑️ Dropped columns: Profile, Labels, Budget group, Status, Current Budget, SP Off-site Ads Strategy, Bidding Strategy\n",
      "✅ Successfully processed: SA_Campaign_List_20240720_20240720_D61x3E.xlsx\n",
      "🔄 Initial run: Processing Q3 2024 file SA_Campaign_List_20240721_20240721_Y9D7Br.xlsx\n",
      "📊 Processing: SA_Campaign_List_20240721_20240721_Y9D7Br.xlsx\n",
      "   🗑️ Dropped columns: Profile, Labels, Budget group, Status, Current Budget, SP Off-site Ads Strategy, Bidding Strategy\n",
      "✅ Successfully processed: SA_Campaign_List_20240721_20240721_Y9D7Br.xlsx\n",
      "🔄 Initial run: Processing Q3 2024 file SA_Campaign_List_20240722_20240722_WzjMZL.xlsx\n",
      "📊 Processing: SA_Campaign_List_20240722_20240722_WzjMZL.xlsx\n",
      "   🗑️ Dropped columns: Profile, Labels, Budget group, Status, Current Budget, SP Off-site Ads Strategy, Bidding Strategy\n",
      "✅ Successfully processed: SA_Campaign_List_20240722_20240722_WzjMZL.xlsx\n",
      "🔄 Initial run: Processing Q3 2024 file SA_Campaign_List_20240723_20240723_AQERzQ.xlsx\n",
      "📊 Processing: SA_Campaign_List_20240723_20240723_AQERzQ.xlsx\n",
      "   🗑️ Dropped columns: Profile, Labels, Budget group, Status, Current Budget, SP Off-site Ads Strategy, Bidding Strategy\n",
      "✅ Successfully processed: SA_Campaign_List_20240723_20240723_AQERzQ.xlsx\n",
      "🔄 Initial run: Processing Q3 2024 file SA_Campaign_List_20240724_20240724_vsoX3D.xlsx\n",
      "📊 Processing: SA_Campaign_List_20240724_20240724_vsoX3D.xlsx\n",
      "   🗑️ Dropped columns: Profile, Labels, Budget group, Status, Current Budget, SP Off-site Ads Strategy, Bidding Strategy\n",
      "✅ Successfully processed: SA_Campaign_List_20240724_20240724_vsoX3D.xlsx\n",
      "🔄 Initial run: Processing Q3 2024 file SA_Campaign_List_20240725_20240725_fdrCVt.xlsx\n",
      "📊 Processing: SA_Campaign_List_20240725_20240725_fdrCVt.xlsx\n",
      "   🗑️ Dropped columns: Profile, Labels, Budget group, Status, Current Budget, SP Off-site Ads Strategy, Bidding Strategy\n",
      "✅ Successfully processed: SA_Campaign_List_20240725_20240725_fdrCVt.xlsx\n",
      "🔄 Initial run: Processing Q3 2024 file SA_Campaign_List_20240726_20240726_yl0GwV.xlsx\n",
      "📊 Processing: SA_Campaign_List_20240726_20240726_yl0GwV.xlsx\n",
      "   🗑️ Dropped columns: Profile, Labels, Budget group, Status, Current Budget, SP Off-site Ads Strategy, Bidding Strategy\n",
      "✅ Successfully processed: SA_Campaign_List_20240726_20240726_yl0GwV.xlsx\n",
      "🔄 Initial run: Processing Q3 2024 file SA_Campaign_List_20240727_20240727_oUaGYh.xlsx\n",
      "📊 Processing: SA_Campaign_List_20240727_20240727_oUaGYh.xlsx\n",
      "   🗑️ Dropped columns: Profile, Labels, Budget group, Status, Current Budget, SP Off-site Ads Strategy, Bidding Strategy\n",
      "✅ Successfully processed: SA_Campaign_List_20240727_20240727_oUaGYh.xlsx\n",
      "🔄 Initial run: Processing Q3 2024 file SA_Campaign_List_20240728_20240728_JA2MmE.xlsx\n",
      "📊 Processing: SA_Campaign_List_20240728_20240728_JA2MmE.xlsx\n",
      "   🗑️ Dropped columns: Profile, Labels, Budget group, Status, Current Budget, SP Off-site Ads Strategy, Bidding Strategy\n",
      "✅ Successfully processed: SA_Campaign_List_20240728_20240728_JA2MmE.xlsx\n",
      "🔄 Initial run: Processing Q3 2024 file SA_Campaign_List_20240729_20240729_nccfO7.xlsx\n",
      "📊 Processing: SA_Campaign_List_20240729_20240729_nccfO7.xlsx\n",
      "   🗑️ Dropped columns: Profile, Labels, Budget group, Status, Current Budget, SP Off-site Ads Strategy, Bidding Strategy\n",
      "✅ Successfully processed: SA_Campaign_List_20240729_20240729_nccfO7.xlsx\n",
      "🔄 Initial run: Processing Q3 2024 file SA_Campaign_List_20240730_20240730_snFC0I.xlsx\n",
      "📊 Processing: SA_Campaign_List_20240730_20240730_snFC0I.xlsx\n",
      "   🗑️ Dropped columns: Profile, Labels, Budget group, Status, Current Budget, SP Off-site Ads Strategy, Bidding Strategy\n",
      "✅ Successfully processed: SA_Campaign_List_20240730_20240730_snFC0I.xlsx\n",
      "🔄 Initial run: Processing Q3 2024 file SA_Campaign_List_20240731_20240731_7gjPuv.xlsx\n",
      "📊 Processing: SA_Campaign_List_20240731_20240731_7gjPuv.xlsx\n",
      "   🗑️ Dropped columns: Profile, Labels, Budget group, Status, Current Budget, SP Off-site Ads Strategy, Bidding Strategy\n",
      "✅ Successfully processed: SA_Campaign_List_20240731_20240731_7gjPuv.xlsx\n",
      "🔄 Initial run: Processing Q3 2024 file SA_Campaign_List_20240801_20240801_THl8uh.xlsx\n",
      "📊 Processing: SA_Campaign_List_20240801_20240801_THl8uh.xlsx\n",
      "   🗑️ Dropped columns: Profile, Labels, Budget group, Status, Current Budget, SP Off-site Ads Strategy, Bidding Strategy\n",
      "✅ Successfully processed: SA_Campaign_List_20240801_20240801_THl8uh.xlsx\n",
      "🔄 Initial run: Processing Q3 2024 file SA_Campaign_List_20240802_20240802_Q1JEsN.xlsx\n",
      "📊 Processing: SA_Campaign_List_20240802_20240802_Q1JEsN.xlsx\n",
      "   🗑️ Dropped columns: Profile, Labels, Budget group, Status, Current Budget, SP Off-site Ads Strategy, Bidding Strategy\n",
      "✅ Successfully processed: SA_Campaign_List_20240802_20240802_Q1JEsN.xlsx\n",
      "🔄 Initial run: Processing Q3 2024 file SA_Campaign_List_20240803_20240803_syIZ3O.xlsx\n",
      "📊 Processing: SA_Campaign_List_20240803_20240803_syIZ3O.xlsx\n",
      "   🗑️ Dropped columns: Profile, Labels, Budget group, Status, Current Budget, SP Off-site Ads Strategy, Bidding Strategy\n",
      "✅ Successfully processed: SA_Campaign_List_20240803_20240803_syIZ3O.xlsx\n",
      "🔄 Initial run: Processing Q3 2024 file SA_Campaign_List_20240804_20240804_H2wN6Y.xlsx\n",
      "📊 Processing: SA_Campaign_List_20240804_20240804_H2wN6Y.xlsx\n",
      "   🗑️ Dropped columns: Profile, Labels, Budget group, Status, Current Budget, SP Off-site Ads Strategy, Bidding Strategy\n",
      "✅ Successfully processed: SA_Campaign_List_20240804_20240804_H2wN6Y.xlsx\n",
      "🔄 Initial run: Processing Q3 2024 file SA_Campaign_List_20240805_20240805_A3oC8p.xlsx\n",
      "📊 Processing: SA_Campaign_List_20240805_20240805_A3oC8p.xlsx\n",
      "   🗑️ Dropped columns: Profile, Labels, Budget group, Status, Current Budget, SP Off-site Ads Strategy, Bidding Strategy\n",
      "✅ Successfully processed: SA_Campaign_List_20240805_20240805_A3oC8p.xlsx\n",
      "🔄 Initial run: Processing Q3 2024 file SA_Campaign_List_20240806_20240806_tMyfQk.xlsx\n",
      "📊 Processing: SA_Campaign_List_20240806_20240806_tMyfQk.xlsx\n",
      "   🗑️ Dropped columns: Profile, Labels, Budget group, Status, Current Budget, SP Off-site Ads Strategy, Bidding Strategy\n",
      "✅ Successfully processed: SA_Campaign_List_20240806_20240806_tMyfQk.xlsx\n",
      "🔄 Initial run: Processing Q3 2024 file SA_Campaign_List_20240807_20240807_pvwPyI.xlsx\n",
      "📊 Processing: SA_Campaign_List_20240807_20240807_pvwPyI.xlsx\n",
      "   🗑️ Dropped columns: Profile, Labels, Budget group, Status, Current Budget, SP Off-site Ads Strategy, Bidding Strategy\n",
      "✅ Successfully processed: SA_Campaign_List_20240807_20240807_pvwPyI.xlsx\n",
      "🔄 Initial run: Processing Q3 2024 file SA_Campaign_List_20240808_20240808_iBVkTq (1).xlsx\n",
      "📊 Processing: SA_Campaign_List_20240808_20240808_iBVkTq (1).xlsx\n",
      "   🗑️ Dropped columns: Profile, Labels, Budget group, Status, Current Budget, SP Off-site Ads Strategy, Bidding Strategy\n",
      "✅ Successfully processed: SA_Campaign_List_20240808_20240808_iBVkTq (1).xlsx\n",
      "🔄 Initial run: Processing Q3 2024 file SA_Campaign_List_20240809_20240809_leqaeZ.xlsx\n",
      "📊 Processing: SA_Campaign_List_20240809_20240809_leqaeZ.xlsx\n",
      "   🗑️ Dropped columns: Profile, Labels, Budget group, Status, Current Budget, SP Off-site Ads Strategy, Bidding Strategy\n",
      "✅ Successfully processed: SA_Campaign_List_20240809_20240809_leqaeZ.xlsx\n",
      "🔄 Initial run: Processing Q3 2024 file SA_Campaign_List_20240810_20240810_yhgNkX.xlsx\n",
      "📊 Processing: SA_Campaign_List_20240810_20240810_yhgNkX.xlsx\n",
      "   🗑️ Dropped columns: Profile, Labels, Budget group, Status, Current Budget, SP Off-site Ads Strategy, Bidding Strategy\n",
      "✅ Successfully processed: SA_Campaign_List_20240810_20240810_yhgNkX.xlsx\n",
      "🔄 Initial run: Processing Q3 2024 file SA_Campaign_List_20240811_20240811_QtBpvM.xlsx\n",
      "📊 Processing: SA_Campaign_List_20240811_20240811_QtBpvM.xlsx\n",
      "   🗑️ Dropped columns: Profile, Labels, Budget group, Status, Current Budget, SP Off-site Ads Strategy, Bidding Strategy\n",
      "✅ Successfully processed: SA_Campaign_List_20240811_20240811_QtBpvM.xlsx\n",
      "🔄 Initial run: Processing Q3 2024 file SA_Campaign_List_20240812_20240812_JCmF4k.xlsx\n",
      "📊 Processing: SA_Campaign_List_20240812_20240812_JCmF4k.xlsx\n",
      "   🗑️ Dropped columns: Profile, Labels, Budget group, Status, Current Budget, SP Off-site Ads Strategy, Bidding Strategy\n",
      "✅ Successfully processed: SA_Campaign_List_20240812_20240812_JCmF4k.xlsx\n",
      "🔄 Initial run: Processing Q3 2024 file SA_Campaign_List_20240813_20240813_wEXK61.xlsx\n",
      "📊 Processing: SA_Campaign_List_20240813_20240813_wEXK61.xlsx\n",
      "   🗑️ Dropped columns: Profile, Labels, Budget group, Status, Current Budget, SP Off-site Ads Strategy, Bidding Strategy\n",
      "✅ Successfully processed: SA_Campaign_List_20240813_20240813_wEXK61.xlsx\n",
      "🔄 Initial run: Processing Q3 2024 file SA_Campaign_List_20240814_20240814_oXNFzb.xlsx\n",
      "📊 Processing: SA_Campaign_List_20240814_20240814_oXNFzb.xlsx\n",
      "   🗑️ Dropped columns: Profile, Labels, Budget group, Status, Current Budget, SP Off-site Ads Strategy, Bidding Strategy\n",
      "✅ Successfully processed: SA_Campaign_List_20240814_20240814_oXNFzb.xlsx\n",
      "🔄 Initial run: Processing Q3 2024 file SA_Campaign_List_20240815_20240815_jYtq9X.xlsx\n",
      "📊 Processing: SA_Campaign_List_20240815_20240815_jYtq9X.xlsx\n",
      "   🗑️ Dropped columns: Profile, Labels, Budget group, Status, Current Budget, SP Off-site Ads Strategy, Bidding Strategy\n",
      "✅ Successfully processed: SA_Campaign_List_20240815_20240815_jYtq9X.xlsx\n",
      "🔄 Initial run: Processing Q3 2024 file SA_Campaign_List_20240816_20240816_XV74Ue.xlsx\n",
      "📊 Processing: SA_Campaign_List_20240816_20240816_XV74Ue.xlsx\n",
      "   🗑️ Dropped columns: Profile, Labels, Budget group, Status, Current Budget, SP Off-site Ads Strategy, Bidding Strategy\n",
      "✅ Successfully processed: SA_Campaign_List_20240816_20240816_XV74Ue.xlsx\n",
      "🔄 Initial run: Processing Q3 2024 file SA_Campaign_List_20240817_20240817_dhbN8X.xlsx\n",
      "📊 Processing: SA_Campaign_List_20240817_20240817_dhbN8X.xlsx\n",
      "   🗑️ Dropped columns: Profile, Labels, Budget group, Status, Current Budget, SP Off-site Ads Strategy, Bidding Strategy\n",
      "✅ Successfully processed: SA_Campaign_List_20240817_20240817_dhbN8X.xlsx\n",
      "🔄 Initial run: Processing Q3 2024 file SA_Campaign_List_20240818_20240818_cVE3M2.xlsx\n",
      "📊 Processing: SA_Campaign_List_20240818_20240818_cVE3M2.xlsx\n",
      "   🗑️ Dropped columns: Profile, Labels, Budget group, Status, Current Budget, SP Off-site Ads Strategy, Bidding Strategy\n",
      "✅ Successfully processed: SA_Campaign_List_20240818_20240818_cVE3M2.xlsx\n",
      "🔄 Initial run: Processing Q3 2024 file SA_Campaign_List_20240819_20240819_xlZUuH.xlsx\n",
      "📊 Processing: SA_Campaign_List_20240819_20240819_xlZUuH.xlsx\n",
      "   🗑️ Dropped columns: Profile, Labels, Budget group, Status, Current Budget, SP Off-site Ads Strategy, Bidding Strategy\n",
      "✅ Successfully processed: SA_Campaign_List_20240819_20240819_xlZUuH.xlsx\n",
      "🔄 Initial run: Processing Q3 2024 file SA_Campaign_List_20240820_20240820_Cgxnji.xlsx\n",
      "📊 Processing: SA_Campaign_List_20240820_20240820_Cgxnji.xlsx\n",
      "   🗑️ Dropped columns: Profile, Labels, Budget group, Status, Current Budget, SP Off-site Ads Strategy, Bidding Strategy\n",
      "✅ Successfully processed: SA_Campaign_List_20240820_20240820_Cgxnji.xlsx\n",
      "🔄 Initial run: Processing Q3 2024 file SA_Campaign_List_20240821_20240821_X2DaaD.xlsx\n",
      "📊 Processing: SA_Campaign_List_20240821_20240821_X2DaaD.xlsx\n",
      "   🗑️ Dropped columns: Profile, Labels, Budget group, Status, Current Budget, SP Off-site Ads Strategy, Bidding Strategy\n",
      "✅ Successfully processed: SA_Campaign_List_20240821_20240821_X2DaaD.xlsx\n",
      "🔄 Initial run: Processing Q3 2024 file SA_Campaign_List_20240822_20240822_KNfyGC.xlsx\n",
      "📊 Processing: SA_Campaign_List_20240822_20240822_KNfyGC.xlsx\n",
      "   🗑️ Dropped columns: Profile, Labels, Budget group, Status, Current Budget, SP Off-site Ads Strategy, Bidding Strategy\n",
      "✅ Successfully processed: SA_Campaign_List_20240822_20240822_KNfyGC.xlsx\n",
      "🔄 Initial run: Processing Q3 2024 file SA_Campaign_List_20240823_20240823_xgc6an.xlsx\n",
      "📊 Processing: SA_Campaign_List_20240823_20240823_xgc6an.xlsx\n",
      "   🗑️ Dropped columns: Profile, Labels, Budget group, Status, Current Budget, SP Off-site Ads Strategy, Bidding Strategy\n",
      "✅ Successfully processed: SA_Campaign_List_20240823_20240823_xgc6an.xlsx\n",
      "🔄 Initial run: Processing Q3 2024 file SA_Campaign_List_20240824_20240824_zkQ8SX.xlsx\n",
      "📊 Processing: SA_Campaign_List_20240824_20240824_zkQ8SX.xlsx\n",
      "   🗑️ Dropped columns: Profile, Labels, Budget group, Status, Current Budget, SP Off-site Ads Strategy, Bidding Strategy\n",
      "✅ Successfully processed: SA_Campaign_List_20240824_20240824_zkQ8SX.xlsx\n",
      "🔄 Initial run: Processing Q3 2024 file SA_Campaign_List_20240825_20240825_JXZ5CR.xlsx\n",
      "📊 Processing: SA_Campaign_List_20240825_20240825_JXZ5CR.xlsx\n",
      "   🗑️ Dropped columns: Profile, Labels, Budget group, Status, Current Budget, SP Off-site Ads Strategy, Bidding Strategy\n",
      "✅ Successfully processed: SA_Campaign_List_20240825_20240825_JXZ5CR.xlsx\n",
      "🔄 Initial run: Processing Q3 2024 file SA_Campaign_List_20240826_20240826_j46ClA.xlsx\n",
      "📊 Processing: SA_Campaign_List_20240826_20240826_j46ClA.xlsx\n",
      "   🗑️ Dropped columns: Profile, Labels, Budget group, Status, Current Budget, SP Off-site Ads Strategy, Bidding Strategy\n",
      "✅ Successfully processed: SA_Campaign_List_20240826_20240826_j46ClA.xlsx\n",
      "🔄 Initial run: Processing Q3 2024 file SA_Campaign_List_20240827_20240827_yD1KBc.xlsx\n",
      "📊 Processing: SA_Campaign_List_20240827_20240827_yD1KBc.xlsx\n",
      "   🗑️ Dropped columns: Profile, Labels, Budget group, Status, Current Budget, SP Off-site Ads Strategy, Bidding Strategy\n",
      "✅ Successfully processed: SA_Campaign_List_20240827_20240827_yD1KBc.xlsx\n",
      "🔄 Initial run: Processing Q3 2024 file SA_Campaign_List_20240828_20240828_FKLiIq.xlsx\n",
      "📊 Processing: SA_Campaign_List_20240828_20240828_FKLiIq.xlsx\n",
      "   🗑️ Dropped columns: Profile, Labels, Budget group, Status, Current Budget, SP Off-site Ads Strategy, Bidding Strategy\n",
      "✅ Successfully processed: SA_Campaign_List_20240828_20240828_FKLiIq.xlsx\n",
      "🔄 Initial run: Processing Q3 2024 file SA_Campaign_List_20240829_20240829_qBu7M1.xlsx\n",
      "📊 Processing: SA_Campaign_List_20240829_20240829_qBu7M1.xlsx\n",
      "   🗑️ Dropped columns: Profile, Labels, Budget group, Status, Current Budget, SP Off-site Ads Strategy, Bidding Strategy\n",
      "✅ Successfully processed: SA_Campaign_List_20240829_20240829_qBu7M1.xlsx\n",
      "🔄 Initial run: Processing Q3 2024 file SA_Campaign_List_20240830_20240830_ZqG2zh.xlsx\n",
      "📊 Processing: SA_Campaign_List_20240830_20240830_ZqG2zh.xlsx\n",
      "   🗑️ Dropped columns: Profile, Labels, Budget group, Status, Current Budget, SP Off-site Ads Strategy, Bidding Strategy\n",
      "✅ Successfully processed: SA_Campaign_List_20240830_20240830_ZqG2zh.xlsx\n",
      "🔄 Initial run: Processing Q3 2024 file SA_Campaign_List_20240831_20240831_sBrJAN.xlsx\n",
      "📊 Processing: SA_Campaign_List_20240831_20240831_sBrJAN.xlsx\n",
      "   🗑️ Dropped columns: Profile, Labels, Budget group, Status, Current Budget, SP Off-site Ads Strategy, Bidding Strategy\n",
      "✅ Successfully processed: SA_Campaign_List_20240831_20240831_sBrJAN.xlsx\n",
      "🔄 Initial run: Processing Q3 2024 file SA_Campaign_List_20240901_20240901_3JsLtM.xlsx\n",
      "📊 Processing: SA_Campaign_List_20240901_20240901_3JsLtM.xlsx\n",
      "   🗑️ Dropped columns: Profile, Labels, Budget group, Status, Current Budget, SP Off-site Ads Strategy, Bidding Strategy\n",
      "✅ Successfully processed: SA_Campaign_List_20240901_20240901_3JsLtM.xlsx\n",
      "🔄 Initial run: Processing Q3 2024 file SA_Campaign_List_20240902_20240902_cG3CFE.xlsx\n",
      "📊 Processing: SA_Campaign_List_20240902_20240902_cG3CFE.xlsx\n",
      "   🗑️ Dropped columns: Profile, Labels, Budget group, Status, Current Budget, SP Off-site Ads Strategy, Bidding Strategy\n",
      "✅ Successfully processed: SA_Campaign_List_20240902_20240902_cG3CFE.xlsx\n",
      "🔄 Initial run: Processing Q3 2024 file SA_Campaign_List_20240903_20240903_GZDx0M.xlsx\n",
      "📊 Processing: SA_Campaign_List_20240903_20240903_GZDx0M.xlsx\n",
      "   🗑️ Dropped columns: Profile, Labels, Budget group, Status, Current Budget, SP Off-site Ads Strategy, Bidding Strategy\n",
      "✅ Successfully processed: SA_Campaign_List_20240903_20240903_GZDx0M.xlsx\n",
      "🔄 Initial run: Processing Q3 2024 file SA_Campaign_List_20240904_20240904_rIkwF3.xlsx\n",
      "📊 Processing: SA_Campaign_List_20240904_20240904_rIkwF3.xlsx\n",
      "   🗑️ Dropped columns: Profile, Labels, Budget group, Status, Current Budget, SP Off-site Ads Strategy, Bidding Strategy\n",
      "✅ Successfully processed: SA_Campaign_List_20240904_20240904_rIkwF3.xlsx\n",
      "🔄 Initial run: Processing Q3 2024 file SA_Campaign_List_20240905_20240905_Otkihv.xlsx\n",
      "📊 Processing: SA_Campaign_List_20240905_20240905_Otkihv.xlsx\n",
      "   🗑️ Dropped columns: Profile, Labels, Budget group, Status, Current Budget, SP Off-site Ads Strategy, Bidding Strategy\n",
      "✅ Successfully processed: SA_Campaign_List_20240905_20240905_Otkihv.xlsx\n",
      "🔄 Initial run: Processing Q3 2024 file SA_Campaign_List_20240906_20240906_6P7Fxn.xlsx\n",
      "📊 Processing: SA_Campaign_List_20240906_20240906_6P7Fxn.xlsx\n",
      "   🗑️ Dropped columns: Profile, Labels, Budget group, Status, Current Budget, SP Off-site Ads Strategy, Bidding Strategy\n",
      "✅ Successfully processed: SA_Campaign_List_20240906_20240906_6P7Fxn.xlsx\n",
      "🔄 Initial run: Processing Q3 2024 file SA_Campaign_List_20240907_20240907_SgpIZ2.xlsx\n",
      "📊 Processing: SA_Campaign_List_20240907_20240907_SgpIZ2.xlsx\n",
      "   🗑️ Dropped columns: Profile, Labels, Budget group, Status, Current Budget, SP Off-site Ads Strategy, Bidding Strategy\n",
      "✅ Successfully processed: SA_Campaign_List_20240907_20240907_SgpIZ2.xlsx\n",
      "🔄 Initial run: Processing Q3 2024 file SA_Campaign_List_20240908_20240908_74oHrV.xlsx\n",
      "📊 Processing: SA_Campaign_List_20240908_20240908_74oHrV.xlsx\n",
      "   🗑️ Dropped columns: Profile, Labels, Budget group, Status, Current Budget, SP Off-site Ads Strategy, Bidding Strategy\n",
      "✅ Successfully processed: SA_Campaign_List_20240908_20240908_74oHrV.xlsx\n",
      "🔄 Initial run: Processing Q3 2024 file SA_Campaign_List_20240909_20240909_5EBgFV.xlsx\n",
      "📊 Processing: SA_Campaign_List_20240909_20240909_5EBgFV.xlsx\n",
      "   🗑️ Dropped columns: Profile, Labels, Budget group, Status, Current Budget, SP Off-site Ads Strategy, Bidding Strategy\n",
      "✅ Successfully processed: SA_Campaign_List_20240909_20240909_5EBgFV.xlsx\n",
      "🔄 Initial run: Processing Q3 2024 file SA_Campaign_List_20240910_20240910_L1awWn.xlsx\n",
      "📊 Processing: SA_Campaign_List_20240910_20240910_L1awWn.xlsx\n",
      "   🗑️ Dropped columns: Profile, Labels, Budget group, Status, Current Budget, SP Off-site Ads Strategy, Bidding Strategy\n",
      "✅ Successfully processed: SA_Campaign_List_20240910_20240910_L1awWn.xlsx\n",
      "🔄 Initial run: Processing Q3 2024 file SA_Campaign_List_20240911_20240911_W5poXg.xlsx\n",
      "📊 Processing: SA_Campaign_List_20240911_20240911_W5poXg.xlsx\n",
      "   🗑️ Dropped columns: Profile, Labels, Budget group, Status, Current Budget, SP Off-site Ads Strategy, Bidding Strategy\n",
      "✅ Successfully processed: SA_Campaign_List_20240911_20240911_W5poXg.xlsx\n",
      "🔄 Initial run: Processing Q3 2024 file SA_Campaign_List_20240912_20240912_0qtkeO.xlsx\n",
      "📊 Processing: SA_Campaign_List_20240912_20240912_0qtkeO.xlsx\n",
      "   🗑️ Dropped columns: Profile, Labels, Budget group, Status, Current Budget, SP Off-site Ads Strategy, Bidding Strategy\n",
      "✅ Successfully processed: SA_Campaign_List_20240912_20240912_0qtkeO.xlsx\n",
      "🔄 Initial run: Processing Q3 2024 file SA_Campaign_List_20240913_20240913_E1WdFc.xlsx\n",
      "📊 Processing: SA_Campaign_List_20240913_20240913_E1WdFc.xlsx\n",
      "   🗑️ Dropped columns: Profile, Labels, Budget group, Status, Current Budget, SP Off-site Ads Strategy, Bidding Strategy\n",
      "✅ Successfully processed: SA_Campaign_List_20240913_20240913_E1WdFc.xlsx\n",
      "🔄 Initial run: Processing Q3 2024 file SA_Campaign_List_20240914_20240914_YxYNAn.xlsx\n",
      "📊 Processing: SA_Campaign_List_20240914_20240914_YxYNAn.xlsx\n",
      "   🗑️ Dropped columns: Profile, Labels, Budget group, Status, Current Budget, SP Off-site Ads Strategy, Bidding Strategy\n",
      "✅ Successfully processed: SA_Campaign_List_20240914_20240914_YxYNAn.xlsx\n",
      "🔄 Initial run: Processing Q3 2024 file SA_Campaign_List_20240915_20240915_W7CMIj.xlsx\n",
      "📊 Processing: SA_Campaign_List_20240915_20240915_W7CMIj.xlsx\n",
      "   🗑️ Dropped columns: Profile, Labels, Budget group, Status, Current Budget, SP Off-site Ads Strategy, Bidding Strategy\n",
      "✅ Successfully processed: SA_Campaign_List_20240915_20240915_W7CMIj.xlsx\n",
      "🔄 Initial run: Processing Q3 2024 file SA_Campaign_List_20240916_20240916_DOofR0.xlsx\n",
      "📊 Processing: SA_Campaign_List_20240916_20240916_DOofR0.xlsx\n",
      "   🗑️ Dropped columns: Profile, Labels, Budget group, Status, Current Budget, SP Off-site Ads Strategy, Bidding Strategy\n",
      "✅ Successfully processed: SA_Campaign_List_20240916_20240916_DOofR0.xlsx\n",
      "🔄 Initial run: Processing Q3 2024 file SA_Campaign_List_20240917_20240917_2vgqpt.xlsx\n",
      "📊 Processing: SA_Campaign_List_20240917_20240917_2vgqpt.xlsx\n",
      "   🗑️ Dropped columns: Profile, Labels, Budget group, Status, Current Budget, SP Off-site Ads Strategy, Bidding Strategy\n",
      "✅ Successfully processed: SA_Campaign_List_20240917_20240917_2vgqpt.xlsx\n",
      "🔄 Initial run: Processing Q3 2024 file SA_Campaign_List_20240918_20240918_J8z1kr.xlsx\n",
      "📊 Processing: SA_Campaign_List_20240918_20240918_J8z1kr.xlsx\n",
      "   🗑️ Dropped columns: Profile, Labels, Budget group, Status, Current Budget, SP Off-site Ads Strategy, Bidding Strategy\n",
      "✅ Successfully processed: SA_Campaign_List_20240918_20240918_J8z1kr.xlsx\n",
      "🔄 Initial run: Processing Q3 2024 file SA_Campaign_List_20240919_20240919_8jFTcp.xlsx\n",
      "📊 Processing: SA_Campaign_List_20240919_20240919_8jFTcp.xlsx\n",
      "   🗑️ Dropped columns: Profile, Labels, Budget group, Status, Current Budget, SP Off-site Ads Strategy, Bidding Strategy\n",
      "✅ Successfully processed: SA_Campaign_List_20240919_20240919_8jFTcp.xlsx\n",
      "🔄 Initial run: Processing Q3 2024 file SA_Campaign_List_20240920_20240920_4cmtsa.xlsx\n",
      "📊 Processing: SA_Campaign_List_20240920_20240920_4cmtsa.xlsx\n",
      "   🗑️ Dropped columns: Profile, Labels, Budget group, Status, Current Budget, SP Off-site Ads Strategy, Bidding Strategy\n",
      "✅ Successfully processed: SA_Campaign_List_20240920_20240920_4cmtsa.xlsx\n",
      "🔄 Initial run: Processing Q3 2024 file SA_Campaign_List_20240921_20240921_es3nT6.xlsx\n",
      "📊 Processing: SA_Campaign_List_20240921_20240921_es3nT6.xlsx\n",
      "   🗑️ Dropped columns: Profile, Labels, Budget group, Status, Current Budget, SP Off-site Ads Strategy, Bidding Strategy\n",
      "✅ Successfully processed: SA_Campaign_List_20240921_20240921_es3nT6.xlsx\n",
      "🔄 Initial run: Processing Q3 2024 file SA_Campaign_List_20240922_20240922_0AkxFc.xlsx\n",
      "📊 Processing: SA_Campaign_List_20240922_20240922_0AkxFc.xlsx\n",
      "   🗑️ Dropped columns: Profile, Labels, Budget group, Status, Current Budget, SP Off-site Ads Strategy, Bidding Strategy\n",
      "✅ Successfully processed: SA_Campaign_List_20240922_20240922_0AkxFc.xlsx\n",
      "🔄 Initial run: Processing Q3 2024 file SA_Campaign_List_20240923_20240923_wuLXAt.xlsx\n",
      "📊 Processing: SA_Campaign_List_20240923_20240923_wuLXAt.xlsx\n",
      "   🗑️ Dropped columns: Profile, Labels, Budget group, Status, Current Budget, SP Off-site Ads Strategy, Bidding Strategy\n",
      "✅ Successfully processed: SA_Campaign_List_20240923_20240923_wuLXAt.xlsx\n",
      "🔄 Initial run: Processing Q3 2024 file SA_Campaign_List_20240924_20240924_Bi9snd.xlsx\n",
      "📊 Processing: SA_Campaign_List_20240924_20240924_Bi9snd.xlsx\n",
      "   🗑️ Dropped columns: Profile, Labels, Budget group, Status, Current Budget, SP Off-site Ads Strategy, Bidding Strategy\n",
      "✅ Successfully processed: SA_Campaign_List_20240924_20240924_Bi9snd.xlsx\n",
      "🔄 Initial run: Processing Q3 2024 file SA_Campaign_List_20240925_20240925_OGRl2a.xlsx\n",
      "📊 Processing: SA_Campaign_List_20240925_20240925_OGRl2a.xlsx\n",
      "   🗑️ Dropped columns: Profile, Labels, Budget group, Status, Current Budget, SP Off-site Ads Strategy, Bidding Strategy\n",
      "✅ Successfully processed: SA_Campaign_List_20240925_20240925_OGRl2a.xlsx\n",
      "🔄 Initial run: Processing Q3 2024 file SA_Campaign_List_20240926_20240926_snbQG0.xlsx\n",
      "📊 Processing: SA_Campaign_List_20240926_20240926_snbQG0.xlsx\n",
      "   🗑️ Dropped columns: Profile, Labels, Budget group, Status, Current Budget, SP Off-site Ads Strategy, Bidding Strategy\n",
      "✅ Successfully processed: SA_Campaign_List_20240926_20240926_snbQG0.xlsx\n",
      "🔄 Initial run: Processing Q3 2024 file SA_Campaign_List_20240927_20240927_KJf43V.xlsx\n",
      "📊 Processing: SA_Campaign_List_20240927_20240927_KJf43V.xlsx\n",
      "   🗑️ Dropped columns: Profile, Labels, Budget group, Status, Current Budget, SP Off-site Ads Strategy, Bidding Strategy\n",
      "✅ Successfully processed: SA_Campaign_List_20240927_20240927_KJf43V.xlsx\n",
      "🔄 Initial run: Processing Q3 2024 file SA_Campaign_List_20240928_20240928_e1R8gN.xlsx\n",
      "📊 Processing: SA_Campaign_List_20240928_20240928_e1R8gN.xlsx\n",
      "   🗑️ Dropped columns: Profile, Labels, Budget group, Status, Current Budget, SP Off-site Ads Strategy, Bidding Strategy\n",
      "✅ Successfully processed: SA_Campaign_List_20240928_20240928_e1R8gN.xlsx\n",
      "🔄 Initial run: Processing Q3 2024 file SA_Campaign_List_20240929_20240929_f8Zkxo.xlsx\n",
      "📊 Processing: SA_Campaign_List_20240929_20240929_f8Zkxo.xlsx\n",
      "   🗑️ Dropped columns: Profile, Labels, Budget group, Status, Current Budget, SP Off-site Ads Strategy, Bidding Strategy\n",
      "✅ Successfully processed: SA_Campaign_List_20240929_20240929_f8Zkxo.xlsx\n",
      "🔄 Initial run: Processing Q3 2024 file SA_Campaign_List_20240930_20240930_GbPddt.xlsx\n",
      "📊 Processing: SA_Campaign_List_20240930_20240930_GbPddt.xlsx\n",
      "   🗑️ Dropped columns: Profile, Labels, Budget group, Status, Current Budget, SP Off-site Ads Strategy, Bidding Strategy\n",
      "✅ Successfully processed: SA_Campaign_List_20240930_20240930_GbPddt.xlsx\n",
      "\n",
      "📈 Combining 92 dataframes...\n",
      "✅ Combined data shape: (41239, 62)\n",
      "📅 Date range: 2024-07-01 00:00:00 to 2024-09-30 00:00:00\n",
      "📤 Uploading to Google Sheets...\n",
      "✅ Successfully uploaded 41239 rows to Google Sheets\n",
      "🔗 Sheet: Raw_XNurta_H2_2024\n",
      "\n",
      "🎉 Successfully processed 92 files:\n",
      "   ✓ SA_Campaign_List_20240701_20240701_38C2RG.xlsx\n",
      "   ✓ SA_Campaign_List_20240702_20240702_9TkpbM.xlsx\n",
      "   ✓ SA_Campaign_List_20240703_20240703_G80TRn.xlsx\n",
      "   ✓ SA_Campaign_List_20240704_20240704_gZtCIL.xlsx\n",
      "   ✓ SA_Campaign_List_20240705_20240705_A1i8Dn.xlsx\n",
      "   ✓ SA_Campaign_List_20240706_20240706_ed4ep2.xlsx\n",
      "   ✓ SA_Campaign_List_20240707_20240707_1nbAjc.xlsx\n",
      "   ✓ SA_Campaign_List_20240708_20240708_nSsf7X.xlsx\n",
      "   ✓ SA_Campaign_List_20240709_20240709_Sa3Pwo.xlsx\n",
      "   ✓ SA_Campaign_List_20240710_20240710_NBUR0e.xlsx\n",
      "   ✓ SA_Campaign_List_20240711_20240711_5zfUcS.xlsx\n",
      "   ✓ SA_Campaign_List_20240712_20240712_Rd20hJ.xlsx\n",
      "   ✓ SA_Campaign_List_20240713_20240713_z6wmov.xlsx\n",
      "   ✓ SA_Campaign_List_20240714_20240714_gkwAAt.xlsx\n",
      "   ✓ SA_Campaign_List_20240715_20240715_EB6eR5.xlsx\n",
      "   ✓ SA_Campaign_List_20240716_20240716_X7QEk3.xlsx\n",
      "   ✓ SA_Campaign_List_20240717_20240717_238iuR.xlsx\n",
      "   ✓ SA_Campaign_List_20240718_20240718_jCLFfO.xlsx\n",
      "   ✓ SA_Campaign_List_20240719_20240719_mgEWBW.xlsx\n",
      "   ✓ SA_Campaign_List_20240720_20240720_D61x3E.xlsx\n",
      "   ✓ SA_Campaign_List_20240721_20240721_Y9D7Br.xlsx\n",
      "   ✓ SA_Campaign_List_20240722_20240722_WzjMZL.xlsx\n",
      "   ✓ SA_Campaign_List_20240723_20240723_AQERzQ.xlsx\n",
      "   ✓ SA_Campaign_List_20240724_20240724_vsoX3D.xlsx\n",
      "   ✓ SA_Campaign_List_20240725_20240725_fdrCVt.xlsx\n",
      "   ✓ SA_Campaign_List_20240726_20240726_yl0GwV.xlsx\n",
      "   ✓ SA_Campaign_List_20240727_20240727_oUaGYh.xlsx\n",
      "   ✓ SA_Campaign_List_20240728_20240728_JA2MmE.xlsx\n",
      "   ✓ SA_Campaign_List_20240729_20240729_nccfO7.xlsx\n",
      "   ✓ SA_Campaign_List_20240730_20240730_snFC0I.xlsx\n",
      "   ✓ SA_Campaign_List_20240731_20240731_7gjPuv.xlsx\n",
      "   ✓ SA_Campaign_List_20240801_20240801_THl8uh.xlsx\n",
      "   ✓ SA_Campaign_List_20240802_20240802_Q1JEsN.xlsx\n",
      "   ✓ SA_Campaign_List_20240803_20240803_syIZ3O.xlsx\n",
      "   ✓ SA_Campaign_List_20240804_20240804_H2wN6Y.xlsx\n",
      "   ✓ SA_Campaign_List_20240805_20240805_A3oC8p.xlsx\n",
      "   ✓ SA_Campaign_List_20240806_20240806_tMyfQk.xlsx\n",
      "   ✓ SA_Campaign_List_20240807_20240807_pvwPyI.xlsx\n",
      "   ✓ SA_Campaign_List_20240808_20240808_iBVkTq (1).xlsx\n",
      "   ✓ SA_Campaign_List_20240809_20240809_leqaeZ.xlsx\n",
      "   ✓ SA_Campaign_List_20240810_20240810_yhgNkX.xlsx\n",
      "   ✓ SA_Campaign_List_20240811_20240811_QtBpvM.xlsx\n",
      "   ✓ SA_Campaign_List_20240812_20240812_JCmF4k.xlsx\n",
      "   ✓ SA_Campaign_List_20240813_20240813_wEXK61.xlsx\n",
      "   ✓ SA_Campaign_List_20240814_20240814_oXNFzb.xlsx\n",
      "   ✓ SA_Campaign_List_20240815_20240815_jYtq9X.xlsx\n",
      "   ✓ SA_Campaign_List_20240816_20240816_XV74Ue.xlsx\n",
      "   ✓ SA_Campaign_List_20240817_20240817_dhbN8X.xlsx\n",
      "   ✓ SA_Campaign_List_20240818_20240818_cVE3M2.xlsx\n",
      "   ✓ SA_Campaign_List_20240819_20240819_xlZUuH.xlsx\n",
      "   ✓ SA_Campaign_List_20240820_20240820_Cgxnji.xlsx\n",
      "   ✓ SA_Campaign_List_20240821_20240821_X2DaaD.xlsx\n",
      "   ✓ SA_Campaign_List_20240822_20240822_KNfyGC.xlsx\n",
      "   ✓ SA_Campaign_List_20240823_20240823_xgc6an.xlsx\n",
      "   ✓ SA_Campaign_List_20240824_20240824_zkQ8SX.xlsx\n",
      "   ✓ SA_Campaign_List_20240825_20240825_JXZ5CR.xlsx\n",
      "   ✓ SA_Campaign_List_20240826_20240826_j46ClA.xlsx\n",
      "   ✓ SA_Campaign_List_20240827_20240827_yD1KBc.xlsx\n",
      "   ✓ SA_Campaign_List_20240828_20240828_FKLiIq.xlsx\n",
      "   ✓ SA_Campaign_List_20240829_20240829_qBu7M1.xlsx\n",
      "   ✓ SA_Campaign_List_20240830_20240830_ZqG2zh.xlsx\n",
      "   ✓ SA_Campaign_List_20240831_20240831_sBrJAN.xlsx\n",
      "   ✓ SA_Campaign_List_20240901_20240901_3JsLtM.xlsx\n",
      "   ✓ SA_Campaign_List_20240902_20240902_cG3CFE.xlsx\n",
      "   ✓ SA_Campaign_List_20240903_20240903_GZDx0M.xlsx\n",
      "   ✓ SA_Campaign_List_20240904_20240904_rIkwF3.xlsx\n",
      "   ✓ SA_Campaign_List_20240905_20240905_Otkihv.xlsx\n",
      "   ✓ SA_Campaign_List_20240906_20240906_6P7Fxn.xlsx\n",
      "   ✓ SA_Campaign_List_20240907_20240907_SgpIZ2.xlsx\n",
      "   ✓ SA_Campaign_List_20240908_20240908_74oHrV.xlsx\n",
      "   ✓ SA_Campaign_List_20240909_20240909_5EBgFV.xlsx\n",
      "   ✓ SA_Campaign_List_20240910_20240910_L1awWn.xlsx\n",
      "   ✓ SA_Campaign_List_20240911_20240911_W5poXg.xlsx\n",
      "   ✓ SA_Campaign_List_20240912_20240912_0qtkeO.xlsx\n",
      "   ✓ SA_Campaign_List_20240913_20240913_E1WdFc.xlsx\n",
      "   ✓ SA_Campaign_List_20240914_20240914_YxYNAn.xlsx\n",
      "   ✓ SA_Campaign_List_20240915_20240915_W7CMIj.xlsx\n",
      "   ✓ SA_Campaign_List_20240916_20240916_DOofR0.xlsx\n",
      "   ✓ SA_Campaign_List_20240917_20240917_2vgqpt.xlsx\n",
      "   ✓ SA_Campaign_List_20240918_20240918_J8z1kr.xlsx\n",
      "   ✓ SA_Campaign_List_20240919_20240919_8jFTcp.xlsx\n",
      "   ✓ SA_Campaign_List_20240920_20240920_4cmtsa.xlsx\n",
      "   ✓ SA_Campaign_List_20240921_20240921_es3nT6.xlsx\n",
      "   ✓ SA_Campaign_List_20240922_20240922_0AkxFc.xlsx\n",
      "   ✓ SA_Campaign_List_20240923_20240923_wuLXAt.xlsx\n",
      "   ✓ SA_Campaign_List_20240924_20240924_Bi9snd.xlsx\n",
      "   ✓ SA_Campaign_List_20240925_20240925_OGRl2a.xlsx\n",
      "   ✓ SA_Campaign_List_20240926_20240926_snbQG0.xlsx\n",
      "   ✓ SA_Campaign_List_20240927_20240927_KJf43V.xlsx\n",
      "   ✓ SA_Campaign_List_20240928_20240928_e1R8gN.xlsx\n",
      "   ✓ SA_Campaign_List_20240929_20240929_f8Zkxo.xlsx\n",
      "   ✓ SA_Campaign_List_20240930_20240930_GbPddt.xlsx\n",
      "\n",
      "📊 PROCESSING SUMMARY - XNurta 2024 Q3\n",
      "=======================================\n",
      "July files: 31\n",
      "August files: 31\n",
      "September files: 30\n",
      "Other files: 0\n",
      "Total files: 184\n",
      "Last run: 2025-08-25 17:33:05\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "import glob\n",
    "import re\n",
    "import json\n",
    "import hashlib\n",
    "import gspread\n",
    "from gspread_dataframe import set_with_dataframe\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "from google.oauth2.service_account import Credentials\n",
    "\n",
    "class XNurtaDataProcessor2024:\n",
    "    def __init__(self, base_folder, credentials_path, sheet_id, worksheet_name):\n",
    "        self.base_folder = base_folder\n",
    "        self.credentials_path = credentials_path\n",
    "        self.sheet_id = sheet_id\n",
    "        self.worksheet_name = worksheet_name\n",
    "        self.metadata_file = \"xnurta_file_metadata_2024.json\"\n",
    "        \n",
    "        # Initialize Google Sheets\n",
    "        self._init_google_sheets()\n",
    "        \n",
    "        # Load existing metadata\n",
    "        self.file_metadata = self._load_metadata()\n",
    "        \n",
    "    def _init_google_sheets(self):\n",
    "        \"\"\"Initialize Google Sheets connection\"\"\"\n",
    "        scopes = [\"https://www.googleapis.com/auth/spreadsheets\", \n",
    "                  \"https://www.googleapis.com/auth/drive\"]\n",
    "        creds = Credentials.from_service_account_file(self.credentials_path, scopes=scopes)\n",
    "        self.client = gspread.authorize(creds)\n",
    "        self.spreadsheet = self.client.open_by_key(self.sheet_id)\n",
    "        self.worksheet = self.spreadsheet.worksheet(self.worksheet_name)\n",
    "    \n",
    "    def _load_metadata(self):\n",
    "        \"\"\"Load file metadata from JSON file\"\"\"\n",
    "        if os.path.exists(self.metadata_file):\n",
    "            with open(self.metadata_file, 'r', encoding='utf-8') as f:\n",
    "                return json.load(f)\n",
    "        return {}\n",
    "    \n",
    "    def _save_metadata(self):\n",
    "        \"\"\"Save file metadata to JSON file\"\"\"\n",
    "        with open(self.metadata_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(self.file_metadata, f, indent=2, ensure_ascii=False, default=str)\n",
    "    \n",
    "    def _get_file_hash(self, file_path):\n",
    "        \"\"\"Calculate file hash for change detection\"\"\"\n",
    "        hash_md5 = hashlib.md5()\n",
    "        with open(file_path, \"rb\") as f:\n",
    "            for chunk in iter(lambda: f.read(4096), b\"\"):\n",
    "                hash_md5.update(chunk)\n",
    "        return hash_md5.hexdigest()\n",
    "        \n",
    "    def extract_date_from_filename(self, filename):\n",
    "        \"\"\"\n",
    "        Extract date from filename pattern: SA_Campaign_List_YYYYMMDD_YYYYMMDD_hash.xlsx\n",
    "        Returns the first date (start date)\n",
    "        \"\"\"\n",
    "        pattern = r'SA_Campaign_List_(\\d{8})_\\d{8}_.*\\.xlsx'\n",
    "        match = re.search(pattern, os.path.basename(filename))\n",
    "        if match:\n",
    "            date_str = match.group(1)\n",
    "            return pd.to_datetime(date_str, format='%Y%m%d')\n",
    "        return None\n",
    "        \n",
    "    def clean_currency_column(self, column):\n",
    "        \"\"\"Remove $ symbol and convert to float\"\"\"\n",
    "        if column.dtype == 'object':\n",
    "            cleaned = column.astype(str).str.replace(r'[$,]', '', regex=True)\n",
    "            cleaned = cleaned.replace(['', 'nan', 'NaN'], np.nan)\n",
    "            return pd.to_numeric(cleaned, errors='coerce')\n",
    "        return column\n",
    "        \n",
    "    def convert_to_float(self, column):\n",
    "        \"\"\"Convert object columns to float\"\"\"\n",
    "        if column.dtype == 'object':\n",
    "            cleaned = column.astype(str).str.replace(r'[%,]', '', regex=True)\n",
    "            cleaned = cleaned.replace(['', 'nan', 'NaN', '--', 'N/A'], np.nan)\n",
    "            return pd.to_numeric(cleaned, errors='coerce')\n",
    "        return column\n",
    "        \n",
    "    def convert_to_int(self, column):\n",
    "        \"\"\"Convert object columns to int\"\"\"\n",
    "        if column.dtype == 'object':\n",
    "            cleaned = column.astype(str).str.replace(r'[,]', '', regex=True)\n",
    "            cleaned = cleaned.replace(['', 'nan', 'NaN', '--', 'N/A'], np.nan)\n",
    "            float_col = pd.to_numeric(cleaned, errors='coerce')\n",
    "            return float_col.astype('Int64')  # Nullable integer type\n",
    "        return column\n",
    "        \n",
    "    def extract_asin_from_portfolio(self, portfolio_str):\n",
    "        \"\"\"Extract ASIN from Portfolio string\"\"\"\n",
    "        if pd.isna(portfolio_str) or portfolio_str == '':\n",
    "            return None\n",
    "        \n",
    "        portfolio_str = str(portfolio_str)\n",
    "        \n",
    "        # Pattern 1: B + 9 alphanumeric (most common ASIN format)\n",
    "        pattern1 = r'B[A-Z0-9]{9}'\n",
    "        match1 = re.search(pattern1, portfolio_str)\n",
    "        if match1:\n",
    "            return match1.group()\n",
    "        \n",
    "        # Pattern 2: 10 alphanumeric characters starting with letter\n",
    "        pattern2 = r'[A-Z][A-Z0-9]{9}'\n",
    "        match2 = re.search(pattern2, portfolio_str)\n",
    "        if match2:\n",
    "            return match2.group()\n",
    "        \n",
    "        # Pattern 3: Any 10 consecutive alphanumeric characters\n",
    "        pattern3 = r'[A-Z0-9]{10}'\n",
    "        match3 = re.search(pattern3, portfolio_str)\n",
    "        if match3:\n",
    "            return match3.group()\n",
    "        \n",
    "        # Pattern 4: 10 alphanumeric with possible lowercase (convert to uppercase)\n",
    "        pattern4 = r'[A-Za-z0-9]{10}'\n",
    "        match4 = re.search(pattern4, portfolio_str)\n",
    "        if match4:\n",
    "            return match4.group().upper()\n",
    "        \n",
    "        # If no pattern matches, return first 10 characters as fallback\n",
    "        clean_str = re.sub(r'[^A-Za-z0-9]', '', portfolio_str)\n",
    "        if len(clean_str) >= 10:\n",
    "            return clean_str[:10].upper()\n",
    "        \n",
    "        return portfolio_str[:10] if len(portfolio_str) >= 10 else portfolio_str\n",
    "        \n",
    "    def normalize_campaign_types(self, text):\n",
    "        \"\"\"Normalize campaign type keywords\"\"\"\n",
    "        if pd.isna(text) or text == '':\n",
    "            return text\n",
    "        \n",
    "        text = str(text)\n",
    "        \n",
    "        normalizations = {\n",
    "            'sponsoredBrands': 'SB',\n",
    "            'sponsoredDisplay': 'SD', \n",
    "            'sponsoredProducts': 'SP',\n",
    "            'sponsoredbrands': 'SB',\n",
    "            'sponsoreddisplay': 'SD',\n",
    "            'sponsoredproducts': 'SP',\n",
    "            'Sponsored Brands': 'SB',\n",
    "            'Sponsored Display': 'SD',\n",
    "            'Sponsored Products': 'SP'\n",
    "        }\n",
    "        \n",
    "        for original, normalized in normalizations.items():\n",
    "            text = text.replace(original, normalized)\n",
    "        \n",
    "        return text\n",
    "        \n",
    "    def process_single_excel(self, file_path):\n",
    "        \"\"\"Process a single Excel file according to specifications\"\"\"\n",
    "        try:\n",
    "            # Read Excel file\n",
    "            df = pd.read_excel(file_path)\n",
    "            \n",
    "            # Extract date from filename\n",
    "            date_extracted = self.extract_date_from_filename(file_path)\n",
    "            \n",
    "            # Drop specified columns if they exist\n",
    "            columns_to_drop = [\n",
    "                'Profile', \n",
    "                'Labels', \n",
    "                'Budget group',\n",
    "                'Status',\n",
    "                'Current Budget',\n",
    "                'SP Off-site Ads Strategy',\n",
    "                'Bidding Strategy',\n",
    "                'Sales Same SKU',\n",
    "                'Sales Other SKU',\n",
    "                'Orders Same SKU',\n",
    "                'Orders Other SKU',\n",
    "                'Units Same SKU',\n",
    "                'Units Other SKU'\n",
    "            ]\n",
    "            existing_columns_to_drop = [col for col in columns_to_drop if col in df.columns]\n",
    "            if existing_columns_to_drop:\n",
    "                df = df.drop(columns=existing_columns_to_drop)\n",
    "                print(f\"   🗑️ Dropped columns: {', '.join(existing_columns_to_drop)}\")\n",
    "            \n",
    "            # Add ASIN column as first column (extract ASIN from Portfolio)\n",
    "            if 'Portfolio' in df.columns:\n",
    "                df.insert(0, 'ASIN', df['Portfolio'].apply(self.extract_asin_from_portfolio))\n",
    "            \n",
    "            # Add Date column\n",
    "            df.insert(1, 'Date', date_extracted)\n",
    "            \n",
    "            # Normalize campaign types in Campaign Type column\n",
    "            if 'Campaign type' in df.columns:\n",
    "                df['Campaign type'] = df['Campaign type'].apply(self.normalize_campaign_types)\n",
    "            \n",
    "            # Clean currency columns\n",
    "            currency_columns = ['Daily Budget']\n",
    "            for col in currency_columns:\n",
    "                if col in df.columns:\n",
    "                    df[col] = self.clean_currency_column(df[col])\n",
    "            \n",
    "            # Convert specified columns to float\n",
    "            float_columns = ['Avg.time in Budget', 'Top-of-search IS', 'CPC', 'CVR', 'ACOS', 'ROAS']\n",
    "            for col in float_columns:\n",
    "                if col in df.columns:\n",
    "                    df[col] = self.convert_to_float(df[col])\n",
    "            \n",
    "            # Note: Removed int_columns conversion since those columns are now dropped\n",
    "            \n",
    "            print(f\"✅ Successfully processed: {os.path.basename(file_path)}\")\n",
    "            return df\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Error processing {file_path}: {str(e)}\")\n",
    "            return pd.DataFrame()\n",
    "            \n",
    "    def _is_h2_2024_file(self, file_date):\n",
    "        \"\"\"Check if file belongs to Q3 2024 (July to September 2024)\"\"\"\n",
    "        if not file_date:\n",
    "            return False\n",
    "        return file_date.month in [7, 8, 9] and file_date.year == 2024\n",
    "        \n",
    "    def _should_process_file(self, file_path, file_date, is_initial_run=False):\n",
    "        \"\"\"Determine if file should be processed\"\"\"\n",
    "        file_name = os.path.basename(file_path)\n",
    "        current_hash = self._get_file_hash(file_path)\n",
    "        modification_time = os.path.getmtime(file_path)\n",
    "        \n",
    "        # For initial run, process all H2 2024 files\n",
    "        if is_initial_run:\n",
    "            if self._is_h2_2024_file(file_date):\n",
    "                print(f\"🔄 Initial run: Processing Q3 2024 file {file_name}\")\n",
    "                return True\n",
    "            return False\n",
    "        \n",
    "        # For subsequent runs, check if file is new or changed\n",
    "        if file_name not in self.file_metadata:\n",
    "            print(f\"➕ New file detected: {file_name}\")\n",
    "            return True\n",
    "        \n",
    "        stored_metadata = self.file_metadata[file_name]\n",
    "        \n",
    "        if (stored_metadata.get('hash') != current_hash or \n",
    "            stored_metadata.get('modification_time') != modification_time):\n",
    "            print(f\"🔄 Modified file detected: {file_name}\")\n",
    "            return True\n",
    "        \n",
    "        print(f\"⏭️ Skipping unchanged file: {file_name}\")\n",
    "        return False\n",
    "        \n",
    "    def _update_file_metadata(self, file_path, file_date):\n",
    "        \"\"\"Update metadata for processed file\"\"\"\n",
    "        file_name = os.path.basename(file_path)\n",
    "        self.file_metadata[file_name] = {\n",
    "            'path': file_path,\n",
    "            'date': file_date,\n",
    "            'hash': self._get_file_hash(file_path),\n",
    "            'modification_time': os.path.getmtime(file_path),\n",
    "            'processed_at': datetime.now()\n",
    "        }\n",
    "        \n",
    "    def process_files(self, initial_run=False):\n",
    "        \"\"\"Main processing function for XNurta 2024 data\"\"\"\n",
    "        print(\"=\" * 60)\n",
    "        if initial_run:\n",
    "            print(\"🚀 INITIAL RUN: Processing Q3 2024 XNurta files (Jul-Sep)\")\n",
    "            # Clear existing Q3 2024 metadata for fresh start\n",
    "            files_to_remove = []\n",
    "            for file_name, metadata in self.file_metadata.items():\n",
    "                if isinstance(metadata.get('date'), str):\n",
    "                    file_date = pd.to_datetime(metadata['date'])\n",
    "                elif metadata.get('date'):\n",
    "                    file_date = metadata['date']\n",
    "                else:\n",
    "                    continue\n",
    "                    \n",
    "                if self._is_h2_2024_file(file_date):\n",
    "                    files_to_remove.append(file_name)\n",
    "            \n",
    "            for file_name in files_to_remove:\n",
    "                del self.file_metadata[file_name]\n",
    "                print(f\"🗑️ Cleared metadata for Q3 2024 file: {file_name}\")\n",
    "        else:\n",
    "            print(\"🔄 INCREMENTAL RUN: Processing new/modified files only\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        all_dataframes = []\n",
    "        processed_files = []\n",
    "        \n",
    "        # Scan all Excel files in subfolders (Tháng 7, Tháng 8, etc.)\n",
    "        for root, dirs, files in os.walk(self.base_folder):\n",
    "            for file in files:\n",
    "                if file.endswith(\".xlsx\"):\n",
    "                    file_path = os.path.join(root, file)\n",
    "                    file_date = self.extract_date_from_filename(file)\n",
    "                    \n",
    "                    if self._should_process_file(file_path, file_date, initial_run):\n",
    "                        print(f\"📊 Processing: {file}\")\n",
    "                        df = self.process_single_excel(file_path)\n",
    "                        \n",
    "                        if not df.empty:\n",
    "                            all_dataframes.append(df)\n",
    "                            processed_files.append(file)\n",
    "                            self._update_file_metadata(file_path, file_date)\n",
    "                        else:\n",
    "                            print(f\"⚠️ Empty dataframe for: {file}\")\n",
    "        \n",
    "        # Combine all processed data\n",
    "        if all_dataframes:\n",
    "            print(f\"\\n📈 Combining {len(all_dataframes)} dataframes...\")\n",
    "            master_df = pd.concat(all_dataframes, ignore_index=True, sort=False)\n",
    "            \n",
    "            # Sort by Date and ASIN\n",
    "            if \"Date\" in master_df.columns:\n",
    "                master_df = master_df.sort_values(['Date', 'ASIN'], na_position='last')\n",
    "            \n",
    "            # Reset index\n",
    "            master_df = master_df.reset_index(drop=True)\n",
    "            \n",
    "            print(f\"✅ Combined data shape: {master_df.shape}\")\n",
    "            print(f\"📅 Date range: {master_df['Date'].min()} to {master_df['Date'].max()}\")\n",
    "            \n",
    "            # Upload to Google Sheets\n",
    "            self._upload_to_sheets(master_df)\n",
    "            \n",
    "            # Save metadata\n",
    "            self._save_metadata()\n",
    "            \n",
    "            print(f\"\\n🎉 Successfully processed {len(processed_files)} files:\")\n",
    "            for file in processed_files:\n",
    "                print(f\"   ✓ {file}\")\n",
    "            \n",
    "            return master_df\n",
    "        else:\n",
    "            print(\"ℹ️ No files to process.\")\n",
    "            return pd.DataFrame()\n",
    "            \n",
    "    def _upload_to_sheets(self, df):\n",
    "        \"\"\"Upload DataFrame to Google Sheets\"\"\"\n",
    "        try:\n",
    "            print(\"📤 Uploading to Google Sheets...\")\n",
    "            \n",
    "            # Clear limited columns range (A to AZ) instead of entire sheet\n",
    "            self.worksheet.batch_clear(['A:AZ'])\n",
    "            \n",
    "            # Upload new data\n",
    "            set_with_dataframe(self.worksheet, df)\n",
    "            \n",
    "            print(f\"✅ Successfully uploaded {len(df)} rows to Google Sheets\")\n",
    "            print(f\"🔗 Sheet: {self.worksheet_name}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error uploading to Google Sheets: {e}\")\n",
    "            \n",
    "    def get_processing_summary(self):\n",
    "        \"\"\"Get summary of processed files by month\"\"\"\n",
    "        if not self.file_metadata:\n",
    "            return \"No files processed yet.\"\n",
    "        \n",
    "        monthly_files = {\n",
    "            7: [], 8: [], 9: [], 10: [], 11: [], 12: [], 'other': []\n",
    "        }\n",
    "        month_names = {\n",
    "            7: 'July', 8: 'August', 9: 'September', \n",
    "            10: 'October', 11: 'November', 12: 'December'\n",
    "        }\n",
    "        \n",
    "        for file_name, metadata in self.file_metadata.items():\n",
    "            if isinstance(metadata.get('date'), str):\n",
    "                file_date = pd.to_datetime(metadata['date'])\n",
    "            elif metadata.get('date'):\n",
    "                file_date = metadata['date']\n",
    "            else:\n",
    "                monthly_files['other'].append(file_name)\n",
    "                continue\n",
    "            \n",
    "            if file_date.month in monthly_files:\n",
    "                monthly_files[file_date.month].append(file_name)\n",
    "            else:\n",
    "                monthly_files['other'].append(file_name)\n",
    "        \n",
    "        summary = f\"\"\"\n",
    "📊 PROCESSING SUMMARY - XNurta 2024 Q3\n",
    "=======================================\"\"\"\n",
    "        \n",
    "        for month_num in [7, 8, 9]:\n",
    "            count = len(monthly_files[month_num])\n",
    "            summary += f\"\\n{month_names[month_num]} files: {count}\"\n",
    "        \n",
    "        summary += f\"\"\"\n",
    "Other files: {len(monthly_files['other'])}\n",
    "Total files: {len(self.file_metadata)}\n",
    "Last run: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "        \"\"\"\n",
    "        return summary\n",
    "\n",
    "# Usage Example\n",
    "if __name__ == \"__main__\":\n",
    "    # Configuration for XNurta 2024\n",
    "    config = {\n",
    "        'base_folder': \"C:/Users/admin1/Desktop/Performance-Tracking/Xnurta 2024 (by day)\",  # Update path\n",
    "        'credentials_path': \"c:/Users/admin1/Downloads/new_credential.json\",\n",
    "        'sheet_id': \"1lZ4dsi94HaeWshsEizKTyNHeOOG0tpLJhzL9pMxvd6k\",\n",
    "        'worksheet_name': \"Raw_XNurta_H2_2024\"\n",
    "    }\n",
    "    \n",
    "    # Initialize processor\n",
    "    processor = XNurtaDataProcessor2024(**config)\n",
    "    \n",
    "    # Choose run mode\n",
    "    print(\"Choose run mode for XNurta 2024 Q3 data:\")\n",
    "    print(\"1. Initial run (reprocess all Q3 2024 files: Jul-Sep)\")\n",
    "    print(\"2. Incremental run (process only new/modified files)\")\n",
    "    \n",
    "    choice = input(\"Enter choice (1 or 2): \").strip()\n",
    "    \n",
    "    if choice == \"1\":\n",
    "        result_df = processor.process_files(initial_run=True)\n",
    "    else:\n",
    "        result_df = processor.process_files(initial_run=False)\n",
    "    \n",
    "    # Print summary\n",
    "    print(processor.get_processing_summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f78e365",
   "metadata": {},
   "source": [
    "# Version 2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
